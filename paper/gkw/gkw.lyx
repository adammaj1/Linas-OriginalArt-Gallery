#LyX 1.3 created this file. For more info see http://www.lyx.org/
\lyxformat 221
\textclass article
\language english
\inputencoding auto
\fontscheme default
\graphics default
\paperfontsize default
\spacing single 
\papersize Default
\paperpackage a4
\use_geometry 0
\use_amsmath 1
\use_natbib 0
\use_numerical_citations 0
\paperorientation portrait
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\defskip medskip
\quotes_language english
\quotes_times 2
\papercolumns 1
\papersides 1
\paperpagestyle default

\layout Title

The Bernoulli Operator, the Gauss-Kuzmin-Wirsing Operator, and the Riemann
 Zeta
\layout Author

Linas Vepstas <linas@linas.org>
\layout Date

2 January 2004 (revised 12 October 2004)
\layout Abstract

The study of the Gauss-Kuzmin-Wirsing (GKW) operator can provide insight
 into the structure of the Riemann Zeta function, as the Zeta is a laplace-like
 transform of the GKW.
 Unfortunately, it is quite complex itself, and appears very difficult to
 solve.
 This chapter applies some tools developed for the study of fractals, and
 thier symmetries, to discuss and solve some related operators.
 
\layout Abstract

Specifically, the Minkowski Question Mark Function is an isomorphism connecting
 the dyadic (binary) fractions and the Farey Fractions.
 The Question Mark embodies the basic Modular Group 
\begin_inset Formula $SL(2,\mathbb{Z})$
\end_inset 

 symmetries seen in the dyadic and Farey Trees, and thus seen in fractals.
 This implies that GKW should have a set of modular-group symmetries as
 well, which in turn might extend onto the Riemann Zeta.
 
\layout Abstract

This chapter develops some of the tools for studying chaotic maps, spcifically
 the idea of studying the Frobenius-Perron (FP) operator of a chaotic map.
 The FP operator of the map that generates continued fractions is the GKW.
 We thus apply the modular group symmetries of the continued fractions to
 study the GKW.
 
\layout Abstract

The general presentation attempts to assume very little prior acquaintance
 with the concepts, and attempts a pedagogical aproach.
 This paper is part of a set of chapters that explore the relationship between
 the real numbers, the modular group, and fractals.
\layout Section

The Bernoulli Operator, the Gauss-Kuzmin-Wirsing Operator and the Riemann
 Zeta
\layout Standard

THIS IS A DRAFT WORK IN PROGRESS.
 The intro hasn't been written yet.
\layout Standard

One of the new results is a demonstration that the Frobenius-Perron operator
 can have a continuous spectrum that is 
\begin_inset Formula $C^{\infty}$
\end_inset 

which flies in the face of common assumptions that the spectrum is either
 discrete with 
\begin_inset Formula $C^{\infty}$
\end_inset 

 eigenfunctions, or is continuous, with non-differentiable (fractal) eigenfuncti
ons.
 Of course, there is a catch: the eigenfunctions are differentiable everywhere
 except at the endpoints, which does render them 
\begin_inset Quotes eld
\end_inset 

non-physical
\begin_inset Quotes erd
\end_inset 

.
 Explicit transformations between these and the fractal eigenfunctions are
 presented.
 
\layout Section

Introduction: The Frobenius-Perron Operator for Iterated Maps
\layout Standard

This section provides a basic review of the Frobenius-Perron operator and
 its use in the description of fractals and chaotic iterated maps.
 No results are presented here; rather the goal is to provide the notation
 and general concepts that will be used in later sections.
 This review assumes no prior encounter with these concepts, and keeps the
 development simple, avoiding the language of higher mathematics.
 More sophisticated developments build on concepts such as Borel Sigma Algebras
 and define the Frobenius-Perron operator on Banach Spaces.
 In the following, we avoid this sophisticated language in order to keep
 the presentation accessible.
 However, we do so at some peril: many of the quantities we'll work with
 are potentially ill-defined or divergent, and so the validity of some of
 the transformations and equations in such foggy surrounds can be questionable.
 A more rigorous treatment with appeals to higher math would help clarify
 where the rocky shoals are.
 As a substitute, we try to maintain a physicist's attitude, and keep our
 heads about us when faced with something dangerous.
 Be aware that not all extrapolations from the following may be warranted.
 
\layout Standard

The Frobenius-Perron operator of a function provides a tool for studying
 the dynamics of the iteration of that function.
 If one only studies how a point value jumps around during iteration, one
 gets a very good sense of the point dynamics but no sense of how iteration
 acts on non-point sets.
 If the iterated function is applied on a continuous, possibly even smooth
 density, then one wants to know how that smooth density evolves over repeated
 iteration.
 
\layout Standard

If we consider a smooth density 
\begin_inset Formula $\rho(x)$
\end_inset 

 as a set of values on a collection of points, we can take each point and
 iterate it to find its new location, and then assign the old value to the
 new location.
 Of course, after iteration, several points may end up at the same location,
 at which point we need to add their values together.
 Lets write the new density as 
\begin_inset Formula $\rho_{1}(x)$
\end_inset 

, with the subscript 1 denoting we've iterated once.
 We can express this idea of iterating the underlying points, and then assigning
 their old values to new locations as 
\begin_inset Formula \[
\rho_{1}(x)=\int dy\;\delta\left(x-g(y)\right)\;\rho(y)\]

\end_inset 

 where 
\begin_inset Formula $g(x)$
\end_inset 

 is the iterated function.
 To get 
\begin_inset Formula $\rho_{n}(x)$
\end_inset 

, one simply repeats the procedure 
\begin_inset Formula $n$
\end_inset 

 times.
 In more abstract notation, one writes 
\begin_inset Formula \[
\left[U_{g}\rho\right](x)=\rho_{1}(x)\]

\end_inset 

 to denote this time evolution.
 The notation here emphasizes that 
\begin_inset Formula $U_{g}:\; f\mapsto U_{g}f$
\end_inset 

 is an operator that maps functions to functions: written formally, we have
 
\begin_inset Formula $U_{g}:\mathcal{F\mathcal{\rightarrow F}}$
\end_inset 

 where 
\begin_inset Formula $\mathcal{F}=\left\{ f\;|\; f:\mathbb{\mathbb{R\rightarrow}R}\right\} $
\end_inset 

 is the set of all functions.
 In analyzing 
\begin_inset Formula $U_{g}$
\end_inset 

, we will often be interested in how it acts on the subset of square-integrable
 functions, or possibly just 
\begin_inset Formula $C^{\infty}$
\end_inset 

 functions or polynomials or the like.
 Repeated iteration just gives the time-evolution of the the density; that
 is, 
\begin_inset Formula \[
U_{g}^{n}\rho\equiv\begin{array}{c}
\underbrace{U_{g}\circ U_{g}\circ...\circ U_{g}}\\
n\textrm{ times}\end{array}\;\circ\rho=\rho_{n}\]

\end_inset 

 where iteration is just ordinary operator multiplication.
 
\layout Standard

To understand 
\begin_inset Formula $U_{g}$
\end_inset 

, one typically tries to understand its spectrum, that is, its eigenvalues
 and eigenfunctions.
 In most cases, one finds that 
\begin_inset Formula $U_{g}$
\end_inset 

 is contractive in that it has one eigenvalue equal to one and all the other
 eigenvalues are real and smaller than one.
 However, one must be terribly careful here, as there are land-mines strewn
 about: the actual spectrum, and the nature of the eigenvalues, depends
 very much on the function space chosen.
 Typically, when acting on polynomials, one gets discrete, real eigenvalues
 for 
\begin_inset Formula $U_{g}$
\end_inset 

.
 When acting on square-integrable functions, one seems to usually get a
 continuous set of complex-valued eigenvalues.
 This is because one can often find shift-states 
\begin_inset Formula $\psi_{n}$
\end_inset 

 such that 
\begin_inset Formula $U_{g}\psi_{n}=\psi_{n-1}$
\end_inset 

, in which case one can construct eigenfunctions 
\begin_inset Formula $\phi(z)=\sum_{n}z^{n}\psi_{n}$
\end_inset 

 whose complex eigenvalues 
\begin_inset Formula $z$
\end_inset 

 form the unit disk.
 It is often considered to be a mistake to try to analyze 
\begin_inset Formula $U_{g}$
\end_inset 

 acting on a finite grid of discrete points, such as one might try on a
 computer: it is all to easy to turn this into an exercise of analyzing
 the permutation group on a set of 
\begin_inset Formula $k$
\end_inset 

 elements, of which any student knows that the eigenvalues are the 
\begin_inset Formula $k$
\end_inset 

'th roots of unity.
 
\layout Standard

Since 
\begin_inset Formula $U_{g}$
\end_inset 

 is a linear operator, it induces a homomorphism in its mapping, and so
 one should study its kernel 
\begin_inset Formula $Ker\; U_{g}=\left\{ f\;|\; U_{g}f=0\right\} $
\end_inset 

 to gain insights into its symmetry as well as to express more correctly
 the quotient space.
 Insofar as the iterated map might represent a dynamical system, one knows
 that symmetries lead to conserved currents, via Noether's theorem, and
 sometimes to topologically-conserved (quantum) numbers, winding numbers
 or other invariants.
 
\layout Standard

Finally, we note that since 
\begin_inset Formula $U_{g}$
\end_inset 

 looks like a time-evolution operator, we are tempted to write
\begin_inset Formula \[
U_{g}^{t}=\exp\;-tH_{g}\]

\end_inset 

 for some other operator 
\begin_inset Formula $H_{g}$
\end_inset 

.
 Since 
\begin_inset Formula $U$
\end_inset 

 is in general not unitary, 
\begin_inset Formula $H$
\end_inset 

 is not (anti-)Hermitian.
 However, for many systems, the eigenvalues of 
\begin_inset Formula $U_{g}$
\end_inset 

 are real and less than or equal to one, and thus, one would expect that
 
\begin_inset Formula $H_{g}$
\end_inset 

 would be positive-definite.
 If 
\begin_inset Formula $H_{g}$
\end_inset 

 is Hermitian, then one is lead to look for an associated Heisenberg Algebra,
 which would point to a dynamical system that can be understood through
 the map iteration.
\layout Standard

Also, any group of symmetries on 
\begin_inset Formula $U$
\end_inset 

 should express themselves as an algebra on 
\begin_inset Formula $H$
\end_inset 

 and these might provide an alternate path for exploring and describing
 the fractal in question.
\layout Standard

In practice, when one is given an iterated map 
\begin_inset Formula $g(x)$
\end_inset 

, one computes the Frobenius-Perron operator as 
\begin_inset Formula \[
\left[U_{g}\rho\right](x)=\sum_{x':x=g(x')}\frac{\rho(x')}{\left|dg(x')/dx'\right|}\]

\end_inset 

 which provides an expression for 
\begin_inset Formula $U_{g}$
\end_inset 

 acting on a general function 
\begin_inset Formula $\rho$
\end_inset 

.
\layout Subsection

Polynomial Representation
\layout Standard

If one is interested in 
\begin_inset Formula $U$
\end_inset 

 acting on polynomial functions, then one immediately writes the Taylor
 (or Maclaurin) series 
\begin_inset Formula \[
\rho(x)=\sum_{n=0}^{\infty}\frac{\rho^{(n)}(0)}{n!}x^{n}=\sum_{n=0}^{\infty}a_{n}x^{n}\]

\end_inset 

 and substitutes this in to get the matrix form of 
\begin_inset Formula $U$
\end_inset 

:
\begin_inset Formula \[
\left[U\rho\right](x)=\sum_{m=0}^{\infty}b_{m}x^{m}=\sum_{m=0}^{\infty}x^{m}\sum_{n=0}^{\infty}U_{mn}a_{n}\]

\end_inset 

 Equating each power of 
\begin_inset Formula $x^{m}$
\end_inset 

 we get 
\begin_inset Formula \[
\left.\frac{1}{m!}\;\frac{d^{m}\left[U\rho\right](x)}{dx^{m}}\right|_{x=0}=\sum_{n=0}^{\infty}U_{mn}\left.\frac{1}{n!}\;\frac{d^{n}\rho(x)}{dx^{n}}\right|_{x=0}\]

\end_inset 

 as the matrix equation for the transformation of polynomials, expressed
 in classical notation.
 
\layout Standard

There are a variety of different notations that one can use when working
 with matrix operators, all of which are, at a certain level, completely
 equivalent.
 However, certain notations are handier than others depending on what representa
tion one is working with, and what point one is trying to emphasize.
 Note in particular that the Dirac bra-ket notation is both very useful,
 and is also sometimes a source for confusion, especially when mixed with
 other notations.
 Thus, in the following, we take some pains to clarify this notation, giving
 a prolonged remedial presentation.
 (XXX this should be moved to an appendix).
\layout Standard

The operator, written in the polynomial representation, in space coordinates,
 is:
\begin_inset Formula \begin{eqnarray*}
\delta\left(x-g(y)\right)=U_{g}(x,y) & = & \left\langle x\left|U_{g}\right|y\right\rangle \\
 & = & \sum_{m=0}^{\infty}\sum_{n=0}^{\infty}\left\langle x|m\right\rangle \left\langle m\left|U_{g}\right|n\right\rangle \left\langle n|y\right\rangle \end{eqnarray*}

\end_inset 

 where 
\begin_inset Formula $U_{mn}=\left\langle m|U|n\right\rangle $
\end_inset 

 and 
\begin_inset Formula $\left\langle x|m\right\rangle =x^{m}$
\end_inset 

 and 
\begin_inset Formula $\left\langle n|y\right\rangle =(-)^{n}\delta^{(n)}(y)/n!$
\end_inset 

, the latter being the 
\begin_inset Formula $n$
\end_inset 

'th derivative of the Dirac delta function.
 In this basis, 
\begin_inset Formula $U$
\end_inset 

 is not diagonal, and the kets 
\begin_inset Formula $\left|n\right\rangle $
\end_inset 

 are not eigenvectors, and the vector element 
\begin_inset Formula $\left\langle x|m\right\rangle $
\end_inset 

 is neither the complex conjugate nor the transpose of 
\begin_inset Formula $\left\langle n|y\right\rangle $
\end_inset 

.
 These are rather monomials and their inverses, and obey traditional orthogonali
ty and completeness relationships.
 The inner products demonstrate orthogonality: 
\begin_inset Formula \begin{eqnarray*}
\left\langle n|m\right\rangle  & = & \int dx\left\langle n|x\right\rangle \left\langle x|m\right\rangle \\
 & = & \int dx\,(-)^{n}\frac{\delta^{(n)}(x)}{n!}x^{m}\\
 & = & \delta_{nm}\end{eqnarray*}

\end_inset 

 and 
\begin_inset Formula \begin{eqnarray*}
\left\langle x|y\right\rangle  & = & \sum_{n=0}^{\infty}\left\langle x|n\right\rangle \left\langle n|y\right\rangle \\
 & = & \sum_{n=0}^{\infty}(-x)^{n}\frac{\delta^{(n)}(y)}{n!}\\
 & = & \delta(y-x)\end{eqnarray*}

\end_inset 

 are the orthogonality relationships in polynomial space and coordinate
 space, respectively.
 The completeness relationships define the identity operator 
\begin_inset Formula \[
\mathbb{I}=\sum_{n=0}^{\infty}\left|n\right\rangle \left\langle n\right|=\int dx\left|x\right\rangle \left\langle x\right|\]

\end_inset 

 whose matrix elements in coordinate space are 
\begin_inset Formula $\left\langle x\right|\mathbb{I}\left|y\right\rangle =\delta(y-x)$
\end_inset 

 and, in polynomial space, 
\begin_inset Formula $\left\langle m\right|\mathbb{I}\left|n\right\rangle =\delta_{mn}$
\end_inset 

.
 In this notation, a function is represented by it's Taylor series: 
\begin_inset Formula \begin{eqnarray*}
f(x) & = & \left\langle x|f\right\rangle \\
 & = & \sum_{n=0}^{\infty}\left\langle x|n\right\rangle \left\langle n|f\right\rangle \\
 & = & \sum_{n=0}^{\infty}x^{n}\left\langle n|f\right\rangle \\
 & = & \sum_{n=0}^{\infty}x^{n}\int dy\left\langle n|y\right\rangle \left\langle y|f\right\rangle \\
 & = & \sum_{n=0}^{\infty}x^{n}\int dy(-)^{n}\frac{\delta^{(n)}(y)}{n!}f(y)\\
 & = & \sum_{n=0}^{\infty}x^{n}\frac{f^{(n)}(0)}{n!}\end{eqnarray*}

\end_inset 


\layout Standard

Lets complete the review by taking the coordinate-space representation of
 the Frobenius-Perron operator back to its matrix representation.
 Integrating the coordinate-space operator representation over 
\begin_inset Formula $y$
\end_inset 

, we regain the previous expressions for the operator in Hilbert space:
 
\begin_inset Formula \begin{multline*}
\left[U_{g}\rho\right](x)=\int dy\; U_{g}(x,y)\rho(y)\end{multline*}

\end_inset 

 
\begin_inset Formula \[
=\int dy\;\delta\left(g(x)-y\right)\rho(y)\]

\end_inset 


\begin_inset Formula \[
=\sum_{m,n=0}^{\infty}\; x^{m}\; U_{mn}\int dy\;(-)^{n}\frac{\delta^{(n)}(y)}{n!}\rho(y)\]

\end_inset 

 
\begin_inset Formula \[
=\sum_{m,n=0}^{\infty}\; x^{m}\; U_{mn}\left.\frac{1}{n!}\;\frac{d^{n}\rho(y)}{dy^{n}}\right|_{y=0}\]

\end_inset 


\begin_inset Formula \[
=\sum_{m,n=0}^{\infty}\; x^{m}\; U_{mn}\;\frac{\rho^{(n)}(0)}{n!}\]

\end_inset 

 Note that when one goes to diagonalize the operator, one will find 
\begin_inset Quotes eld
\end_inset 

right eigenvectors
\begin_inset Quotes erd
\end_inset 

 that will consist solely of a linear combination of 
\begin_inset Formula $\left\langle x|m\right\rangle =x^{m}$
\end_inset 

 , that is, will be polynomials.
 The 
\begin_inset Quotes eld
\end_inset 

left eigenstates
\begin_inset Quotes erd
\end_inset 

 will, by definition, be a linear combination solely of 
\begin_inset Formula $\left\langle n|y\right\rangle =(-)^{n}\delta^{(n)}(y)/n!$
\end_inset 

 since, in a polynomial Hilbert space, these are the basis functions that
 are adjoint to polynomials.
\layout Standard

It is critical to understand that the above notation and conventions are
 applicable only to the polynomial representation, and by construction,
 yields discrete spectra and polynomial (analytic, 
\begin_inset Formula $C^{\infty}$
\end_inset 

) eigenfunctions.
 This representation is more-or-less incapable of doing otherwise.
 The above expressions, although constructed using an equals sign, in fact
 do a great deal of violence and are in a certain way violently incorrect,
 because they hide or incorrectly equate the function spaces on which the
 operator 
\begin_inset Formula $U_{g}$
\end_inset 

 acts.
 That is, whenever 
\begin_inset Formula $\rho(x)$
\end_inset 

 is not differentiable or is otherwise singular, the expansion in derivatives
 is not justified.
 As we will see shortly, when considered as acting in the space of square-integr
able functions, 
\begin_inset Formula $U_{g}$
\end_inset 

 can and will have fractal eigenfunctions, which will typically be non-different
iable and even possibly continuous-nowhere, and thus not representable by
 polynomials.
 This is, of course, the whole point of this exercise!
\layout Standard

If one is very lucky, one finds that 
\begin_inset Formula $U_{mn}$
\end_inset 

 is upper-triangular, in which case it can be solved immediately for its
 eigenfunctions, and its eigenvalues already lie on the diagonal.
 We will find that we get lucky in this way for the Bernoulli operator,
 and for the 
\begin_inset Quotes eld
\end_inset 

singular sawtooth
\begin_inset Quotes erd
\end_inset 

 operator, but not for the Gauss-Kuzmin-Wirsing operator.
 Of course, it is known that a complete solution of the GKW should lead
 directly to a proof of the Riemann Hypothesis, so getting lucky would be
 truly lucky indeed.
 XXXX edit the above sentences.
\layout Subsection

Fourier Representation
\layout Standard

We repeat the above analysis using standard Fourier Series techniques.
 Although such an analysis may be considered to be old and shop-worn, it
 is critical to note that in this context, the Fourier representation is
 not only inequivalent to the polynomial representation, but that attempting
 to establish an equivalence leads to divergences reminiscent of those seen
 in more complicated Hilbert spaces, such as those encountered in Quantum
 Field Theory and elsewhere.
 In less flowery terms, we provide a simple example where undergraduate
 
\begin_inset Quotes eld
\end_inset 

textbook math
\begin_inset Quotes erd
\end_inset 

 leads one to form incorrect conclusions about Hilbert Spaces and the behavior
 of operators in them.
 What look like simple statements about orthogonality and completeness of
 a set of basis functions can lead to serious trouble when analyzing even
 simple operators, as we shall show.
 The goal here is to get this 
\begin_inset Quotes eld
\end_inset 

dirty laundry
\begin_inset Quotes erd
\end_inset 

 out in the open, as it affects the development of later sections.
 
\layout Standard

Lets quickly review the standard textbook treatment of a Fourier Series.
 In traditional notation, for some (periodic) function 
\begin_inset Formula $f(x)$
\end_inset 

 one writes the Fourier Series as 
\begin_inset Formula \[
f(x)=\sum_{n=-\infty}^{\infty}a_{n}\cos2\pi nx\;+b_{n}\sin2\pi nx\]

\end_inset 

 where the conjugates of 
\begin_inset Formula $f$
\end_inset 

 are given by 
\begin_inset Formula \[
a_{n}=\int_{0}^{1}f(x)\,\cos(2\pi nx)\, dx\]

\end_inset 

 and 
\begin_inset Formula \[
b_{n}=\int_{0}^{1}f(x)\,\sin(2\pi nx)\, dx\]

\end_inset 

 Moving over to bra-ket notation, we can define the Fourier-space basis
 vectors 
\begin_inset Formula $\left|em\right\rangle $
\end_inset 

 in terms of their components in coordinate space.
 These components are 
\begin_inset Formula $\left\langle x|em\right\rangle =\exp(i2\pi mx)$
\end_inset 

.
 The conjugate vectors 
\begin_inset Formula $\left\langle en\right|$
\end_inset 

 have an equally simple representation: 
\begin_inset Formula $\left\langle en|x\right\rangle =\exp(-i2\pi nx)$
\end_inset 

.
 One has the usual sense of orthogonality over coordinate space in that
 
\begin_inset Formula \[
\left\langle em|en\right\rangle =\int_{0}^{1}dx\,\left\langle em|x\right\rangle \left\langle x|en\right\rangle =\int_{0}^{1}dx\,\exp(2\pi i(n-m)x)=\delta_{nm}\]

\end_inset 

 and the traditional presentation of the Fourier Series is a statement of
 completeness over coordinate space, in that for an arbitrary square-integrable
 coordinate-space function 
\begin_inset Formula $f(x)=\left\langle x|f\right\rangle $
\end_inset 

 one has 
\begin_inset Formula \begin{eqnarray*}
f(x)=\left\langle x|f\right\rangle  & = & \sum_{n=-\infty}^{\infty}\left\langle x|en\right\rangle \left\langle en|f\right\rangle \\
 & = & \sum_{n=-\infty}^{\infty}\exp(i2\pi nx)\int_{0}^{1}dy\,\left\langle en|y\right\rangle \left\langle y|f\right\rangle \\
 & = & \sum_{n=-\infty}^{\infty}\exp(i2\pi nx)\int_{0}^{1}dy\,\exp(-i2\pi ny)f(y)\\
 & = & \int_{0}^{1}dy\,\delta(x-y)\, f(y)\end{eqnarray*}

\end_inset 

 Thus, one is accustomed to the notion of having an identity operator of
 the form 
\begin_inset Formula $1_{F}=\sum_{m=-\infty}^{\infty}\left|em\right\rangle \left\langle em\right|$
\end_inset 

 because it has the matrix elements that one expects in both the Fourier
 space and in coordinate space: that is, 
\begin_inset Formula $\left\langle em\right|1_{F}\left|en\right\rangle =\delta_{nm}$
\end_inset 

 and 
\begin_inset Formula $\left\langle x\right|1_{F}\left|y\right\rangle =\delta(x-y)$
\end_inset 

 .
 
\layout Standard

Thus, in light of this perfectly ordinary standard textbook behavior, the
 following shall be surprising.
 The matrix elements of this operator, expressed in the polynomial basis,
 are not only non-trivial, but are divergent.
 That is, one can be lulled into believing that 
\begin_inset Formula $\left\langle m\right|1_{F}\left|n\right\rangle =\delta_{nm}$
\end_inset 

 for the polynomial basis, and indeed, by performing the operations in a
 certain order, one can certainly show this.
 However, reversing the order of operations shows that what might seem like
 simple operations can in fact be quite treacherous.
 
\layout Standard

We begin by writing the components of the vector 
\begin_inset Formula $\left|em\right\rangle $
\end_inset 

 in the polynomial-space representation:
\layout Standard


\begin_inset Formula \begin{eqnarray*}
\left\langle n|em\right\rangle  & = & \int_{0}^{1}dx\left\langle n|x\right\rangle \left\langle x|em\right\rangle \\
 & = & \int_{0}^{1}dx\,\frac{(-)^{n}}{n!}\delta^{(n)}(x)\, e^{i2\pi mx}\\
 & = & \int_{0}^{1}dx\,\frac{\delta(x)}{n!}\,\frac{d^{n}}{dx^{n}}\, e^{i2\pi mx}\\
 & = & \frac{(i2\pi m)^{n}}{n!}\end{eqnarray*}

\end_inset 

 Essentially, this is nothing more than a plain-old Taylor's Series expansion
 of the exponential function.
 The conjugate vectors have a slightly trickier form.
 They are the Fourier components of monomials.
 For 
\begin_inset Formula $m\neq0$
\end_inset 

 
\begin_inset Formula \begin{eqnarray*}
\left\langle em|n\right\rangle  & = & \int_{0}^{1}dy\left\langle em|y\right\rangle \left\langle y|n\right\rangle \\
 & = & \int_{0}^{1}\exp(-2\pi imy)\, y^{n}\, dy\\
 & = & \frac{-1}{2\pi im}+\frac{n}{2\pi im}\int_{0}^{1}\exp(-2\pi imy)\, y^{n-1}\, dy\\
 & = & -\frac{1}{2\pi im}\sum_{k=0}^{n-1}\frac{n!}{(n-k)!}\left(\frac{1}{2\pi im}\right)^{k}\end{eqnarray*}

\end_inset 

 and, for 
\begin_inset Formula $m=0$
\end_inset 

, 
\begin_inset Formula $\left\langle e0|n\right\rangle =1/(n+1)$
\end_inset 

.
 Let us now try to explicitly evaluate the matrix elements of the Fourier
 identity operator in the polynomial representation.
 That is, we attempt to write the matrix elements of 
\begin_inset Formula $1_{F}=\sum_{m=-\infty}^{\infty}\left|em\right\rangle \left\langle em\right|$
\end_inset 

 
\begin_inset Formula \begin{eqnarray*}
\left\langle p\right|1_{F}\left|n\right\rangle  & = & \sum_{m=-\infty}^{\infty}\left\langle p|em\right\rangle \left\langle em|n\right\rangle \\
 & = & \sum_{m=-\infty}^{\infty}\left[\delta_{p0}+\left(1-\delta_{p0}\right)\frac{\left(2\pi im\right)^{p}}{p!}\right]\left[\frac{\delta_{m0}}{n+1}-\frac{\left(1-\delta_{m0}\right)}{2\pi im}\sum_{k=0}^{n-1}\frac{n!}{(n-k)!}\left(\frac{1}{2\pi im}\right)^{k}\right]\end{eqnarray*}

\end_inset 

 We need only to look at the relatively simple matrix element 
\begin_inset Formula $n=1$
\end_inset 

, 
\begin_inset Formula $p\neq0$
\end_inset 

 to see the misery of this expression: 
\begin_inset Formula \[
\left\langle p\neq0\right|1_{F}\left|n=1\right\rangle =\frac{\left(2\pi i\right)^{p}}{p!}\sum_{m=1}^{\infty}\frac{m^{p}}{2\pi im}\]

\end_inset 

 One can try to rescue the situation by making the Ansatz that the summation
 should have been replaced by 
\begin_inset Formula $\zeta(1-p)$
\end_inset 

 which is regular, but already this is dangerous.
 What is perhaps the more surprising is that one might have expected this
 kind of trouble from the polynomial completeness relationship 
\begin_inset Formula $\mathbb{I}_{A}=\sum_{n=0}^{\infty}\left|n\right\rangle \left\langle n\right|$
\end_inset 

 because it ranges only over analytic functions: its essentially a statement
 of the idea that analytic functions are expressible through a series expansion
 in a variable.
 Functions that are not infinitely differentiable more-or-less lie in the
 kernel of 
\begin_inset Formula $\mathbb{I}_{A}$
\end_inset 

.
 However, we'd expect 
\begin_inset Formula $1_{F}$
\end_inset 

 to be more faithful, as it would seem to venture over square-integrable
 functions.
 Thus, such a simple failing is surprising.
 
\layout Standard

The goal here is to simply present a signpost warning, as we make heavy
 use of these techniques in the sections that follow, where we work with
 functions that are differentiable-nowhere or worse.
 
\layout Subsection

The Koopman Operator
\layout Standard

The Koopman operator is in a certain sense conjugate to the Frobenius-Perron
 operator, and defines how observables evolve.
 Given a density 
\begin_inset Formula $\rho(x)$
\end_inset 

 we say that the observation of a function 
\begin_inset Formula $f(x)$
\end_inset 

 by 
\begin_inset Formula $\rho$
\end_inset 

 is 
\begin_inset Formula \[
\left\langle f\,\right\rangle _{\rho}=\int_{0}^{1}f(x)\rho(x)\, dx\]

\end_inset 

 The term 
\begin_inset Quotes eld
\end_inset 

observable
\begin_inset Quotes erd
\end_inset 

 comes from usage in Quantum Mechanics, where 
\begin_inset Formula $f(x)$
\end_inset 

 is associated with the eigenvalues of an operator.
 We do not need to appeal to these operator equations for the following
 development.
 The Koopman operator 
\begin_inset Formula $K$
\end_inset 

 gives the change in 
\begin_inset Formula $f$
\end_inset 

 when 
\begin_inset Formula $U$
\end_inset 

 acts on 
\begin_inset Formula $\rho$
\end_inset 

, thus: 
\begin_inset Formula \[
K_{g}:\left\langle f\,\right\rangle _{\rho}\rightarrow\left\langle K_{g}f\,\right\rangle _{\rho}=\int_{0}^{1}[K_{g}f](x)\rho(x)\, dx=\int_{0}^{1}f(x)[U_{g}\rho](x)\, dx\]

\end_inset 

 In Dirac bra-ket notation, we have 
\begin_inset Formula \begin{eqnarray*}
\int_{0}^{1}f(x)[U_{g}\rho](x)\, dx & = & \int_{0}^{1}\left\langle x|U_{g}|\rho\right\rangle \left\langle x|f\right\rangle \, dx\\
 & = & \int_{0}^{1}dx\int_{0}^{1}dy\left\langle x|U_{g}|y\right\rangle \left\langle y|\rho\right\rangle \left\langle x|f\right\rangle \, dx\end{eqnarray*}

\end_inset 

 and so we have 
\begin_inset Formula \[
\left[K_{g}f\right](y)=\int_{0}^{1}\left\langle x|U_{g}|y\right\rangle \left\langle x|f\right\rangle \, dx=\int_{0}^{1}U_{g}(x,y)f(x)\, dx=\int_{0}^{1}\delta\left(x-g(y)\right)f(x)\, dx\]

\end_inset 

 This gives the action of the Koopman operator in a coordinate-space representat
ion.
 As is the recurring theme, different representations can lead to different
 results.
 In the coordinate-space representation, the Koopman operator appears to
 be the transpose of the Frobenius-Perron operator, in that 
\begin_inset Formula $K(x,y)=U(y,x)$
\end_inset 

.
 However, in a general representation, whether the Koopman operator is the
 transpose or the complex conjugate or something else needs to be determined
 on a case-by-case basis, with an appeal to the particular operator 
\begin_inset Formula $g(x)$
\end_inset 

 and the representations on which it works.
 
\layout Subsection

Conjugate Maps
\layout Standard

Conjugation of the function that generates the map will provide, in general,
 another map that behaves exactly the same as the first, as long as the
 conjugating function is a diffeomorphism.
 That is, if 
\begin_inset Formula $\phi$
\end_inset 

is out conjugating function, then 
\begin_inset Formula \[
\gamma=\phi\circ g\circ\phi^{-1}\]

\end_inset 

 will iterate the same way that 
\begin_inset Formula $g$
\end_inset 

 does: 
\begin_inset Formula $\gamma^{n}=\phi\circ g^{n}\circ\phi^{-1}$
\end_inset 

, and we thus would expect that the Koopman and Frobenius-Perron operators
 for 
\begin_inset Formula $\gamma$
\end_inset 

 are conjugate to those for 
\begin_inset Formula $g$
\end_inset 

: 
\begin_inset Formula \[
U_{\gamma}=U_{\phi}^{-1}U_{g}U_{\phi}\]

\end_inset 


\layout Standard

XXX derive the above.
 Show that eigenvalues are preserved.
 
\layout Standard

In order to preserve the polynomial-rep eigenvalues, a diffeomorphism is
 required.
 Will show an example below of a homeomorphic but not diffeomorphic map
 that alters the polynomial-representation eigenvalues.
\layout Section

The Frobenius-Perron Operator of the Bernoulli Map
\layout Standard

The Bernoulli map is an exactly solvable example of deterministic chaos.
 This map is presented in 
\begin_inset LatexCommand \cite{key-10}

\end_inset 

 and a more thorough exposition of it is provided in 
\begin_inset LatexCommand \cite{key-2}

\end_inset 

.
 However, these authors seem to have missed or ignored certain key aspects
 of the operator, including the fact that the Hurwitz Zeta function is an
 eigenvector, as well as the action of the modular group 
\begin_inset Formula $SL(2,\mathbb{Z})$
\end_inset 

 as a symmetry group playing an important part in the analysis.
 Thus, we recap the results here, using simpler techniques, and then (making
 use of these simpler tools) extend the results in several directions.
 The motivation for the detailed development is, of course, that we will
 want to extend these tools to the GKW operator.
 
\layout Standard

The Bernoulli map is given by 
\begin_inset Formula \[
b(x)=2x-\left\lfloor 2x\right\rfloor \]

\end_inset 

 and can be thought of as popping the leading digit off of the binary expansion
 of 
\begin_inset Formula $x.$
\end_inset 

 This map has a positive Lyapunov exponent and is highly chaotic, as, in
 a certain sense, one can say that the digits of the binary expansion of
 some 'arbitrary' number are unpredictable, and that the orbits of two close-by
 numbers will eventually become 'uncorellated' (after suitably defining
 what we mean by 'arbitrary' and 'unpredictable').
 
\layout Standard

The Frobenius-Perron operator of the Bernoulli map is given by
\begin_inset Formula \[
\left[U_{B}f\right](x)=\frac{1}{2}\left[f\left(\frac{x}{2}\right)+f\left(\frac{x+1}{2}\right)\right]\]

\end_inset 

 
\layout Standard

Blah blah blah.
 How much more here do we want to say? 
\layout Subsection

The Polynomial Representation
\layout Standard

Well, Provide the matrix elements.
\layout Standard


\begin_inset Formula \[
\left[U_{B}\right]_{mk}\equiv U_{mk}\equiv\left\langle m\right|U\left|k\right\rangle =\frac{\delta_{mk}}{2^{m}}+\left(\begin{array}{c}
k\\
m\end{array}\right)\frac{\Theta_{mk}}{2^{k+1}}\]

\end_inset 

 where 
\begin_inset Formula $\left(\begin{array}{c}
m\\
k\end{array}\right)$
\end_inset 

 is the binomial coefficient, and 
\begin_inset Formula \[
\Theta_{mk}=\left\{ \begin{array}{c}
0\;\textrm{ if }\; k\leq m\\
1\;\textrm{ if }\; k>m\end{array}\right.\]

\end_inset 

 is a traceless, pure upper-triangular matrix.
 Thus, for the polynomial eigenstates, we can promptly read the eigenvalues
 off the diagonal; these eigenvalues are 
\begin_inset Formula $\lambda_{n}=2^{-n}$
\end_inset 

.
 Because the matrix is upper-triangular, it is easily solvable for both
 the left and right eigenvectors, which agree perfectly w/ Driebe
\begin_inset LatexCommand \cite{key-2}

\end_inset 

.
 Visually, the upper-left of this matrix looks like 
\begin_inset Formula \[
U_{mk}=\left[\begin{array}{cccccc}
1 & \frac{1}{4} & \frac{1}{8} & \frac{1}{16} & \frac{1}{32} & ...\\
0 & \frac{1}{2} & \frac{1}{4} & \frac{3}{16} & \frac{1}{8}\\
0 & 0 & \frac{1}{4} & \frac{3}{16} & \frac{3}{16}\\
0 & 0 & 0 & \frac{1}{8} & \frac{1}{8}\\
0 & 0 & 0 & 0 & \frac{1}{16}\\
... &  &  &  &  & ...\end{array}\right]\]

\end_inset 


\layout Standard

The right eigenvectors are denoted by 
\begin_inset Formula $\left|B_{n}\right\rangle $
\end_inset 

 and have the vector components 
\begin_inset Formula \[
\left\langle k|B_{n}\right\rangle =\left(\begin{array}{c}
n\\
k\end{array}\right)\left(1-\Theta_{n,k}\right)B_{n-k}=\left\{ \begin{array}{ccc}
\left(\begin{array}{c}
n\\
k\end{array}\right)B_{n-k} & \;\textrm{ for }\; & k\leq n\\
0 & \;\textrm{ for }\; & k>n\end{array}\right.\]

\end_inset 

 where 
\begin_inset Formula $B_{k}$
\end_inset 

 are the Bernoulli numbers.
 We can verify this by multiplying the eigenvector into the matrix: 
\begin_inset Formula \begin{eqnarray*}
\sum_{k=0}^{\infty}\left\langle m\right|U\left|k\right\rangle \left\langle k|B_{n}\right\rangle  & = & \sum_{k=m}^{n}\left[\frac{\delta_{mk}}{2^{m}}+\left(\begin{array}{c}
k\\
m\end{array}\right)\frac{\Theta_{mk}}{2^{k+1}}\right]\left(\begin{array}{c}
n\\
k\end{array}\right)B_{n-k}\\
 & = & \frac{1}{2^{m}}\left(\begin{array}{c}
n\\
m\end{array}\right)B_{n-m}+...non-trivial-taylor-expn\\
 & = & \lambda_{n}\left\langle m|B_{n}\right\rangle \end{eqnarray*}

\end_inset 

 In coordinate space, the right eigenvectors are the Bernoulli polynomials.
\layout Standard


\begin_inset Formula \[
\sum_{k=0}^{\infty}\left\langle x|k\right\rangle \left\langle k|B_{n}\right\rangle =\sum_{k=0}^{n}\left(\begin{array}{c}
n\\
k\end{array}\right)B_{n-k}x^{k}=B_{n}(x)\]

\end_inset 

 which we can verify explicitly by substituting into the function-operator
 form of the map:
\begin_inset Formula \begin{eqnarray*}
\left[U_{B}B_{n}\right](x) & = & \frac{1}{2}\left[B_{n}\left(\frac{x}{2}\right)+B_{n}\left(\frac{x+1}{2}\right)\right]\\
 & = & \lambda_{n}B_{n}(x)\end{eqnarray*}

\end_inset 

 The last identity follows from the 
\begin_inset Quotes eld
\end_inset 

multiplication formula
\begin_inset Quotes erd
\end_inset 

 for Bernoulli polynomials.
\layout Standard

The left eigenvectors are denoted by 
\begin_inset Formula $\left\langle \tilde{B}_{n}\right|$
\end_inset 

and, for 
\begin_inset Formula $n>0$
\end_inset 

, have the components 
\begin_inset Formula \[
\left\langle \tilde{B}_{n}|k\right\rangle =\left(\begin{array}{c}
k\\
n-1\end{array}\right)\frac{1}{n}\left(\delta_{nk}+\Theta_{nk}\right)\]

\end_inset 

 The zeroth left eigenvector is a special-case; it has components 
\begin_inset Formula $\left\langle \tilde{B}_{0}|k\right\rangle =1/(k+1)$
\end_inset 

.
 The left eigenvectors can also be written out in coordinate space: 
\begin_inset Formula \begin{eqnarray*}
\left\langle \tilde{B}_{n}|x\right\rangle  & = & \sum_{k=0}^{\infty}\left\langle \tilde{B}_{n}|k\right\rangle \left\langle k|x\right\rangle \\
 & = & \sum_{k=0}^{\infty}\left\langle \tilde{B}_{n}|k\right\rangle (-)^{k}\frac{\delta^{(k)}(x)}{k!}\\
 & = & \frac{1}{n}\sum_{k=n}^{\infty}\left(\begin{array}{c}
k\\
n-1\end{array}\right)(-)^{k}\frac{\delta^{(k)}(x)}{k!}\\
 & = & \frac{(-)^{n+1}}{n!}\left[\delta^{(n-1)}(1-x)-\delta^{(n-1)}(x)\right]\end{eqnarray*}

\end_inset 

 for the 
\begin_inset Formula $n>0$
\end_inset 

case.
 The 
\begin_inset Formula $n=0$
\end_inset 

 left eigenvector is best understood by integrating it over some arbitrary
 function 
\begin_inset Formula $f(x)$
\end_inset 

: 
\begin_inset Formula \begin{eqnarray*}
\int_{0}^{1}dx\,\left\langle \tilde{B}_{0}|x\right\rangle f(x) & = & \int_{0}^{1}dx\, f(x)\sum_{k=0}^{\infty}(-)^{k}\frac{\delta^{(k)}(x)}{(k+1)!}\\
 & = & \sum_{k=0}^{\infty}\frac{f^{(k)}(0)}{(k+1)!}\\
 & = & \sum_{k=0}^{\infty}\frac{f^{(k)}(0)}{k!}\int_{0}^{1}x^{k}dx\\
 & = & \int_{0}^{1}f(x)dx\\
 & = & \left\langle \tilde{B}_{0}|f\right\rangle \end{eqnarray*}

\end_inset 

 Its instructive to look at the other left eigenvectors acting on some function
 
\begin_inset Formula $f(x)$
\end_inset 

; these can be written as 
\begin_inset Formula \[
\left\langle \tilde{B}_{n}|f\right\rangle =\frac{1}{n!}\left[f^{(n-1)}(1)-f^{(n-1)}(0)\right]\]

\end_inset 

Note that the left eigenvectors are adjoint to the Bernoulli polynomials.
 Thus, the identity operator 
\begin_inset Formula $\mathbb{I}_{B}=\sum_{n=0}^{\infty}\left|B_{n}\right\rangle \left\langle \tilde{B}_{n}\right|$
\end_inset 

turns out to be the Euler-Maclaurin summation formula in disguise, which
 we can see more easily by writing 
\begin_inset Formula \begin{eqnarray*}
f(x) & = & \left\langle x|f\right\rangle \\
 & = & \sum_{m=0}^{M}B_{m}(x)\left\langle \tilde{B}_{m}|f\right\rangle -\frac{1}{M!}\int_{0}^{1}dy\, B_{M}(x-y)\; f^{(M)}(y)\end{eqnarray*}

\end_inset 

 Its not to hard to explicitly validate completeness: one finds that 
\begin_inset Formula \[
\left\langle j\left|\mathbb{I}_{B}\right|k\right\rangle =\left\langle j\right|\sum_{n=0}^{\infty}\left|B_{n}\right\rangle \left\langle \tilde{B}_{n}\right|\left|k\right\rangle =\delta_{jk}\]

\end_inset 

 One can also check orthogonality over coordinate space, and explicitly
 verify that 
\begin_inset Formula \[
\int_{0}^{1}dx\left\langle B_{n}|x\right\rangle \left\langle x|\tilde{B}_{m}\right\rangle =\frac{1}{m!}\int_{0}^{1}\frac{d^{m}}{dx^{m}}B_{n}(x)\, dx=\delta_{nm}\]

\end_inset 

Thus, in the polynomial representation, the Frobenius-Perron operator of
 the Bernoulli map is 
\begin_inset Formula \[
U_{B}=\sum_{n=0}^{\infty}\left|B_{n}\right\rangle \lambda_{n}\left\langle \tilde{B}_{n}\right|\]

\end_inset 

 We can make use of this diagonal form to easily compute formal expressions
 involving 
\begin_inset Formula $U_{B}$
\end_inset 

.
 Thus, for a function 
\begin_inset Formula $f(x)$
\end_inset 

 that is expressible as a polynomial series in 
\begin_inset Formula $x$
\end_inset 

, we can write the operator 
\begin_inset Formula \[
f\left(U_{B}\right)=\sum_{n=0}^{\infty}\left|B_{n}\right\rangle f\left(\lambda_{n}\right)\left\langle \tilde{B}_{n}\right|\]

\end_inset 

 whose matrix elements we can explicitly demonstrate in the monomial basis:
 
\begin_inset Formula \[
\left\langle j\left|f\left(U_{B}\right)\right|k\right\rangle =\sum_{j\leq n\leq k}\left(\begin{array}{c}
n\\
j\end{array}\right)\left(\begin{array}{c}
k\\
n-1\end{array}\right)\frac{B_{n-j}}{n}f\left(2^{-n}\right)\]

\end_inset 

 This allows us to write, for example, 
\begin_inset Formula $U_{B}=\exp(-H_{B})$
\end_inset 

 so that 
\begin_inset Formula $H_{B}=-\log U_{B}$
\end_inset 

 has matrix elements 
\begin_inset Formula \[
\left\langle j\left|H_{B}\right|k\right\rangle =\frac{\log(2)}{k+1}\left(\begin{array}{c}
k+1\\
j\end{array}\right)\sum_{m=0}^{k-j}\left(\begin{array}{c}
k-j+1\\
m\end{array}\right)(j+m)\, B_{m}\]

\end_inset 


\layout Subsection

Orthogonality
\layout Standard

The nature and meaning of 
\begin_inset Quotes eld
\end_inset 

vector space basis
\begin_inset Quotes erd
\end_inset 

 is perhaps a bit confusing in Hilbert Space.
 It is hard to discuss the notion of what an operator 
\begin_inset Quotes eld
\end_inset 

is
\begin_inset Quotes erd
\end_inset 

 without also discussing the basis at the same time.
 Removing this confusion takes mathematical techniques beyond the scope
 of this paper.
 In this section, we'll merely review some of the sources of confusion,
 and some of the notational devices that help minimize it.
 We begin by asking, 
\begin_inset Quotes eld
\end_inset 

what is the operator 
\begin_inset Formula $U_{B}$
\end_inset 

, really
\begin_inset Quotes erd
\end_inset 

? We saw above that the monomials form a complete set of basis states, and
 that we can call 
\begin_inset Formula $\mathbb{I}_{M}=\sum_{n=0}^{\infty}\left|n\right\rangle \left\langle n\right|$
\end_inset 

 the identity operator, where we use the subscript 
\begin_inset Formula $M$
\end_inset 

 to remind us that the identity operator is built from the monomial states.
 Thus, we can write 
\begin_inset Formula $U_{B}=\mathbb{I}_{M}U_{B}\mathbb{I}_{M}$
\end_inset 

 which expands to 
\begin_inset Formula \[
U_{B}=\sum_{m=0}^{\infty}\sum_{n=0}^{\infty}\left|m\right\rangle \left\langle m\left|U_{B}\right|n\right\rangle \left\langle n\right|\]

\end_inset 

 As we saw above, the matrix elements 
\begin_inset Formula $U_{mn}\equiv\left\langle m\left|U\right|n\right\rangle $
\end_inset 

 are upper-triangular, and so one wants to say that the operator 
\begin_inset Formula $U_{B}$
\end_inset 

 is clearly not Hermitian.
 And yet, we can use the same trick to write 
\begin_inset Formula $U_{B}=\mathbb{I}_{B}U_{B}\mathbb{I}_{B}$
\end_inset 

 to get matrix elements that are clearly non-zero only on the diagonal:
 
\begin_inset Formula $\left\langle B_{m}\left|U_{B}\right|\tilde{B}_{n}\right\rangle =\delta_{mn}\lambda_{n}$
\end_inset 

.
 Matrixes that are diagonal and have only real entries on the diagonal are
 clearly Hermitian, so this implies that 
\begin_inset Formula $U_{B}$
\end_inset 

 is Hermitian.
 So which is it? Is it Hermitian or not? Some of the confusion is due to
 the fact that the use of the operator notation carries hidden with it an
 implied choice of basis, and, so in the above, we have made an inadvertent
 change of basis, which is 
\begin_inset Quotes eld
\end_inset 

invisible
\begin_inset Quotes erd
\end_inset 

 when we write things like 
\begin_inset Formula $U_{B}=\mathbb{I}_{M}U_{B}\mathbb{I}_{M}$
\end_inset 

.
 Much of the confusion is due to the fact that in a Hilbert space, the concept
 of orthonormality violates the notions one gets from working with finite-dimens
ional basis.
 Lets show this change of basis explicitly.
 We write 
\begin_inset Formula \begin{eqnarray*}
U_{diagonal} & = & \sum_{j,k=0}^{\infty}\left|B_{j}\right\rangle \delta_{jk}\lambda_{k}\left\langle \tilde{B}_{k}\right|\\
 & = & \sum_{j,k,m,n=0}^{\infty}\left|B_{j}\right\rangle \left\langle \tilde{B}_{j}|m\right\rangle \left\langle m\left|U_{monomial}\right|n\right\rangle \left\langle n|B_{k}\right\rangle \left\langle \tilde{B}_{k}\right|\\
 & = & \tilde{B}\, U_{monomial}\, B\end{eqnarray*}

\end_inset 

 where the operators 
\begin_inset Formula $\tilde{B}$
\end_inset 

 and 
\begin_inset Formula $B$
\end_inset 

 show the change of basis: 
\begin_inset Formula \[
\tilde{B}=\sum_{j,m=0}^{\infty}\left|B_{j}\right\rangle \left\langle \tilde{B}_{j}|m\right\rangle \left\langle m\right|\]

\end_inset 

 and 
\begin_inset Formula \[
B=\sum_{k,n=0}^{\infty}\left|n\right\rangle \left\langle n|B_{k}\right\rangle \left\langle \tilde{B}_{k}\right|\]

\end_inset 

 It is not hard to work out that 
\begin_inset Formula $\tilde{B}B=\mathbb{I}_{B}$
\end_inset 

 and that 
\begin_inset Formula $B\tilde{B}=\mathbb{I}_{M}$
\end_inset 

 so that, in a certain sense 
\begin_inset Formula $\tilde{B}$
\end_inset 

 is both a left- and right-inverse of 
\begin_inset Formula $B$
\end_inset 

.
 However, 
\begin_inset Formula $B$
\end_inset 

 is not orthogonal in the traditional sense: we had demonstrated the matrix
 elements up above, and we clearly have 
\begin_inset Formula $\left\langle n|B_{k}\right\rangle \neq\left\langle \tilde{B}_{n}|k\right\rangle $
\end_inset 

.
 What makes this seem so strange is that both the monomial basis states
 
\begin_inset Formula $\left|n\right\rangle $
\end_inset 

 and the Bernoulli polynomial basis states 
\begin_inset Formula $\left|B_{j}\right\rangle $
\end_inset 

 are both complete and orthogonal.
 From experience working with finite-dimensional matrices, we are accustomed
 to believe that any change of basis between a set of ortho-normal basis
 states is given by a similarity matrix with is orthogonal.
 We see here that for infinite-dimensional spaces, that this is not the
 case.
 
\layout Standard

XXX I'm still troubled by this.
 Its not completely clear that the space spanned by the monomial basis is
 really identical to the space spanned by the Bernoulli polynomial basis.
 Either set of basis functions seems to be in a certain sense 
\begin_inset Quotes eld
\end_inset 

complete
\begin_inset Quotes erd
\end_inset 

, but we haven't truly proven the following: Thm: Consider a larger space
 of functions, for example, the space of square integrable functions.
 Then consider 
\begin_inset Formula $\mathbb{I}_{M}$
\end_inset 

 and 
\begin_inset Formula $\mathbb{I}_{B}$
\end_inset 

 as projection operators on this space.
 Then is the image of 
\begin_inset Formula $\mathbb{I}_{M}$
\end_inset 

 equal to image of 
\begin_inset Formula $\mathbb{I}_{B}$
\end_inset 

 when embedded in this larger space?
\layout Subsection

The Fourier Representation 
\layout Standard

The Koopman operator of the Bernoulli Map has the property of taking a function
 and making two copies of it.
 That is, 
\begin_inset Formula \begin{eqnarray*}
\left[K_{B}f\right](y) & = & \int_{0}^{1}\delta\left(x-b(y)\right)f(x)\, dx\\
 & = & f(b(y))\\
 & = & f(2y)\theta(1-2y)+f(2y-1)\theta(2y-1)\end{eqnarray*}

\end_inset 

 where 
\begin_inset Formula $\theta(x)$
\end_inset 

 is the step function, identically zero for 
\begin_inset Formula $x<0$
\end_inset 

 and identically one for 
\begin_inset Formula $x>0$
\end_inset 

.
 The Koopman operator for the Bernoulli map is not faithfully representable
 in the polynomial basis; this can be seen in two ways.
 First, it introduces a discontinuity at 
\begin_inset Formula $x=1/2$
\end_inset 

 which the polynomials cannot move beyond; the radius of the circle of converge
 is limited by this singularity.
 Secondly, it takes a function and more-or-less makes it periodic; again,
 the polynomials cannot cope directly with this.
 Thus, we are motivated to explore the Fourier representation, if only to
 express the Koopman operator.
 
\layout Standard

It turns out to be exceedingly simple to find this operator in the Fourier
 basis.
 If we write 
\begin_inset Formula \[
f(x)=\sum_{n}a_{n}\cos2\pi nx\;+b_{n}\sin2\pi nx\]

\end_inset 

 then 
\begin_inset Formula \[
\left[K_{B}f\right](x)=\sum_{n}a_{n}\cos4\pi nx\;+b_{n}\sin4\pi nx\]

\end_inset 

 or, in Dirac notation, 
\begin_inset Formula $\left\langle em|K_{B}|en\right\rangle =\delta_{2m,n}$
\end_inset 

.
 This is a very singular operator in this basis.
 Visually, it has the distinctive appearance of 
\begin_inset Formula \[
K_{B}=\left[\begin{array}{cccccc}
1 & 0 & 0 & 0 & 0 & ...\\
0 & 0 & 0 & 0 & ...\\
0 & 1 & 0 & 0\\
0 & 0 & 0 & 0\\
0 & 0 & 1 & 0 & ...\\
...\end{array}\right]\]

\end_inset 

 where every other row consists of zeros.
 In this same basis, 
\begin_inset Formula $U_{B}$
\end_inset 

is equally remarkable: it is literally the transpose: that is 
\begin_inset Formula $K_{B}=U_{B}^{T}$
\end_inset 

 in this basis, and so 
\begin_inset Formula \[
U_{B}=\left[\begin{array}{cccccc}
1 & 0 & 0 & 0 & 0 & ...\\
0 & 0 & 1 & 0 & 0\\
0 & 0 & 0 & 0 & 1\\
0 & 0 & 0 & 0 & 0\\
0 & 0 & 0 & 0 & ...\\
...\end{array}\right]\]

\end_inset 

 We can see that in this representation, we have 
\begin_inset Formula $U_{B}K_{B}=1$
\end_inset 

 but 
\begin_inset Formula $K_{B}U_{B}\neq1$
\end_inset 

, just as in the coordinate-space representation.
 It is very instructive to verify that the Bernoulli polynomials are still
 eigenfunctions in this representation.
 For 
\begin_inset Formula $n\neq0$
\end_inset 

, we have 
\begin_inset Formula \[
\int_{0}^{1}B_{1}(x)\,\sin(2\pi nx)\, dx=\frac{-1}{\pi n}\]

\end_inset 

 and it is straightforward to visually verify that 
\begin_inset Formula $U_{B}B_{1}=\frac{1}{2}B_{1}$
\end_inset 

.
 By working with the generator for the Bernoulli polynomials, 
\begin_inset Formula \[
\frac{te^{xt}}{e^{t}-1}=\sum_{n=0}^{\infty}B_{n}(x)\,\frac{t^{n}}{n!}\]

\end_inset 

 one can immediately find, for 
\begin_inset Formula $m\neq0$
\end_inset 

, the Fourier components 
\begin_inset Formula \[
\int_{0}^{1}B_{n}(x)\,\cos(2\pi mx)\, dx=\left\{ \begin{array}{cc}
0 & \;\textrm{ for n odd }\\
\left(-\right)^{1+n/2}n!/\left(2\pi m\right)^{n} & \;\textrm{ for n even }\end{array}\right.\]

\end_inset 

 and 
\begin_inset Formula \[
\int_{0}^{1}B_{n}(x)\,\sin(2\pi mx)\, dx=\left\{ \begin{array}{cc}
0 & \;\textrm{ for n even }\\
\left(-\right)^{(n+1)/2}n!/\left(2\pi m\right)^{n} & \;\textrm{ for n odd }\end{array}\right.\]

\end_inset 

 Applying the Fourier-representation 
\begin_inset Formula $U_{B}$
\end_inset 

 to these to these vector components makes it immediately clear how the
 eigenvalue of 
\begin_inset Formula $1/2^{n}$
\end_inset 

 is associated with the eigenvector 
\begin_inset Formula $B_{n}$
\end_inset 

.
 
\layout Subsection

The Hurwitz Zeta Eigenfunctions
\layout Standard

The Fourier representation also makes it clear that any vector with vector
 components 
\begin_inset Formula $a_{n}=1/n^{s}$
\end_inset 

 will be an eigenvector of 
\begin_inset Formula $U_{B}$
\end_inset 

 associated with the eigenvalue 
\begin_inset Formula $\lambda=1/2^{s}$
\end_inset 

.
 In coordinate space, we can write these eigenfunctions as 
\begin_inset Formula \[
\beta(x;s)=2\Gamma(s+1)\sum_{n=1}^{\infty}\frac{\exp(2\pi inx)}{\left(2\pi n\right)^{s}}\]

\end_inset 

 which transform as 
\begin_inset Formula $U_{B}\beta(x;s)=2^{-s}\beta(x;s)$
\end_inset 

.
 Given the nature of summation, we see that the series is strictly convergent
 for any complex-valued 
\begin_inset Formula $s$
\end_inset 

 with 
\begin_inset Formula $\Re s>1$
\end_inset 

.
 This series recreates the Bernoulli polynomials for integer values of 
\begin_inset Formula $n$
\end_inset 

, so for example, 
\begin_inset Formula $\Re\beta(x;2)=B_{2}(x)$
\end_inset 

 and 
\begin_inset Formula $\Im\beta(x;3)=B_{3}(x)$
\end_inset 

 and generally 
\begin_inset Formula $\Re\left[\left(-i\right)^{n}\beta(x;n)\right]=-B_{n}(x)$
\end_inset 

.
 Equivalently, the Fourier series for the Bernoulli Polynomials can be written
 as 
\begin_inset Formula \begin{eqnarray*}
B_{n}(x) & = & -\Gamma(s+1)\sum_{k=1}^{\infty}\frac{\exp(2\pi ikx)+\exp(2\pi ik(1-x))}{\left(2\pi ik\right)^{n}}\\
 & = & \frac{-(-i)^{n}}{2}\left(\beta(x;n)+\beta(1-x;n)\right)\end{eqnarray*}

\end_inset 

It turns out that these eigenfunctions are essentially a form of the Hurwitz
 Zeta function 
\begin_inset Formula \[
\zeta(s,x)=\sum_{n=0}^{\infty}\frac{1}{\left(n+x\right)^{s}}\]

\end_inset 

 and that, in fact, the Hurwitz Zeta itself is an eigenfunction, with eigenvalue
 
\begin_inset Formula $2^{s-1}$
\end_inset 

.
 We can confirm this by following a very old-fashioned recipe for obtaining
 the functional relation for a zeta-like sum.
 We start by expressing the gamma function as 
\begin_inset Formula \[
\int_{0}^{\infty}dy\, e^{-2\pi ny}y^{s-1}=\frac{\Gamma(s)}{(2\pi n)^{s}}\]

\end_inset 

 Substituting into the expression for 
\begin_inset Formula $\beta$
\end_inset 

 and performing the sum, we find we can write 
\begin_inset Formula \[
\beta(x;s)=2s\int_{0}^{\infty}dy\,\frac{y^{s-1}}{\exp\left(-2\pi i(x+iy)\right)-1}\]

\end_inset 

 Then, following a traditional trick [ref Edwards] we can re-write this
 as a contour integral 
\begin_inset Formula \[
\beta(x;s)=\frac{-is}{\sin\pi s}\oint\frac{(-y)^{s}}{\exp\left(-2\pi i(x+iy)\right)-1}\;\frac{dy}{y}\]

\end_inset 

 where the contour is taken to extend from 
\begin_inset Formula $+\infty+i\epsilon$
\end_inset 

, running just above the positive real axis, to the origin, circling the
 origin in a clockwise fashion, and returning to 
\begin_inset Formula $+\infty-i\epsilon$
\end_inset 

 just under the real axis.
 The contour essentially encloses the cut of the logarithm in the expression
 
\begin_inset Formula $(-y)^{s}=\exp s\,\log(-y)$
\end_inset 

.
 The old fashioned recipe calls for closing the contour at infinity (in
 a counter-clockwise direction) and then taking the dubious step of asserting
 Cauchy's Theorem to equate the integral around the cut to the sum of the
 poles, where we note that we have a pole whenever 
\begin_inset Formula $x+iy=n$
\end_inset 

 for some integer 
\begin_inset Formula $n$
\end_inset 

.
 By doing this we get the formal summation 
\begin_inset Formula \[
\frac{i\sin\pi s}{s}\beta(x;s)=\exp\left(\frac{i\pi s}{2}\right)\sum_{n=-\infty}^{\infty}(n-x)^{s-1}\]

\end_inset 

 We call this a formal sum, since the preceding steps required taking 
\begin_inset Formula $\Re s>1$
\end_inset 

 whereas now we need to take 
\begin_inset Formula $\Re s<0$
\end_inset 

.
 This is a bit of jiggery-pokery that is common for this type of presentation;
 and a very different set of tools is required to do better.
 So we proceed.
 We re-write this sum as 
\begin_inset Formula \[
\frac{i\sin\pi s}{s}\beta(x;s)=\exp\left(\frac{i\pi s}{2}\right)\left[\sum_{n=0}^{\infty}(n+(1-x))^{s-1}+e^{-i\pi(s-1)}\sum_{n=0}^{\infty}(n+x)^{s-1}\right]\]

\end_inset 

 where we were mindful to rotate counter-clockwise for 
\begin_inset Formula $n<0$
\end_inset 

 when replacing 
\begin_inset Formula $(-)^{n}$
\end_inset 

 by 
\begin_inset Formula $e^{-i\pi n}$
\end_inset 

 instead of the sloppy and incorrect 
\begin_inset Formula $e^{i\pi n}$
\end_inset 

.
 Recognizing the sums as the Hurwitz Zeta, this then gives us the desired
 result: 
\begin_inset Formula \[
\beta(x;s)=\frac{is}{\sin\pi s}\left[e^{-i\pi s/2}\zeta(1-s,x)-e^{i\pi s/2}\zeta(1-s,1-x)\right]\]

\end_inset 

 It is straightforward to invert this and solve for 
\begin_inset Formula $\zeta$
\end_inset 

; one gets 
\begin_inset Formula \[
\zeta(1-s,x)=\frac{1}{2s}\left[e^{-i\pi s/2}\beta(x;s)+e^{i\pi s/2}\beta(1-x;s)\right]\]

\end_inset 

 thus proving the assertion that the Hurwitz Zeta is an eigenfunction of
 the Bernoulli Operator, with eigenvalue 
\begin_inset Formula $2^{z-1}$
\end_inset 

.
 To verify the correctness of the above steps, we can expand the exponentials
 in terms of their real and imaginary parts, to find that 
\layout Standard


\begin_inset Formula \[
\zeta(z,x)=\frac{2\Gamma(1-z)}{\left(2\pi\right)^{1-z}}\left[\sin\left(\frac{\pi z}{2}\right)\sum_{n=1}^{\infty}\frac{\cos(2\pi nx)}{n^{1-z}}+\cos\left(\frac{\pi z}{2}\right)\sum_{n=1}^{\infty}\frac{\sin(2\pi nx)}{n^{1-z}}\right]\]

\end_inset 

 which agrees with standard textbook presentations of the Hurwitz Zeta.
 
\layout Subsection

Visualizing the Hurwitz Zeta Eigenfunctions
\layout Standard

Perhaps one surprising aspect of this result is that the Hurwitz Zeta eigenfunct
ions appear to be smooth, since one is conditioned to expect that the only
 continuous-spectrum eigenfunctions of a Frobenius-Perron operator are fractal.
 Thus, it is worthwhile to take a few minutes to get acquainted with the
 shape and nature of the zeta.
 This section shows a number of graphs, and discusses the analytic structure
 of the eigenvectors.
 We'll see that the eigenfunctions are 
\begin_inset Formula $C^{\infty}$
\end_inset 

 in 
\begin_inset Formula $x$
\end_inset 

 for almost all 
\begin_inset Formula $x$
\end_inset 

: everywhere except at the endpoints 
\begin_inset Formula $x=0,1$
\end_inset 

.
 Thus, these are not 
\begin_inset Quotes eld
\end_inset 

physical
\begin_inset Quotes erd
\end_inset 

 eigenstates, if 
\begin_inset Formula $C^{\infty}$
\end_inset 

 for all 
\begin_inset Formula $x$
\end_inset 

 is placed as a demand for being 
\begin_inset Quotes eld
\end_inset 

physical
\begin_inset Quotes erd
\end_inset 

.
 We also find that there are eigenfunctions that have eigenvalues greater
 than one; these, while quite smooth and differentiable, are not square-integrab
le: they are divergent at 
\begin_inset Formula $x=0,1$
\end_inset 

.
 However, in all other respects, the eigenfunctions are analytically well-behave
d, even if a bit 
\begin_inset Quotes eld
\end_inset 

lumpy
\begin_inset Quotes erd
\end_inset 

 and uneven.
 
\layout Standard

There is a countably infinite degeneracy of eigenfunctions for a give eigenvalue.
 We can see this by writing 
\begin_inset Formula $s=\sigma+i\tau$
\end_inset 

 in terms of its real and imaginary components.
 Then the eigenvalue is 
\begin_inset Formula $\lambda=2^{-s}=2^{-\sigma}\exp(-i\tau\ln2)$
\end_inset 

 and it belongs to a family of eigenvectors with 
\begin_inset Formula $\tau'=\tau+2\pi n/\ln2$
\end_inset 

 for 
\begin_inset Formula $n\in\mathbb{Z}$
\end_inset 

.
 The next five figures show some of these, graphed in various ways.
\layout Standard


\begin_inset Float figure
wide false
collapsed false

\layout Caption

Real Part of Symmetric Beta
\layout Standard


\begin_inset Graphics
	filename zeta-2.2345-04.png

\end_inset 


\layout Standard

This figure illustrates a family of eigenvectors 
\begin_inset Formula $\beta(x;s)$
\end_inset 

 having the same eigenvalue.
 To be precise, the illustration shows 
\begin_inset Formula \[
\Re\left[\beta(x;s)+\beta(-x;s)\right]/2\left|\Gamma(1+s)\right|\]

\end_inset 

 for values of 
\begin_inset Formula $s=\sigma+2\pi in/\ln2$
\end_inset 

 for 
\begin_inset Formula $\sigma=2.345$
\end_inset 

 and n=0,1,2,3,4.
 Note that 
\begin_inset Formula $\left|\Gamma(1+s)\right|$
\end_inset 

gets very small as n gets large, and so the normalization brings them to
 visually comparable values.
 Other real values of 
\begin_inset Formula $\sigma$
\end_inset 

 can be understood by recalling that 
\begin_inset Formula $\beta$
\end_inset 

 essentially interpolates between Bernoulli polynomials at integer values
 of 
\begin_inset Formula $\sigma$
\end_inset 

.
 In short, they'll all look more or less like this.
 
\layout Standard

XXX redo this graph to show 
\begin_inset Formula $\Re\left[\beta(x;s)+\beta(1-x;s)\right]/2\left|\Gamma(1+s)\right|$
\end_inset 

 instead XXX
\end_inset 


\layout Standard


\begin_inset Float figure
wide false
collapsed false

\layout Caption

Magnitude of Symmetric Beta
\layout Standard


\begin_inset Graphics
	filename zeta-abs-2.2345-04.png

\end_inset 


\layout Standard

This figure illustrates a family of eigenvectors 
\begin_inset Formula $\beta(x;s)$
\end_inset 

 having the same eigenvalue.
 To be precise, the illustration shows 
\begin_inset Formula \[
\left|\beta(x;s)+\beta(-x;s)\right|/2\left|\Gamma(1+s)\right|\]

\end_inset 

 for values of 
\begin_inset Formula $s=\sigma+2\pi in/\ln2$
\end_inset 

 for 
\begin_inset Formula $\sigma=2.345$
\end_inset 

 and n=0,1,2,3,4.
 Note that 
\begin_inset Formula $\left|\Gamma(1+s)\right|$
\end_inset 

gets very small as n gets large, and so the normalization brings them to
 visually comparable values.
 
\layout Standard

XXX redo this graph to show 
\begin_inset Formula $\left|\beta(x;s)+\beta(1-x;s)\right|/2\left|\Gamma(1+s)\right|$
\end_inset 

 instead XXX
\end_inset 


\layout Standard


\begin_inset Float figure
wide false
collapsed false

\layout Caption

Real part of Beta
\layout Standard


\begin_inset Graphics
	filename zeta-exp-2.2345-04.png

\end_inset 


\layout Standard

This figure illustrates a family of eigenvectors 
\begin_inset Formula $\beta(x;s)$
\end_inset 

 having the same eigenvalue.
 To be precise, the illustration shows 
\begin_inset Formula \[
\Re\beta(x;s)/2\left|\Gamma(1+s)\right|\]

\end_inset 

 for values of 
\begin_inset Formula $s=\sigma+2\pi in/\ln2$
\end_inset 

 for 
\begin_inset Formula $\sigma=2.345$
\end_inset 

 and n=0,1,2,3,4.
 Although these curves clearly look very lumpy, they are 
\begin_inset Formula $C^{\infty}$
\end_inset 

 for all 
\begin_inset Formula $x\in(0,1)$
\end_inset 

 but not at the endpoints 
\begin_inset Formula $x=0,1$
\end_inset 

.
 At the endpoints, the derivative becomes divergent after just a few derivatives
, where the curves are behaving essentially as 
\begin_inset Formula $x^{s-1}$
\end_inset 

 and 
\begin_inset Formula $(1-x)^{s-1}$
\end_inset 

.
 It is impossible to see this pending divergence in the graphs above, because,
 to the naked eye, a graph of, for example, 
\begin_inset Formula $x^{1.5}$
\end_inset 

 is nearly indistinguishable from a graph of 
\begin_inset Formula $x^{2}$
\end_inset 

.
 
\layout Standard

Although these curves appear to be sine-wave-like, it is perhaps more correct
 to think of them as being Bernoulli-polynomial-like.
 That is, to better understand what eigenvectors near some arbitrary value
 of 
\begin_inset Formula $s$
\end_inset 

 look like, its useful to think of what the polynomial 
\begin_inset Formula $B_{\left\lfloor \Re s\right\rfloor }(x)$
\end_inset 

 looks like.
 Recall, however, that, of course, 
\begin_inset Formula $B_{k}(x)$
\end_inset 

 for 
\begin_inset Formula $k\geq3$
\end_inset 

 is very sine-wave like! Note also that the first curve shown above, for
 
\begin_inset Formula $n=0$
\end_inset 

, generally resembles 
\begin_inset Formula $B_{2}(x)$
\end_inset 

 which is a parabola.
\end_inset 


\layout Standard


\begin_inset Float figure
wide false
collapsed false

\layout Caption

Magnitude of Beta 
\layout Standard


\begin_inset Graphics
	filename zeta-emag-2.2345-04.png

\end_inset 


\layout Standard

This figure illustrates a family of eigenvectors 
\begin_inset Formula $\beta(x;s)$
\end_inset 

 having the same eigenvalue.
 To be precise, the illustration shows 
\begin_inset Formula \[
\left|\beta(x;s)\right|/2\left|\Gamma(1+s)\right|\]

\end_inset 

 for values of 
\begin_inset Formula $s=\sigma+2\pi in/\ln2$
\end_inset 

 for 
\begin_inset Formula $\sigma=2.345$
\end_inset 

 and n=0,1,2,3,4.
 Note that curiously, these functions seem to be smoother for larger x and
 seem to have vanishing ripples as x approaches zero.
 Curiously, the ripples seem to have a period of oscillation of approximately
 
\begin_inset Formula $nx$
\end_inset 

, which can best be seen in the n=1 curve, which seems to hold a complete
 cycle between 1, 1/2, 1/4, 1/8, ...
\end_inset 


\layout Standard


\begin_inset Float figure
wide false
collapsed false

\layout Caption

Argument of Beta
\layout Standard


\begin_inset Graphics
	filename zeta-arg-2.2345-04.png

\end_inset 


\layout Standard

This figure illustrates a family of eigenvectors 
\begin_inset Formula $\beta(x;s)$
\end_inset 

 having the same eigenvalue.
 To be precise, the illustration shows 
\begin_inset Formula \[
\arg\beta(x;s)/2\left|\Gamma(1+s)\right|\]

\end_inset 

 for values of 
\begin_inset Formula $s=\sigma+2\pi in/\ln2$
\end_inset 

 for 
\begin_inset Formula $\sigma=2.345$
\end_inset 

 and n=0,1,2,3,4.
 
\end_inset 

 
\layout Standard

There are eigenfunctions with eigenvalues greater than one, essentially
 because the Hurwitz Zeta can be analytically continued to everywhere on
 the complex plane except for a simple pole at 
\begin_inset Formula $z=1$
\end_inset 

.
 Examining these eigenfunctions, one quickly discovers that these are not
 square-integrable: they have singularities located at 
\begin_inset Formula $x=0,1$
\end_inset 

.
 That is, for for 
\begin_inset Formula $\Re z>0$
\end_inset 

, the Hurwitz Zeta 
\begin_inset Formula $\zeta(z,x)$
\end_inset 

 has a clear singularity 
\begin_inset Formula $x^{-z}$
\end_inset 

 at 
\begin_inset Formula $x=0$
\end_inset 

.
 We remove this explicitly, and write 
\begin_inset Formula \begin{eqnarray*}
\frac{\sin\pi s}{is}\beta(x;s) & = & \frac{e^{-i\pi s/2}}{x^{1-s}}-\frac{e^{i\pi s/2}}{(1-x)^{1-s}}+\\
 &  & e^{-i\pi s/2}\left(\zeta(1-s,x)-x^{s-1}\right)-e^{i\pi s/2}\left(\zeta(1-s,1-x)-(1-x)^{s-1}\right)\end{eqnarray*}

\end_inset 

 The first part of the equation above encapsulates the singularities at
 
\begin_inset Formula $x=0,1$
\end_inset 

 that occur when working with eigenvalues 
\begin_inset Formula $\left|\lambda\right|=\left|2^{-s}\right|>1$
\end_inset 

, that is, with 
\begin_inset Formula $\Re s<0$
\end_inset 

.
 The remaining term is well-behaved and is shown in figure xx
\begin_inset LatexCommand \ref{cap:The-non-singular-part}

\end_inset 

xx.
 
\layout Standard


\begin_inset Float figure
wide false
collapsed false

\layout Caption


\begin_inset LatexCommand \label{cap:The-non-singular-part}

\end_inset 

The Non-Singular Part of the Divergent Eigenfunctions
\layout Standard


\begin_inset Graphics
	filename zeta-diverge.png

\end_inset 


\layout Standard

This figure shows 
\begin_inset Formula \[
\eta_{even}(x;\sigma)=\frac{\cos\pi\sigma/2}{\sigma}\left[\beta(x;\sigma)+\beta(1-x;\sigma)\right]-x^{\sigma-1}-(1-x)^{\sigma-1}\]

\end_inset 

 and 
\begin_inset Formula \[
\eta_{odd}(x;\sigma)=\frac{\sin\pi\sigma/2}{\sigma}\left[\beta(x;\sigma)-\beta(1-x;\sigma)\right]-x^{\sigma-1}+(1-x)^{\sigma-1}\]

\end_inset 

 for a value of 
\begin_inset Formula $\sigma=-3.3$
\end_inset 

, corresponding to an eigenvalue of 
\begin_inset Formula $9.85=2^{3.3}$
\end_inset 

.
 Except for the singularity, we see that the finite part of these eigenfunctions
 is very well behaved.
 
\end_inset 

 
\layout Standard

Note that when 
\begin_inset Formula $\left|\lambda\right|=\left|2^{-s}\right|<1/2$
\end_inset 

, that is, when 
\begin_inset Formula $\Re s>1$
\end_inset 

, there is no singularity, and 
\begin_inset Formula $\beta(x;s)$
\end_inset 

 is finite on the entire interval 
\begin_inset Formula $x\in[0,1]$
\end_inset 

 including the endpoints.
 For 
\begin_inset Formula $1/2<\Re s\leq1$
\end_inset 

 there is a bit of funny-business at the endpoints, that is, there is a
 weak divergence there, but the function overall remains square-integrable.
 Things break loose after that, with the exception of 
\begin_inset Formula $s=0$
\end_inset 

, where we have 
\begin_inset Formula $\beta(x;0)=-1$
\end_inset 

, a constant independent of 
\begin_inset Formula $x$
\end_inset 

.
 This essentially follows from the nature of differentiation on the Bernoulli
 polynomials, which we'll see below.
 Note, however, that for 
\begin_inset Formula $s$
\end_inset 

 near zero, the function 
\begin_inset Formula $\beta(x;s)$
\end_inset 

 has severe ringing artifacts in 
\begin_inset Formula $x$
\end_inset 

, suffering from a variation of Gibbs Phenomenon.
 
\layout Standard


\begin_inset Float figure
wide false
collapsed false

\layout Caption

Ringing
\layout Standard


\begin_inset Graphics
	filename zeta-gibbs.png

\end_inset 


\layout Standard

This figure shows ringing/Gibbs phenomenon as 
\begin_inset Formula $s$
\end_inset 

 approaches zero.
 In the limit of 
\begin_inset Formula $s=0$
\end_inset 

, we expect the real part of 
\begin_inset Formula $\beta$
\end_inset 

 to approach the trivial eigenfunction 
\begin_inset Formula $\lim_{s\rightarrow0^{+}}\Re\beta(x;s)=-B_{0}(x)=-1$
\end_inset 

.
 As this graph shows, the function is indeed trying very desperately to
 get flat, with not much success.
 The ringing occurs only at 
\begin_inset Formula $s=0$
\end_inset 

; there is no problem with convergence near larger integers, where 
\begin_inset Formula $\lim_{s\rightarrow n}\Re(-i)^{s}\beta(x;s)=-B_{n}(x)$
\end_inset 

 converges very smoothly and cleanly.
\end_inset 


\layout Standard

We conclude by noting that 
\begin_inset Formula $\beta$
\end_inset 

 is 
\begin_inset Formula $C^{\infty}$
\end_inset 

 for 
\begin_inset Formula $x\in(0,1)$
\end_inset 

 but not at the endpoints 
\begin_inset Formula $x=0,1$
\end_inset 

.
 This can be easily seen by writing the derivative 
\begin_inset Formula \[
\frac{d}{dx}\beta(x;s)=2\pi i\beta(x;s-1)\]

\end_inset 

 and so even if we start with 
\begin_inset Formula $\Re s>1$
\end_inset 

, each derivative carries us one step closer into the danger zone.
 
\layout Subsection

The Kernel
\layout Standard

What is the kernel of 
\begin_inset Formula $U_{B}$
\end_inset 

? It is the set of functions that have only odd Fourier terms.
 
\layout Standard

That is, for any integer 
\begin_inset Formula $k\in\mathbb{Z}$
\end_inset 

 we have 
\begin_inset Formula $U_{B}\cos2\pi(2k+1)x=0$
\end_inset 

 and so we write 
\begin_inset Formula $\cos2\pi(2k+1)x\in K\left[U_{B}\right]$
\end_inset 

 and likewise 
\begin_inset Formula $\sin2\pi(2k+1)x\in K\left[U_{B}\right]$
\end_inset 

.
 
\layout Standard

This implies that 'half' of all square-integrable functions are in the kernel.
 This is a huge space.
 The quotient space of the implied isomorphism thus has the Bernoulli polynomial
s as the representative elements.
 This is I think the correct way to relate coordinate space to the Hilbert
 space, is by means of the quotient space generated by the kernel of the
 time-evolution operator.
 
\layout Subsection

The Symmetry Group
\layout Standard

Note that 
\begin_inset Formula $\left[U_{B}f\right](x)=\frac{1}{2}\left(f(g_{D}(x))+f(r_{D}g_{D}r_{D}(x)\right)$
\end_inset 

 and so on.
\layout Subsection

The Takagi Representation 
\layout Standard

Note that the the iterated tent map behaves sort-of like a shift state,
 in that 
\begin_inset Formula \[
\left[U_{B}\tau^{k}\right](x)=\tau^{k-1}(x)\]

\end_inset 

 although it does not terminate properly for a shift state: 
\begin_inset Formula \[
\left[U_{B}\tau\right](x)=\frac{1}{2}\]

\end_inset 

 (a true shift state would vanish on the final iteration).
 Thus we see that the Takagi curve transforms as 
\begin_inset Formula \[
\left[U_{B}t_{w}\right](x)=\frac{1}{2}+wt_{w}(x)\]

\end_inset 

 under the Bernoulli operator.
 We can use this to build an eigenfunction 
\begin_inset Formula \[
b_{w}(x)=\frac{-1}{2(1-w)}+t_{w}(x)\]

\end_inset 

 so that 
\begin_inset Formula $U_{B}b_{w}=wb_{w}$
\end_inset 

.
 
\layout Standard

We can quickly obtain the other eigenvectors by starting with the Takagi
 curves that transform under the higher-dimensional representations of 
\begin_inset Formula $SL(2,\mathbb{Z})$
\end_inset 

.
 We do this by noting that we can write the Bernoulli transfer operator
 as 
\begin_inset Formula \[
\left[U_{B}f\right](x)=\frac{1}{2}\left(f(g_{D}(x))+f(r_{D}g_{D}r_{D}(x)\right)\]

\end_inset 

 so that if 
\begin_inset Formula $t_{n,w}(x)$
\end_inset 

 is a Takagi curve that transforms under the 
\begin_inset Formula $n$
\end_inset 

-dimensional representation, then 
\begin_inset Formula $U_{B}$
\end_inset 

 obviously is represented by 
\begin_inset Formula $(g_{n}+r_{n}g_{n}r_{n})/2$
\end_inset 

 where 
\begin_inset Formula $r_{n},g_{n}\in GL(n,\mathbb{R})$
\end_inset 

 are the generators of the 
\begin_inset Formula $n$
\end_inset 

-dimensional representation of 
\begin_inset Formula $SL(2,\mathbb{Z})$
\end_inset 

.
 As before, we have, up to conjugacy, only two representations, the even
 and odd-parity representations.
 
\layout Standard

XXX finish me ..
 The higher-dimensional Takagi Curves are given using the Bernoulli Poly's
 as the basis.
 What about (2k+1)x in the curves? 
\layout Subsection

The Continuous Fractal Spectrum
\layout Standard

An alternate set of eigenvectors with a continuous spectrum are given by
 
\begin_inset Formula \[
\phi_{z,k}(x)=\sum_{n=0}^{\infty}z^{n}\exp\left(2\pi i\;2^{n}\left(2k+1\right)x\right)\]

\end_inset 

 and have eigenvalue 
\begin_inset Formula $z$
\end_inset 

: that is 
\begin_inset Formula $[U_{B}\phi_{z,k}](x)=z\phi_{z,k}(x)$
\end_inset 

.
 Again, for a given fixed eigenvalue, they have a countably infinite degeneracy,
 labelled by the parameter 
\begin_inset Formula $k\in\mathbb{Z}$
\end_inset 

.
 These eigenfunctions are fractal, as can be readily seen from the graph[xxx
 need figure].
 Since they are a generalization of the Takagi-Landsberg Curve, they have
 an 
\begin_inset Formula $SL(2,\mathbb{Z})$
\end_inset 

 symmetry, as discussed in an earlier chapter.
 As is typical for fractals, these eigenfunctions are differentiable a finite
 number of times before they become differentiable nowhere.
 For example, for 
\begin_inset Formula $1/2<\left|z\right|<1$
\end_inset 

, these are continuous with respect to 
\begin_inset Formula $x$
\end_inset 

 but nowhere differentiable.
 For 
\begin_inset Formula $1/2^{m+1}<\left|z\right|<1/2^{m}$
\end_inset 

, these are everywhere 
\begin_inset Formula $m$
\end_inset 

 times differentiable with respect to 
\begin_inset Formula $x$
\end_inset 

, but nowhere 
\begin_inset Formula $m+1$
\end_inset 

 times differentiable.
 
\layout Standard

We can express these in terms of the Hurwitz Zeta eigenfunctions by considering
 the sum 
\begin_inset Formula \begin{eqnarray*}
\sum_{k=0}^{\infty}z^{\ln_{2}(2k+1)}\phi_{z,k}(x) & = & \sum_{n=1}^{\infty}z^{\ln_{2}n}\exp\left(2\pi inx\right)\\
 & = & \sum_{n=1}^{\infty}n^{\ln_{2}z}\exp\left(2\pi inx\right)\end{eqnarray*}

\end_inset 

 Thus, we see that we should equate 
\begin_inset Formula $s=-\ln_{2}z$
\end_inset 

 so that the eigenvalues are 
\begin_inset Formula $z=2^{-s}$
\end_inset 

.
 Multiplying by the appropriate factors, we get the desired relationship
 
\begin_inset Formula \[
\beta(x;s)=2\Gamma(s+1)\left(2\pi\right)^{-s}\sum_{k=0}^{\infty}\left(2k+1\right)^{-s}\phi_{z,k}(x)\]

\end_inset 

 That is, the Hurwitz zeta eigenfunctions are expressible as a linear combinatio
n of the fractal eigenfunctions.
 Essentially, either set of eigenfunctions can be used to form a set of
 basis states for the Bernoulli Map transfer operator.
 The Hurwitz Zeta eigenfunctions span a larger space than the fractal eigenfunct
ions, as the Hurwitz Zeta is well-defined for eigenvalues with 
\begin_inset Formula $\left|z\right|>1$
\end_inset 

, whereas the fractal eigenfunctions are not.
 Of course, as we saw above, the Hurwitz Zeta eigenfunctions are not square-inte
grable when 
\begin_inset Formula $\left|z\right|>1$
\end_inset 

, which invalidates their consideration for most 
\begin_inset Quotes eld
\end_inset 

physical
\begin_inset Quotes erd
\end_inset 

 uses.
 Note also that through careful work, the fractal eigenfunctions can probably
 be extended to 
\begin_inset Formula $\left|z\right|>1$
\end_inset 

 continuous-nowhere functions by considering their transformation properties
 under 
\begin_inset Formula $SL(2,\mathbb{Z})$
\end_inset 

.
 This would be in analogy to the exploration of the derivative of the Takagi
 Curve, which, as we saw in an earlier chapter, can be defined as the Cantor
 polynomial, built out of the digits of the binary expansion of 
\begin_inset Formula $x$
\end_inset 

.
 
\layout Standard

We can explicitly demonstrate the change of basis by defining 
\begin_inset Formula \[
\beta_{n}(x;s)\equiv\beta(x;s+2\pi ni/\ln2)\]

\end_inset 

 which all share the same eigenvalue: 
\begin_inset Formula $U_{B}\beta_{n}=2^{-s}\beta_{n}$
\end_inset 

.
 We can then restrict 
\begin_inset Formula $s$
\end_inset 

 to a principle domain 
\begin_inset Formula $-\pi<\Im s\,\ln2=\arg\, z<\pi$
\end_inset 

 .
 The change of basis can now be written explicitly as 
\begin_inset Formula \[
\beta_{n}(x;s)=\sum_{k=0}^{\infty}F_{nk}\phi_{z,k}(x)\]

\end_inset 

 where the matrix elements are 
\begin_inset Formula \[
F_{nk}=2\Gamma\left(s+1+\frac{2\pi ni}{\ln2}\right)\left(2\pi(2k+1)\right)^{-s}\exp\left[-2n\pi i\frac{\ln\pi(2k+1)}{\ln2}\right]\]

\end_inset 

 Presumably 
\begin_inset Formula $F$
\end_inset 

 is invertible; either set of eigenstates span the space.
 
\layout Standard

The modular group symmetries of the fractal eigenfunctions do not seem to
 provide any interesting insight into the zeta, since they do not mix or
 permute eigenstates.
 For example, applying the generator 
\begin_inset Formula $g$
\end_inset 

 on the fractal eigenstates gives
\begin_inset Formula \[
g\phi_{zk}(x)=\phi_{zk}\left(\frac{x}{2}\right)=\exp((2k+1)\pi ix)+z\phi_{zk}(x)\]

\end_inset 

 and so one might hope that since the zetas are a linear combination of
 the fractal eigenfunctions, one might get some new insight.
 However, doing this gives the sum 
\layout Standard


\begin_inset Formula \[
g\beta(x;s)=\beta(\frac{x}{2};s)=\frac{2\Gamma(s+1)}{(2\pi)^{s}}\sum_{k=0}^{\infty}\frac{\exp2\pi ix(2k+1)}{(2k+1)^{s}}+2^{-s}\beta(x;s)\]

\end_inset 

 as a symmetry, but the evaluation of the sum in the middle yields 
\begin_inset Formula $\beta(x/2;s)-2^{-s}\beta(x;s)$
\end_inset 

 and so one gets a trivial relationship and no insight in particular.
\layout Standard

By contrast ....
 mix up k's, n's, ...
 xxx finish me.
 
\layout Subsection

Misc Junk
\layout Standard

Delete these paragraphs.
\layout Standard

These are prototype forms for and the famous and beautiful Levy Dragons
 (reference the Paul Levy 1938 paper here) (actually Levy was trying to
 generalize the Koch curves).
 
\layout Standard

Note that when we go to look at the tessellation of the hyperbolic plane
 by the hyperbolic triangle under the symmetry of the modular group, I think
 we get the tessellation of the plane with Levy's Dragons, which I think
 is the point that Paul Levy was trying to make.
 So this fits all very nicely: we have a direct 1-1 correspondence between
 tessellations on the hyperplane with tessellations of real space by fractal
 curves.
 It is sufficient to talk about one to talk about the other.
\layout Standard

This also means that Bernoulli map also makes for a good toy example of
 quantum chaos.
 In quantum chaos, the eigenfunctions must form a complete set in the sense
 that for any given point in space, there must exist at least one eigenfunction
 that is non-vanishing on that point.
 In other words, the eigenfunctions of a quantum-chaotic system must tessellate
 the space in which they live.
 The toy example of this kind of tessellation is the Levy Dragon.
 
\layout Section

The Gauss-Kuzmin-Wirsing Operator
\layout Standard

The map that truncates continued fractions is 
\begin_inset Formula \[
h(x)=\frac{1}{x}-\left\lfloor \frac{1}{x}\right\rfloor \]

\end_inset 

 and is sometimes called the Gauss Map.
 It is connected to the Riemann Zeta by a Mellin Transform:
\begin_inset Formula \[
\zeta(s)=\frac{1}{s-1}-s\int_{0}^{1}h(x)\, x^{s-1}dx\]

\end_inset 

The Frobenius-Perron operator for this map is known as the Gauss-Kuzmin-Wirsing
 (GKW) Operator, and is represented by.
 
\layout Standard


\begin_inset Formula \[
\left[U_{h}f\right](x)=\sum_{n=1}^{\infty}\frac{1}{(n+x)^{2}}f\left(\frac{1}{n+x}\right)\]

\end_inset 

 Thus, the Riemann zeta can be written under a change of variable as
\begin_inset Formula \[
\zeta(s)=\frac{s}{s-1}-s\int_{0}^{1}dx\; x\left[U_{h}x^{s-1}\right]\]

\end_inset 

 and thus it seems that a better understanding of GKW may shed light on
 the Riemann Hypothesis.
 There is one known eigenvector, 
\begin_inset Formula $f(x)=1/(1+x)$
\end_inset 

 which corresponds to the unit eigenvalue.
 The others do not seem to be (by combinatorial search) any simple combination
 or summation of simple functions, including the digamma, and etc.
 XXX Provide the details.
 
\layout Standard

Todo:Blah Blah.
 Give the collection of interesting summations.
 Give the Riemann Hypothesis as a vector equation.
 
\layout Subsection

Assorted Algebraic Identities
\layout Standard

This section lists an assortment of random algebraic results, none particularly
 deep or interesting.
 These are listed here mostly for the sake of completeness.
 First, we notice that adjacent terms in the series can be made to cancel
 by shifting the series by one:
\layout Standard


\begin_inset Formula \[
\left[U_{h}f\right](x)-\left[U_{h}f\right](x+1)=\frac{1}{(1+x)^{2}}f\left(\frac{1}{1+x}\right)\]

\end_inset 

 which holds for any function 
\begin_inset Formula $f(x).$
\end_inset 

 Thus, if 
\begin_inset Formula $\rho(x)$
\end_inset 

 is an eigenvector, so that 
\begin_inset Formula $U_{h}\rho=\lambda\rho$
\end_inset 

, then it would also solve 
\begin_inset Formula \[
\frac{1}{(1+x)^{2}}\rho\left(\frac{1}{1+x}\right)=\lambda\left(\rho(x)-\rho(+1)\right)\]

\end_inset 

This can be solved easily to get the zeroth eigenvector 
\begin_inset Formula \[
\rho_{0}(x)=\frac{1}{\ln2}\;\frac{1}{1+x}\]

\end_inset 

 which satisfies 
\begin_inset Formula $[U_{h}\rho_{0}](x)=\rho_{0}(x)$
\end_inset 

 and the normalization is given by requiring 
\begin_inset Formula \[
\int_{0}^{1}\rho_{0}(x)\, dx=1\]

\end_inset 

 We can see one hint of the relationship between period-doubling and the
 GKW in the identity 
\begin_inset Formula \[
\frac{1}{1+x}=\sum_{n=1}^{\infty}\,\frac{1}{2^{n}}\left[\frac{2}{x+n}-\frac{1}{x+n+1}\right]\]

\end_inset 


\layout Standard

A reflection identity: 
\begin_inset Formula $f(x)=1-(1+x)^{-2}$
\end_inset 

 satisfies 
\begin_inset Formula $U_{h}f=1-f$
\end_inset 

.
\layout Standard

Another: 
\begin_inset Formula $U_{h}[(1+?(x))/(1+x)^{2}]=1-?(x)$
\end_inset 

 where 
\begin_inset Formula $?(x)$
\end_inset 

 is the Minkowski Question Mark function.
\layout Standard

Another: 
\begin_inset Formula $U_{h}[?(x)\, x^{-2}]=2-?(x)$
\end_inset 

 .
 One can construct a variety of identities of this sort, for example: 
\begin_inset Formula \[
U_{h}\left[?(x)\left(\frac{1}{(1+x)^{2}}-2\right)\right]=\frac{?(x)-2}{(1+x)^{2}}\]

\end_inset 

 but these types of exercises do not seem to lead to any sort of worthwhile
 recurrence relations.
 
\layout Standard

Acting on the monomial, one gets 
\begin_inset Formula \[
\left[U_{h}x^{k}\right](x)=\sum_{n=1}^{\infty}\,\frac{1}{(n+x)^{k+2}}=\frac{(-)^{k+2}}{(k+1)!}\psi^{(k+1)}(1+x)\]

\end_inset 

 where 
\begin_inset Formula $\psi^{(k)}(x)$
\end_inset 

 is the 
\begin_inset Formula $k$
\end_inset 

'th derivative of the Gamma function.
 The true difficulty of finding the solution to GKW becomes clear when the
 search leads one to start discovering complicated identities, such as 
\begin_inset Formula \[
\sum_{m=1}^{\infty}\,\frac{1}{m^{2}}\psi^{(1)}\left(1+\frac{1}{m}+x\right)=\sum_{n=1}^{\infty}\,\frac{1}{(n+x)^{2}}\psi^{(1)}\left(\frac{1}{n+x}+1\right)\]

\end_inset 

 or curiosities such as 
\begin_inset Formula $f(x)=(1+ax)^{2}$
\end_inset 

 gives 
\begin_inset Formula $U_{h}f=\psi^{(1)}(1+x+a)$
\end_inset 

.
 
\layout Standard

For 
\begin_inset Formula $f(x)=(1+nx)^{-2}-1$
\end_inset 

 one gets 
\begin_inset Formula $U_{h}f=-\sum_{k=1}^{n}(x+k)^{-2}$
\end_inset 


\layout Standard

Acting on a general power, the map gives the Hurwitz Zeta: 
\begin_inset Formula \[
\left[U_{h}x^{s}\right](x)=\sum_{n=1}^{\infty}\,\frac{1}{(n+x)^{s+2}}=\zeta(s+2,x+1)\]

\end_inset 

 and this transformation gives us another hint of a deep relationship to
 the Bernoulli Map.
\layout Standard

We have some conditionally convergent series: 
\begin_inset Formula \[
\sum_{k=0}^{\infty}\,(-)^{k}\,\left(\begin{array}{c}
k+m+1\\
m\end{array}\right)\zeta(k+m+2)=1\]

\end_inset 

 which holds for any integer 
\begin_inset Formula $m$
\end_inset 

.
 We also have series such as 
\begin_inset Formula \[
\lim_{t\rightarrow0}\sum_{k=0}^{\infty}\,(-)^{k}e^{-tk}=\frac{1}{2}\]

\end_inset 

 
\begin_inset Formula \[
\lim_{t\rightarrow0}\sum_{k=0}^{\infty}\,(-)^{k}(k+2)e^{-tk}=\frac{3}{4}\]

\end_inset 

 
\begin_inset Formula \[
\lim_{t\rightarrow0}\sum_{k=0}^{\infty}\,(-)^{k}(k+2)(k+3)e^{-tk}=\frac{7}{4}\]

\end_inset 

 
\begin_inset Formula \[
\lim_{t\rightarrow0}\sum_{k=0}^{\infty}\,(-)^{k}(k+2)(k+3)(k+4)e^{-tk}=\frac{45}{8}\]

\end_inset 

 
\begin_inset Formula \[
\lim_{t\rightarrow0}\sum_{k=0}^{\infty}\,(-)^{k}(k+2)(k+3)(k+4)(k+5)e^{-tk}=\frac{93}{4}\]

\end_inset 

 Its not clear what the general expression for forms of the above type is.
 Similarly, if we let 
\begin_inset Formula \[
S_{m}\equiv\lim_{t\rightarrow0}\sum_{k=0}^{\infty}\,(-)^{k}\frac{(k+m+1)!}{(k+1)!}\left[\zeta(k+m+2)-1\right]e^{-tk}\]

\end_inset 

 then we find 
\begin_inset Formula $S_{0}=1/2$
\end_inset 

, 
\begin_inset Formula $S_{1}=1/4$
\end_inset 

, 
\begin_inset Formula $S_{2}=1/4$
\end_inset 

, 
\begin_inset Formula $S_{3}=3/8$
\end_inset 

 and 
\begin_inset Formula $S_{4}=3/4$
\end_inset 

 but its again not clear what the general expression might be.
 The above sums are generated by considering 
\begin_inset Formula \[
\psi(1+z)=\frac{-1}{1+z}+1-\gamma+\sum_{m=0}^{\infty}(-)^{m}\left[\zeta(m+2)-1\right]z^{m+1}\]

\end_inset 

 and then writing 
\begin_inset Formula $z^{m+1}=(z+1-1)^{m+1}=\sum_{k=0}^{m}(-)^{m-k}\left(\begin{array}{c}
m\\
k\end{array}\right)(z+1)^{k}$
\end_inset 


\layout Subsection

Numeric Attacks
\layout Standard

One can mount numeric attacks on GKW.
 One can find, for instance, that 
\begin_inset Formula \[
\rho_{1}(x)\approx\frac{-3}{4}+\frac{7}{4}\frac{1}{(1+x)^{5/2}}\]

\end_inset 

 is accurate to about one or two percent over the domain 
\begin_inset Formula $x\in[0,1]$
\end_inset 

.
 It is associated with an eigenvalue 
\begin_inset Formula $\lambda_{1}\approx0.3025$
\end_inset 


\layout Subsection

Polynomial Representation
\layout Standard

One can attempt to solve GKW by working in the polynomial representation.
 One possible choice is to make one's Taylor expansion about 
\begin_inset Formula $x=0$
\end_inset 

, but this turns out to be a very poor choice, as we shall soon see.
 Thus, if we write 
\begin_inset Formula $U_{h}f=g$
\end_inset 

 and substitute a Taylor's expansion for 
\begin_inset Formula $f$
\end_inset 

 and 
\begin_inset Formula $g$
\end_inset 

, we get 
\begin_inset Formula \[
\frac{g^{(m)}(0)}{m!}=\sum_{k=0}^{\infty}\frac{f^{(k)}(0)}{k!}\,(-)^{m}\;\frac{(k+m+1)!}{m!\,(k+1)!}\,\zeta(k+m+2)\]

\end_inset 

 or, adopting the bra-ket notation introduced earlier, we have 
\begin_inset Formula \[
\left\langle m\left|U_{h}\right|k\right\rangle =(-)^{m}\;\left(\begin{array}{c}
k+m+1\\
m\end{array}\right)\,\zeta(k+m+2)\]

\end_inset 

 where we've replaced the factorials by the binomial coefficient that they
 form.
 Unfortunately, this is clearly a very poorly conditioned matrix.
 One can make some progress, if one wishes, by applying a regulator and
 using Levin-type sequence acceleration techniques.
 One can thus find a number of curious identities, some of which we've listed
 previously.
 However, the difficulty of working with divergent sums seems to outweigh
 any advantages given by the relatively simple form of the matrix elements.
 Thus, we are lead to consider the matrix elements for a polynomial expansion
 about 
\begin_inset Formula $x=1$
\end_inset 

.
 These are far more complex, but give a very well-conditioned matrix.
 These are: 
\begin_inset Formula \[
G_{mn}=\sum_{k=0}^{n}(-)^{k}\left(\begin{array}{c}
n\\
k\end{array}\right)\left(\begin{array}{c}
k+m+1\\
m\end{array}\right)\,\left[\zeta(k+m+2)-1\right]\]

\end_inset 

 satisfying 
\begin_inset Formula \[
(-)^{m}\frac{g^{(m)}(1)}{m!}=\sum_{n=0}^{\infty}G_{mn}(-)^{n}\frac{f^{(n)}(1)}{n!}\]

\end_inset 

 Other authors have chosen to expand about 
\begin_inset Formula $x=1/2$
\end_inset 

 [need ref here] but as can be seen the above is a more tractable expression.
 (copy the x=1/2 expansion here).
 Inserting this into the integral expression for the Riemann Zeta gives
 
\begin_inset Formula \[
\zeta(s)=\frac{s}{s-1}-s\sum_{m=0}^{\infty}\sum_{n=0}^{\infty}\frac{G_{mn}(-)^{n}}{(m+1)(m+2)}\left(\begin{array}{c}
s-1\\
n\end{array}\right)\]

\end_inset 

 We evaluate this expression in the next section..
\layout Subsection

The Riemann Zeta and Stieltjes Constants
\layout Standard

Let us then do each sum bit by bit.
 Using 
\begin_inset Formula $t_{n}$
\end_inset 

to denote the intermediate sum, 
\begin_inset Formula \[
\zeta(s)=\frac{s}{s-1}-s\sum_{n=0}^{\infty}(-)^{n}\left(\begin{array}{c}
s-1\\
n\end{array}\right)t_{n}\]

\end_inset 

 one gets 
\begin_inset Formula \begin{eqnarray*}
t_{n} & = & \sum_{m=0}^{\infty}\frac{G_{mn}}{(m+1)(m+2)}\\
 & = & 1-\gamma+\sum_{k=1}^{n}(-)^{k}\left(\begin{array}{c}
n\\
k\end{array}\right)\left[\frac{1}{k}+\frac{\zeta(k+1)}{k+1}\right]\end{eqnarray*}

\end_inset 

 where 
\begin_inset Formula $\gamma=0.577...$
\end_inset 

 is the Euler-Mascheroni Constant.
 We note that for large 
\begin_inset Formula $n$
\end_inset 

, 
\begin_inset Formula $t_{n}\rightarrow1/2(n+1)$
\end_inset 

 motivating us to define 
\begin_inset Formula $a_{n}=t_{n}-1/2(n+1)$
\end_inset 

 so that 
\begin_inset Formula \[
\zeta(s)=\frac{s}{s-1}-\frac{1}{2}-s\sum_{n=0}^{\infty}(-)^{n}\left(\begin{array}{c}
s-1\\
n\end{array}\right)a_{n}\]

\end_inset 

 If we write the binomial coefficient as 
\begin_inset Formula $\left(\begin{array}{c}
s-1\\
n\end{array}\right)=(s-1)_{n}/n!$
\end_inset 

 where 
\begin_inset Formula $(x)_{n}$
\end_inset 

 is the falling Pochammer symbol, we see that the 
\begin_inset Formula $a_{n}$
\end_inset 

 play the analogue of the Stieltjes constants for this kind of Umbral, 
\begin_inset Quotes eld
\end_inset 

divided differences
\begin_inset Quotes erd
\end_inset 

 type equation.
 The 
\begin_inset Formula $a_{n}$
\end_inset 

 are small and seem to be bounded and oscillatory.
 We have 
\begin_inset Formula $a_{0}=0.5-\gamma$
\end_inset 

 and the next few are approximately equal to 
\layout Standard


\begin_inset  Tabular
<lyxtabular version="3" rows="9" columns="2">
<features>
<column alignment="center" valignment="top" leftline="true" width="0">
<column alignment="center" valignment="top" leftline="true" rightline="true" width="0">
<row topline="true" bottomline="true">
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard


\begin_inset Formula $n$
\end_inset 


\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\layout Standard


\begin_inset Formula $a_{n}$
\end_inset 


\end_inset 
</cell>
</row>
<row topline="true">
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard

0
\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\layout Standard

-0.0772156...
\end_inset 
</cell>
</row>
<row topline="true">
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard

1
\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\layout Standard

-0.00474863...
\end_inset 
</cell>
</row>
<row topline="true">
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard

2
\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\layout Standard

0.00036610...
\end_inset 
</cell>
</row>
<row topline="true">
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard

3
\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\layout Standard

0.00037601...
\end_inset 
</cell>
</row>
<row topline="true">
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard

4
\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\layout Standard

0.00014301...
\end_inset 
</cell>
</row>
<row topline="true">
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard

5
\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\layout Standard

3.399...e-5
\end_inset 
</cell>
</row>
<row topline="true">
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard

6
\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\layout Standard

-4.832...e-7
\end_inset 
</cell>
</row>
<row topline="true" bottomline="true">
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\layout Standard

7
\end_inset 
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\layout Standard

-6.778..e-6
\end_inset 
</cell>
</row>
</lyxtabular>

\end_inset 

 
\layout Standard

Numerically, it appears that 
\begin_inset Formula $\left|a_{n}\right|\lesssim\exp\left(-4\sqrt{n+1}\right)$
\end_inset 

 at least for 
\begin_inset Formula $n\leq40$
\end_inset 

.
 The 
\begin_inset Formula $a_{n}$
\end_inset 

appear naturally in the Taylor's expansion for the Gamma function, and so
 one finds 
\begin_inset Formula \[
\sum_{n=0}^{\infty}a_{n}z^{n}=\frac{1}{1-z}+\frac{\ln(1-z)}{z}\left(\frac{1}{1-z}-\frac{1}{2}\right)+\frac{1}{2}\ln\Gamma\left(\frac{1}{1-z}\right)\]

\end_inset 

 Some curious values for this sum are 
\begin_inset Formula \[
\sum_{n=0}^{\infty}a_{n}=\ln\sqrt{2\pi}-1=-0.081061467...\]

\end_inset 

 and 
\begin_inset Formula \[
\sum_{n=0}^{\infty}a_{n}2^{-n}=2-3\ln2=-0.079441542...\]

\end_inset 

 Its equally curious that the other variation on the expression is even
 more trivial, namely 
\begin_inset Formula \[
\sum_{n=0}^{\infty}(-)^{n}\left(\begin{array}{c}
s-1\\
n\end{array}\right)x^{n}=\sum_{n=0}^{\infty}(-)^{n}(s-1)_{n}\,\frac{x^{n}}{n!}=\left(1-x\right)^{s-1}\]

\end_inset 

 where 
\begin_inset Formula $(s)_{n}=s(s-1)(s-2)...(s-n+1)$
\end_inset 

 is the falling factorial.
 One is left to wonder what the function 
\begin_inset Formula \[
\mu(s;x)=\frac{s}{s-1}-\frac{1}{2}-s\sum_{n=0}^{\infty}(-)^{n}\left(\begin{array}{c}
s-1\\
n\end{array}\right)a_{n}x^{n}\]

\end_inset 

 might be like; it is presumably related to the Polylogarithm (Jonquiere's
 function) XXXX Do the scratching needed to get the relationship nailed
 down.
 Ugh.
 The general idea of replacing power series by series in rising or falling
 Pochammer symbols and then exploring the curious relationships that result
 is referred to as Umbral Calculus; it seems that a number of interesting
 relationships can be obtained in this way.
\layout Standard


\begin_inset Float figure
wide false
collapsed false

\layout Caption

Graph of the first few values of 
\begin_inset Formula $a_{n}$
\end_inset 


\layout Standard


\begin_inset Graphics
	filename asubn.png

\end_inset 


\layout Standard

This figure shows a graph of the first 40 values of 
\begin_inset Formula $a_{n}$
\end_inset 

 normalized by a factor of 
\begin_inset Formula $\exp-4\sqrt{n+1}$
\end_inset 

.
 The first value, 
\begin_inset Formula $a_{0}$
\end_inset 

, is omitted on this graph; it would have a value of about -4.0.
 XXX todo graph the first 500 terms.
 
\end_inset 


\layout Standard

The 
\begin_inset Formula $a_{n}$
\end_inset 

 are can be used to express the Stieltjes constants and vice-versa by re-express
ing the binomial coefficient with a power series, making use of Stirling
 Numbers.
 That is, we write 
\begin_inset Formula \[
\left(\begin{array}{c}
s-1\\
n\end{array}\right)=\frac{(s-1)_{n}}{n!}=\frac{1}{n!}\sum_{k=0}^{n}\left[\begin{array}{c}
n\\
k\end{array}\right](s-1)^{k}\]

\end_inset 

 where 
\begin_inset Formula $\left[\begin{array}{c}
n\\
k\end{array}\right]$
\end_inset 

 is the Stirling Number of the First Kind.
 Substituting in the above, and comparing to the standard definition of
 the Stieltjes constants 
\begin_inset Formula \[
\zeta(s)=\frac{1}{s-1}+\sum_{n=0}^{\infty}\frac{(-)^{n}}{n!}\gamma_{n}(s-1)^{n}\]

\end_inset 

 shows that 
\begin_inset Formula $\gamma_{0}=1/2-a_{0}=\gamma$
\end_inset 

 and 
\begin_inset Formula \[
\gamma_{k}=-ka_{k-1}+(-)^{k}k!\,\sum_{n=k}^{\infty}(-)^{n}\frac{a_{n}}{n!}\left(\left[\begin{array}{c}
n\\
k\end{array}\right]+\left[\begin{array}{c}
n\\
k-1\end{array}\right]\right)\]

\end_inset 

 Note that the Stirling Numbers can be written as a sum over a product of
 harmonic numbers.
 That is,
\begin_inset Formula \[
\left[\begin{array}{c}
n\\
k\end{array}\right]=(-)^{k-n}\frac{(n-1)!}{(k-1)!}w(n,k-1)\]

\end_inset 

 where 
\begin_inset Formula $w(n,0)=1$
\end_inset 

 and 
\begin_inset Formula \[
w(n,k)=\sum_{m=0}^{k-1}\frac{\Gamma(1-k+m)}{\Gamma(1-k)}H_{n-1}^{(m+1)}w(n,k-1-m)\]

\end_inset 

 and the Harmonic numbers 
\begin_inset Formula $H_{n}^{(m)}$
\end_inset 

 are given by 
\begin_inset Formula \[
H_{n}^{(m)}=\sum_{k=1}^{n}\frac{1}{k^{m}}\]

\end_inset 

 This finally allows us to write 
\begin_inset Formula \[
\gamma_{k}=-ka_{k}+k\sum_{n=k}^{\infty}\frac{a_{n}}{n}\left(w(n,k-1)-(k-1)w(n,k-2)\right)\]

\end_inset 

and so the factorial factors cancel, leaving only the sum over the crazy
 product of harmonics.
 XXX todo show some of the values of w, esp.
 along the diagonal.
 XXX
\layout Standard

While on the topic of Umbral relations, one also has the curious function
 
\begin_inset Formula \[
Q(z)=\sum_{n=0}^{\infty}\left(\begin{array}{c}
n+1\\
z-1\end{array}\right)\left[\zeta(n+2)-1\right]\]

\end_inset 

 which has the curious properties that 
\begin_inset Formula $Q(n)=\zeta(n)$
\end_inset 

 for all integers 
\begin_inset Formula $n\geq2$
\end_inset 

.
 The pole is absent: 
\begin_inset Formula $Q(1)=1$
\end_inset 

 and 
\begin_inset Formula $Q(n)=0\;\forall\textrm{integers }n\leq0$
\end_inset 

.
 The analytic structure of 
\begin_inset Formula $Q(z)$
\end_inset 

 is unclear.
\layout Subsection

The Kernel
\layout Standard

We would like to know what the kernel of the GKW operator is.
 Consider 
\begin_inset Formula \[
k(x)=\frac{1}{x^{2}}\exp(2k+1)\frac{\pi}{x}\]

\end_inset 

 Then 
\begin_inset Formula \begin{eqnarray*}
\left[U_{h}k\right](x) & = & \exp\left((2k+1)\pi x\right)\sum_{n=1}^{\infty}\cos(2k+1)n\pi\\
 & = & \exp\left((2k+1)\pi x\right)\sum_{n=1}^{\infty}(-)^{n}\end{eqnarray*}

\end_inset 

 The value of the sum is ambiguous.
 One is tempted to cancel terms pairwise, and thus declare 
\begin_inset Formula $k(x)$
\end_inset 

 to belong to the kernel.
 On the other hand, we've seen that the regularized sum is not zero: 
\begin_inset Formula \[
\lim_{t\rightarrow0}\sum_{k=0}^{\infty}\,(-)^{k}e^{-tk}=\frac{1}{2}\]

\end_inset 

 and so one is left in a bit of a quandary.
\layout Section

The Singular Sawtooth of the First Kind
\layout Standard

The Gauss Map 
\begin_inset Formula $h(x)=\frac{1}{x}-\left\lfloor \frac{1}{x}\right\rfloor $
\end_inset 

 is used in the construction of continued fractions.
 In this section, we will study a model for this function, where we replace
 the curve by a set of straight lines arranged between values of 
\begin_inset Formula $1/n$
\end_inset 

 for integer 
\begin_inset Formula $n$
\end_inset 

.
 This forms a singular sawtooth, with a singularity at 
\begin_inset Formula $x=0.$
\end_inset 

 
\layout Standard


\begin_inset Formula \[
w(x)=\left\{ \begin{array}{ccc}
2-2x & \;\textrm{ for \;} & \frac{1}{2}<x\leq1\\
3-6x & \;\textrm{ for \;} & \frac{1}{3}<x\leq\frac{1}{2}\\
4-12x & \;\textrm{ for \;} & \frac{1}{4}<x\leq\frac{1}{3}\\
n+1-n(n+1)x & \;\textrm{ for \;} & \frac{1}{n+1}<x\leq\frac{1}{n}\end{array}\right.\]

\end_inset 

 This function is pictured in figure 
\begin_inset LatexCommand \ref{cap:The-Singular-Sawtooth}

\end_inset 

.
 
\layout Standard


\begin_inset Float figure
wide false
collapsed false

\layout Caption


\begin_inset LatexCommand \label{cap:The-Singular-Sawtooth}

\end_inset 

The Singular Sawtooth of the First Kind
\layout Standard


\begin_inset Graphics
	filename saw-first.png

\end_inset 


\layout Standard

This sawtooth function joins values of 
\begin_inset Formula $1/n$
\end_inset 

 with straight lines.
\end_inset 

 The Frobenius-Perron operator for this function is exactly solvable, and
 provides a toy model of the Gauss-Kuzmin-Wirsing operator.
 The Frobenius-Perron operator of this sawtooth, acting on a general function
 
\begin_inset Formula $f(x)$
\end_inset 

, is given by
\begin_inset Formula \[
\left[U_{w}f\right](x)=\sum_{x':w(x')=x}\frac{f(x')}{\left|dw(x')/dx'\right|}=\sum_{n=1}^{\infty}\frac{1}{n(n+1)}f\left(\frac{n+1-x}{n(n+1)}\right)\]

\end_inset 

We develop a representation of this operator in the monomial-basis Hilbert
 space below.
\layout Subsection

The Polynomial Eigenfunctions
\layout Standard

We will want to consider the action of this operator on polynomials of 
\begin_inset Formula $y=1-x$
\end_inset 

, so that we can express 
\begin_inset Formula $f(x)$
\end_inset 

 as a Taylor's expansion about 
\begin_inset Formula $y=0$
\end_inset 

.
 Lets make this change-of-variable now, and write 
\begin_inset Formula \[
f(y)=\sum_{k=0}^{\infty}\frac{f^{(k)}(0)}{k!}y^{k}\equiv\sum_{k=0}^{\infty}a_{k}y^{k}\]

\end_inset 

 so that 
\begin_inset Formula \[
\left[U_{w}f\right](y)=\sum_{k=0}^{\infty}b_{k}y^{k}=\sum_{n=1}^{\infty}\frac{1}{n(n+1)}\sum_{k=0}^{\infty}a_{k}\left(\frac{n+y}{n(n+1)}\right)^{k}\]

\end_inset 

 Rearranging the sums, and equating terms with the same power of 
\begin_inset Formula $y$
\end_inset 

, we define the matrix elements 
\begin_inset Formula $W_{mk}$
\end_inset 

 so that 
\begin_inset Formula \[
b_{m}=\sum_{k=0}^{\infty}W_{mk}a_{k}\]

\end_inset 

 and find that 
\begin_inset Formula \[
W_{mk}=\left\{ \begin{array}{ccc}
\left(\begin{array}{c}
k\\
m\end{array}\right)\sum_{n=1}^{\infty}n^{-m-1}(n+1)^{-k-1} & \;\textrm{ for \;} & k\geq m\\
0 & \;\textrm{ for \;} & k<m\end{array}\right.\]

\end_inset 

 where we use 
\begin_inset Formula $\left(\begin{array}{c}
k\\
m\end{array}\right)$
\end_inset 

 to denote the binomial coefficient.
 This matrix is upper-triangular, and thus has its eigenvalues along the
 diagonal.
 These are 
\begin_inset Formula \[
\lambda_{k}=\sum_{n=1}^{\infty}\frac{1}{n^{k+1}(n+1)^{k+1}}\]

\end_inset 

 so that 
\begin_inset Formula $\lambda_{0}=1$
\end_inset 

 and 
\begin_inset Formula $\lambda_{1}=2\zeta(2)-3$
\end_inset 

 where 
\begin_inset Formula $\zeta(x)$
\end_inset 

 is the Riemann zeta.
 Numerically, we can see that the first few eigenvalues are 
\begin_inset Formula $\lambda_{1}=0.289868...$
\end_inset 

 and 
\begin_inset Formula $\lambda_{2}=0.130396...$
\end_inset 

 and 
\begin_inset Formula $\lambda_{3}=0.0633278...$
\end_inset 

 and 
\begin_inset Formula $\lambda_{4}=0.031383...$
\end_inset 

 and 
\begin_inset Formula $\lambda_{5}=0.0156468...$
\end_inset 

 We can trivially see that the ratio of eigenvalues settles down to 
\begin_inset Formula $\lambda_{k}/\lambda_{k+1}=2$
\end_inset 

 for large 
\begin_inset Formula $k$
\end_inset 

, since the first term of the sum will dominate for large 
\begin_inset Formula $k$
\end_inset 

.
 
\layout Standard

We can solve the operator through recursion on the matrix elements of a
 related operator, by observing that 
\begin_inset Formula \[
Z_{mk}\equiv\sum_{n=1}^{\infty}\frac{1}{n^{m}(n+1)^{k}}\left[\frac{1}{n}-\frac{1}{n+1}\right]=Z_{m,k-1}-Z_{m-1,k}\]

\end_inset 

 These recurrence relations are bounded on the edges by 
\begin_inset Formula $Z_{00}=1$
\end_inset 

, 
\begin_inset Formula $Z_{01}=2-\zeta(2)$
\end_inset 

 and thus 
\begin_inset Formula \begin{eqnarray*}
Z_{0k} &  & =Z_{0,k-1}-\left(\zeta(k+1)-1\right)=1-\sum_{j=1}^{k}\left[\zeta(j+1)-1\right]\end{eqnarray*}

\end_inset 

 and 
\begin_inset Formula $Z_{10}=\zeta(2)-1$
\end_inset 

 so that 
\begin_inset Formula \[
Z_{m0}=\zeta(m+1)-Z_{m-1,0}=(-)^{m}\left[1+\sum_{j=1}^{m}(-)^{j}\zeta(j+1)\right]\]

\end_inset 

 and we have 
\begin_inset Formula $Z_{mk}=W_{mk}$
\end_inset 

 for 
\begin_inset Formula $m\leq k$
\end_inset 

 .
 The first few eigenfunctions are 
\begin_inset Formula \[
e_{0}(y)=1\]

\end_inset 

 
\begin_inset Formula \[
e_{1}(y)=1-2y\]

\end_inset 

 
\begin_inset Formula \begin{eqnarray*}
e_{2}(y) & = & \frac{15-13\zeta(2)-9\zeta(3)+2\zeta(2)[\zeta(2)+3\zeta(3)]}{3(13\zeta(2)-8\zeta(3))(3-2\zeta(2))}+\\
 &  & +\frac{6\zeta(2)+2\zeta(3)-12}{13-8\zeta(2)}\, y+y^{2}\end{eqnarray*}

\end_inset 

 We see that although the eigenfunctions are polynomials and are exactly
 solvable, they quickly spiral out of control.
 
\layout Standard

XXX To Do: Double-check 
\begin_inset Formula $e_{2}$
\end_inset 

 Provide the closed-form finite-sum matrix elements.
 Provide graphs of the first dozen polynomials.
 Discuss the similarity transform that takes 
\begin_inset Formula $w(x)$
\end_inset 

 to 
\begin_inset Formula $h(x)$
\end_inset 

 and discuss why this fails to preserve the eigenvalues.
 What are the shift-states of this operator? What are the continuous-eigenvalue
 (square-integrable) eigenfunctions? Graph these eigenfunctions, see what
 kind of fractals they look like.
 
\layout Section

Singular Sawtooth of the Second Kind
\layout Standard

The singular sawtooth of the second kind is given by the dyadic-space conjugate
 of the continued-fraction shift function 
\begin_inset Formula $h(x)=\frac{1}{x}-\left\lfloor \frac{1}{x}\right\rfloor $
\end_inset 

, that is, 
\begin_inset Formula \[
c(x)=?\left(\frac{1}{?^{-1}(x)}-\left\lfloor \frac{1}{?^{-1}(x)}\right\rfloor \right)=(?\circ h\circ?^{-1})(x)\]

\end_inset 

 where 
\begin_inset Formula $?(x)$
\end_inset 

 is the Minkowski Question Mark, presented in earlier sections.
 This map consists of straight-line segments between values of 
\begin_inset Formula $1/2^{k}$
\end_inset 

, as pictured in figure 
\begin_inset LatexCommand \ref{cap:Singular-Sawtooth,-Second}

\end_inset 

, and can be written as 
\begin_inset Formula \[
c(x)=2-2^{n}x\;\textrm{ for \; }\frac{1}{2^{n}}<x\leq\frac{1}{2^{n-1}}\]

\end_inset 

 The Frobenius-Perron operator of this function provides a second model
 of the Gauss-Kuzmin-Wirsing operator.
 It can be solved exactly; unfortunately, while one might think that there
 is a similarity transform to take it back to GKW, it turns out this similarity
 transform is dastardly singular, being just the Jacobian of the Minkowski
 question mark 
\begin_inset Formula $(?'\circ?^{-1})(x)$
\end_inset 

, which we'll examine shortly.
 The FP operator is 
\begin_inset Formula \[
\left[U_{C}f\right](x)=\sum_{n=1}^{\infty}\frac{1}{2^{n}}f\left(\frac{2-x}{2^{n}}\right)\]

\end_inset 

 The following sections develop this operator in different function spaces.
 
\layout Standard


\begin_inset Float figure
wide false
collapsed false

\layout Caption


\begin_inset LatexCommand \label{cap:Singular-Sawtooth,-Second}

\end_inset 

Singular Sawtooth, Second Kind
\layout Standard


\begin_inset Graphics
	filename saw-second.png

\end_inset 


\layout Standard

Picture of the second kind of sawtooth.
 
\end_inset 

 
\layout Subsection

The Polynomial Basis Eigenfunctions
\layout Standard

As before, we change variables to 
\begin_inset Formula $y=1-x$
\end_inset 

, expand both sides in terms of 
\begin_inset Formula $y$
\end_inset 

, and match terms to find the matrix elements 
\begin_inset Formula \[
C_{mk}=\left(\begin{array}{c}
k\\
m\end{array}\right)\frac{1}{2^{k+1}-1}\]

\end_inset 

 which is upper triangular (we take the binomial coefficients to be vanishing
 when 
\begin_inset Formula $k<m$
\end_inset 

).
 The eigenvalues lie along the diagonal.
 The first few are 
\begin_inset Formula $\lambda_{0}=1$
\end_inset 

, 
\begin_inset Formula $\lambda_{1}=1/3$
\end_inset 

, 
\begin_inset Formula $\lambda_{2}=1/7$
\end_inset 

, 
\emph on 
etc
\emph default 
.
 with the ratio of successive eigenvalues tending to 2.
 The first few eigenvectors are 
\begin_inset Formula \[
e_{0}=1\]

\end_inset 

 
\begin_inset Formula \[
e_{1}=1-2y=2x-1\]

\end_inset 

 
\begin_inset Formula \[
e_{2}=1-\frac{18}{5}y+\frac{12}{5}y^{2}=\frac{-1}{5}\left(1+6x-12x^{2}\right)\]

\end_inset 

 
\begin_inset Formula \[
e_{3}=1-\frac{66}{13}y+\frac{84}{13}y^{2}-\frac{32}{13}y^{3}=\frac{-1}{13}\left(1+6x+12x^{2}-32x^{3}\right)\]

\end_inset 


\begin_inset Formula \begin{eqnarray*}
e_{4} & = & 1-\frac{36450}{5597}y+\frac{67620}{5597}y^{2}-\frac{50400}{5597}y^{3}+\frac{13440}{5597}y^{4}\\
 & = & \frac{-1}{29\cdot193}\left(193+1350x+2940x^{2}+3360x^{3}-13440x^{4}\right)\end{eqnarray*}

\end_inset 

 As we can see, the complexity of individual eigenvectors spirals out of
 control; there's no obvious simple closed form expression for higher eigenvecto
rs.
 Indeed, it seems that the simplest algorithm is to directly invert the
 matrix.
 This is curious, because the matrix itself is so curiously simple, and
 superficially similar to that for the Bernoulli map.
\layout Standard


\begin_inset Float figure
wide false
collapsed false

\layout Caption

Second Sawtooth Polynomials
\layout Standard


\begin_inset Graphics
	filename saw-eigen.png

\end_inset 


\layout Standard

Eigenvectors of the second sawtooth.
\end_inset 


\layout Subsection

The Failure of the Similarity Transform for the Polynomial Basis
\layout Standard

Under normal circumstances, whenever one has a pair of maps 
\begin_inset Formula $\alpha(x)$
\end_inset 

 and 
\begin_inset Formula $\beta(x)$
\end_inset 

 that are conjugate to each other through an invertible function 
\begin_inset Formula $\phi(x)$
\end_inset 

 such that 
\begin_inset Formula $\alpha(x)=(\phi\circ\beta\circ\phi^{-1})(x)$
\end_inset 

, then there exists a similarity transform 
\begin_inset Formula $S_{\phi}$
\end_inset 

 such that the Frobenius-Perron operators are also conjugate; that is, 
\begin_inset Formula $U_{\alpha}=S_{\phi}U_{\beta}S_{\phi}^{-1}$
\end_inset 

 where 
\begin_inset Formula $S_{\phi}^{-1}=S_{\phi^{-1}}$
\end_inset 

.
 Formally, one finds that 
\begin_inset Formula $S_{\phi}=1/(\phi'\circ\phi^{-1})$
\end_inset 

 where the prime denotes differentiation: 
\begin_inset Formula $\phi'(x)=d\phi(x)/dx$
\end_inset 

 .
 Since the continued-fraction shift function is conjugate to the sawtooth,
 one might hope that GKW would be conjugate to 
\begin_inset Formula $U_{C}$
\end_inset 

, that is, 
\begin_inset Formula $U_{h}=S_{?}U_{C}S_{?}^{-1}$
\end_inset 

.
 Unfortunately, the Minkowski Question Mark is highly singular and is not
 traditionally differentiable, and so we cannot build such a similarity
 transform using the polynomial function basis.
 Another way to deduce this is to note that the similarity transform 
\begin_inset Formula $S_{\phi}$
\end_inset 

, working as a traditional, ordinary operator, normally preserves the eigenvalue
s; that is, the eigenvalues of 
\begin_inset Formula $U_{\alpha}$
\end_inset 

 equal those of 
\begin_inset Formula $U_{\beta}$
\end_inset 

.
 In the current case, we see trouble in that the eigenvalues of 
\begin_inset Formula $U_{C}$
\end_inset 

 are not those of GKW.
 They are not even 'close', in that the ratio of tends to 
\begin_inset Formula $\lambda_{k}/\lambda_{k+1}=2$
\end_inset 

 whereas for the GKW the ratio is 2.65...
 I am not aware of what this value is supposed to be.
 Its plausible that it may be Khinchin's constant 2.685.
 But given the intricate connection between the Riemann Zeta, the Modular
 Group, and period-doubling fractals, its equally plausible is that it may
 be Feigenbaum's constant, the ratio of period doubling 
\begin_inset Formula $\delta=4.6692...$
\end_inset 

 which is 2+2.6692...
\layout Standard

However, there are suggestive elements.
 For example, the function argument 
\begin_inset Formula $(2-x)/2^{n}$
\end_inset 

 is just the dyadic polynomial 
\begin_inset Formula $(g_{D}^{n-1}r_{D}g_{D})(x)$
\end_inset 

.
 Tantalizingly, the corresponding Mobius transform is 
\begin_inset Formula $(g_{C}^{n-1}r_{C}g_{C})(x)=1/(n+x)$
\end_inset 

 which is the function argument to the GKW operator.
 This suggests the tantalizing re-write of the terms of GKW as 
\begin_inset Formula \[
f\left(\frac{1}{n+x}\right)=f\circ?^{-1}\left(\frac{2-?(x)}{2^{n}}\right)\]

\end_inset 

 Also, one can do strange things such as xxx but why do we want to do that?
\layout Standard

The point is to not give up hope on the operator relationships, even though
 the polynomial basis breaks the relationship.
 Thus, we are motivated to explore other bases, and not just the polynomial
 basis.
 Fortunately, we can find some of these.
 
\layout Subsection

Fractal Eigenfunctions of the Second Sawtooth
\layout Standard

The Takagi curve can be used to build an alternate set of eigenfunctions
 for the second sawtooth, possessing continuous-spectrum eigenvalues.
 These eigenfunctions are not differentiable, and thus cannot be obtained
 through polynomials, and thus are not visible when working with the operator
 in a polynomial-basis Hilbert Space.
 They can be used to build an alternate function space, in which the Second
 Sawtooth remains exactly solvable.
 
\layout Standard

We recognize from the studying of the dyadic representation of the Modular
 Group 
\begin_inset Formula $SL(2,\mathbb{Z})$
\end_inset 

 that the second sawtooth is expressed in terms of the the group element
 
\begin_inset Formula \[
\left[g_{D}^{k-1}r_{D}g_{D}\right](x)=\frac{1}{2^{k-1}}-\frac{x}{2^{k}}\]

\end_inset 

 and thus functions possessing the modular group symmetry are candidates
 for solving the operator 
\begin_inset Formula $U_{C}$
\end_inset 

.
 The candidates we have in mind are of course the family of Takagi Curves.
 
\layout Standard

We begin by defining the Takagi Curve as 
\begin_inset Formula \[
t_{w}(x)=\sum_{k=0}^{\infty}w^{k}\tau\left(2^{k}x-\left\lfloor 2^{k}x\right\rfloor \right)\]

\end_inset 

 where 
\begin_inset Formula $\tau(x)$
\end_inset 

 is the triangle wave: 
\begin_inset Formula \[
\tau(x)=\left\{ \begin{array}{ccc}
2x & \;\textrm{ when }\; & 0\leq x\leq1/2\\
2(1-x) & \;\textrm{ when }\; & 1/2\leq x\leq1\end{array}\right.\]

\end_inset 

 This form of the Takagi curve transforms under the three-dimensional representa
tion of the Modular Group.
 Specifically, we write 
\begin_inset Formula \[
g_{3}^{n}=\left(\begin{array}{ccc}
1 & 0 & 0\\
0 & 1/2^{n} & 0\\
0 & q_{n}(w) & w\end{array}\right)\]

\end_inset 

 where 
\begin_inset Formula $q_{n}(w)$
\end_inset 

 is the polynomial 
\begin_inset Formula \[
q_{n}(w)=\frac{1}{2^{n-1}}\sum_{k-0}^{n-1}(2w)^{k}=\frac{1}{2^{n-1}}\left(\frac{1-(2w)^{n}}{1-2w}\right)\]

\end_inset 

 We write out the full matrix form for 
\begin_inset Formula $g_{3}^{k-1}r_{3}g_{3}$
\end_inset 

 and apply the group action isomorphism 
\begin_inset Formula $t_{w}g_{D}^{k-1}r_{D}g_{D}=g_{3}^{k-1}r_{3}g_{3}t_{w}$
\end_inset 

 to obtain 
\begin_inset Formula \[
t_{w}\left(\frac{1}{2^{k-1}}-\frac{x}{2^{k}}\right)=q_{k-1}(w)+x\left(w^{k-1}-q_{k-1}(w)/2\right)+w^{k}t_{w}(x)\]

\end_inset 

 Inserting the above back into the definition for the sawtooth operator,
 and performing the sum, we get
\begin_inset Formula \[
\left[U_{C}t_{w}\right](x)=\frac{4}{3(2-w)}+\frac{x}{3(2-w)}+\frac{wt_{w}(x)}{2-w}\]

\end_inset 

 From this, we can immediately read off the eigenvalue as 
\begin_inset Formula $w/(2-w)$
\end_inset 

.
 To get the eigenfunction, we need to complete the diagonalization by using
 
\begin_inset Formula $\left[U_{C}1\right](x)=1$
\end_inset 

 and 
\begin_inset Formula $\left[U_{C}x\right](x)=(2-x)/3$
\end_inset 

 to get the eigenfunction 
\begin_inset Formula \[
E_{2}(x)=\frac{2-w}{2(w+1)(w-1)}+\frac{x}{2(w+1)}+t_{w}(x)\]

\end_inset 

 It should be clear from this presentation that the higher and lower dimensional
 Takagi curves, of both even and odd parity, give eigenvectors and eigenvalues
 as well.
 We present a few more here:
\layout Standard

XXX to do, present 
\begin_inset Formula $E_{1}$
\end_inset 

and the odd-parity 
\begin_inset Formula $E_{2}$
\end_inset 

and both parities for 
\begin_inset Formula $E_{3}$
\end_inset 

 as well.
 Show graphs as well.
\layout Section

Other Trees of Rationals
\layout Standard

Recall that we were able to construct other trees that are isomorphic to
 the Stern-Brocot tree by passing the values in the Stern-Brocot Tree through
 a ratio of polynomials, thus mapping rationals to rationals.
 Monotonically-increasing functions will always preserve monotonicity of
 the question mark.
 Other mappings, such as the cubic 
\begin_inset Formula $x^{3}-x$
\end_inset 

, are in general not globally monotonic, but they are always locally monotonic.
 In other words, 
\begin_inset Formula $?((2x-1)^{3}-x+1)$
\end_inset 

 is monotonic between the same regions that 
\begin_inset Formula $(2x-1)^{3}-x+1$
\end_inset 

 is, and thus it does not yield a fundamentally new function.
 Thus, these polynomial-based mappings of rationals into rationals do not
 generate another self-similar map, they are distorted versions of the Minkowski
 question mark.
\layout Standard

Here's a mapping that is continuous and is also fractally non-monotonic
 (and is thus self-similar): its 
\begin_inset Formula $x-?(x)$
\end_inset 

 which looks sine-like and we want to exhibit the cosine-like so that we
 can build up fractally-periodic basis functions.
 Its also remarkable because its exactly ...XXX wow!
\layout Section

Conclusions
\layout Standard

Apologies for the format of this paper.
 It's a veritable candy store of goodies; there are all these yummy toys
 to play with, which one first?
\layout Bibliography
\bibitem [asdf]{key-1}

Here is a very similarly titled paper with a very different subject matter:
 
\begin_inset LatexCommand \htmlurl[Continued Fractions and Chaos]{http://www.cecm.sfu.ca/organics/papers/corless/confrac/html/confrac.html}

\end_inset 

 by Robert M.
 Corless
\layout Bibliography
\bibitem [Dri99]{key-2}

Dean Driebe, 
\emph on 
Fully Chaotic Maps and Broken Time Symmetry, 1999,
\emph default 
 Kluwer Academic Publishers
\layout Bibliography
\bibitem [Man88]{key-3}

Benoit Mandelbrot, in 
\emph on 
The Science of Fractal Images, ed.
 Heinz-Otto Peitgen, Dietmar Saupe,
\emph default 
 (Springer-Verlag, 1988) p.
 246
\layout Bibliography
\bibitem [deR57]{key-4}

Georges de Rham, 
\emph on 
On Some Curves Defined by Functional Equations
\emph default 
 (1957), reprinted in
\emph on 
 Classics on Fractals, ed.
 Gerald A.
 Edgar
\emph default 
, (Addison-Wesley, 1993) pp.
 285-298
\layout Bibliography
\bibitem [Gas92]{key-10}

P.
 Gaspard, 
\emph on 
r-adic one-dimensional maps and the Euler summation formula
\emph default 
, 1992, Journal of Physics A: Mathematical and General, vol.
 25, L483-485.
 
\the_end
