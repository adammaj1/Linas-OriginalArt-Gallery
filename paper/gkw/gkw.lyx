#LyX 1.3 created this file. For more info see http://www.lyx.org/
\lyxformat 221
\textclass article
\language english
\inputencoding auto
\fontscheme default
\graphics default
\paperfontsize default
\spacing single 
\papersize Default
\paperpackage a4
\use_geometry 0
\use_amsmath 1
\use_natbib 0
\use_numerical_citations 0
\paperorientation portrait
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\defskip medskip
\quotes_language english
\quotes_times 2
\papercolumns 1
\papersides 1
\paperpagestyle default

\layout Title

The GKW and Related Operators
\layout Author

Linas Vepstas <linas@linas.org>
\layout Date

2 January 2004 (revised 12 October 2004)
\layout Abstract

The study of the Gauss-Kuzmin-Wirsing (GKW) operator can provide insight
 into the structure of the Riemann Zeta function, as the Zeta is a laplace-like
 transform of the GKW.
 Unfortunately, it is quite complex itself, and appears very difficult to
 solve.
 This chapter applies some tools developed for the study of fractals, and
 thier symmetries, to discuss and solve some related operators.
 
\layout Abstract

Specifically, the Minkowski Question Mark Function is an isomorphism connecting
 the dyadic (binary) fractions and the Farey Fractions.
 The Question Mark embodies the basic Modular Group 
\begin_inset Formula $SL(2,\mathbb{Z})$
\end_inset 

 symmetries seen in the dyadic and Farey Trees, and thus seen in fractals.
 This implies that GKW should have a set of modular-group symmetries as
 well, which in turn might extend onto the Riemann Zeta.
 
\layout Abstract

This chapter develops some of the tools for studying chaotic maps, spcifically
 the idea of studying the Frobenius-Perron (FP) operator of a chaotic map.
 The FP operator of the map that generates continued fractions is the GKW.
 We thus apply the modular group symmetries of the continued fractions to
 study the GKW.
 
\layout Abstract

The general presentation attempts to assume very little prior acquaintance
 with the concepts, and attempts a pedagogical aproach.
 This paper is part of a set of chapters that explore the relationship between
 the real numbers, the modular group, and fractals.
\layout Section

The Gauss-Kuzmin-Wirsing Operator
\layout Standard

THIS IS A DRAFT WORK IN PROGRESS.
 The intro hasn't been written yet.
\layout Standard

One of the new results is a demonstration that the Frobenius-Perron operator
 can have a continuous spectrum that is 
\begin_inset Formula $C^{\infty}$
\end_inset 

which flies in the face of common assumptions that the spectrum is eitehr
 discrete with 
\begin_inset Formula $C^{\infty}$
\end_inset 

 eigenfunctions, or is continous, with non-differentiable (fractal) eigenfunctio
ns.
 
\layout Section

Introduction: The Frobenius-Perron Operator for Iterated Maps
\layout Standard

This section provides a basic review of the Frobenius-Perron operator and
 its use in the description of fractals and chaotic iterated maps.
 No results are presented here; rather the goal is to provide the notation
 and general concepts that will be used in later sections.
 This review assumes no prior encounter with these concepts, and keeps the
 development simple, avoiding the language of higher mathematics.
 More sophisticated developments build on concepts such as Borel Sigma Algebras
 and define the Frobenius-Perron operator on Banach Spaces.
 In the following, we avoid this sophisticated language in order to keep
 the presentation accesible.
 However, we do so at some peril: many of the quantites we'll work with
 are potentially ill-defined or divergent, and so the validity of some of
 the transformations and equations in such foggy surrounds can be questionable.
 A more rigorous treatment with appeals to higher math would help clarify
 where the rocky shoals are.
 As a substitute, we try to maintain a physicist's attitude, and keep our
 heads about us when faced with something dangerous.
 Be aware that not all exrapolations from teh following may be warrented.
 
\layout Standard

The Frobenius-Perron operator of a function provides a tool for studying
 the dynamics of the iteration of that function.
 If one only studies how a point value jumps around during iteration, one
 gets a very good sense of the point dynamics but no sense of how iteration
 acts on non-point sets.
 If the iterated function is applied on a continuous, possibly even smooth
 density, then one wants to know how that smooth density evolves over repeated
 iteration.
 
\layout Standard

If we consider a smooth density 
\begin_inset Formula $\rho(x)$
\end_inset 

 as a set of values on a collection of points, we can take each point and
 iterate it to find its new location, and then assign the old value to the
 new location.
 Of course, after iteration, several points may end up at the same location,
 at which point we need to add thier values together.
 Lets write the new density as 
\begin_inset Formula $\rho_{1}(x)$
\end_inset 

, with the subscript 1 denoting we've iterated once.
 We can express this idea of iterating the underlying points, and then assigning
 thier old values to new locations as 
\begin_inset Formula \[
\rho_{1}(x)=\int dy\;\delta\left(x-g(y)\right)\;\rho(y)\]

\end_inset 

 where 
\begin_inset Formula $g(x)$
\end_inset 

 is the iterated function.
 To get 
\begin_inset Formula $\rho_{n}(x)$
\end_inset 

, one simply repeats the proceedure 
\begin_inset Formula $n$
\end_inset 

 times.
 In more abstract notation, one writes 
\begin_inset Formula \[
\left[U_{g}\rho\right](x)=\rho_{1}(x)\]

\end_inset 

 to denote this time evolution.
 The notation here emphasizes that 
\begin_inset Formula $U_{g}:\; f\mapsto U_{g}f$
\end_inset 

 is an operator that maps functions to functions: written formally, we have
 
\begin_inset Formula $U_{g}:\mathcal{F\mathcal{\rightarrow F}}$
\end_inset 

 where 
\begin_inset Formula $\mathcal{F}=\left\{ f\;|\; f:\mathbb{\mathbb{R\rightarrow}R}\right\} $
\end_inset 

 is the set of all functions.
 In analyzing 
\begin_inset Formula $U_{g}$
\end_inset 

, we will often be interested in how it acts on the subset of square-integrable
 functions, or possibly just 
\begin_inset Formula $C^{\infty}$
\end_inset 

 functions or polynomials or the like.
 Repeated iteration just gives the time-evolution of the the density; that
 is, 
\begin_inset Formula \[
U_{g}^{n}\rho\equiv\begin{array}{c}
\underbrace{U_{g}\circ U_{g}\circ...\circ U_{g}}\\
n\textrm{ times}\end{array}\;\circ\rho=\rho_{n}\]

\end_inset 

 where iteration is just ordinary operator multiplication.
 
\layout Standard

To understand 
\begin_inset Formula $U_{g}$
\end_inset 

, one typically tries to understand its spectrum, that is, its eigenvalues
 and eigenfunctions.
 In most cases, one finds that 
\begin_inset Formula $U_{g}$
\end_inset 

 is contractive in that it has one eigenvalue equal to one and all the other
 eigenvalues are real and smaller than one.
 However, one must be terribly careful here, as there are land-mines strewn
 about: the actual spectrum, and the nature of the eigenvalues, depends
 very much on the function space choosen.
 Typically, when acting on polynomials, one gets discrete, real eigenvalues
 for 
\begin_inset Formula $U_{g}$
\end_inset 

.
 When acting on square-integrable functions, one seems to usually get a
 continuous set of complex-valued eigenvalues.
 This is because one can often find shift-states 
\begin_inset Formula $\psi_{n}$
\end_inset 

 such that 
\begin_inset Formula $U_{g}\psi_{n}=\psi_{n-1}$
\end_inset 

, in which case one can construct eigenfunctions 
\begin_inset Formula $\phi(z)=\sum_{n}z^{n}\psi_{n}$
\end_inset 

 whose complex eigenvalues 
\begin_inset Formula $z$
\end_inset 

 form the unit disk.
 It is often considered to be a mistake to try to analyse 
\begin_inset Formula $U_{g}$
\end_inset 

 acting on a finite grid of discrete points, such as one might try on a
 computer: it is all to easy to turn this into an excercise of analysing
 the permutation group on a set of 
\begin_inset Formula $k$
\end_inset 

 elements, of which any student knows that the eigenvalues are the 
\begin_inset Formula $k$
\end_inset 

'th roots of unity.
 
\layout Standard

Since 
\begin_inset Formula $U_{g}$
\end_inset 

 is a linear operator, it induces a homomorphism in its mapping, and so
 one should study its kernel 
\begin_inset Formula $Ker\; U_{g}=\left\{ f\;|\; U_{g}f=0\right\} $
\end_inset 

 to gain insights into its symmetry as well as to express more correctly
 the quotient space.
 Insofar as the iterated map might represent a dynamical system, one knows
 that symmetries lead to conserved currents, via Noether's theorm, and sometimes
 to topologically-conserved (quantum) numbers, winding numbers or other
 invarients.
 
\layout Standard

Finally, we note that since 
\begin_inset Formula $U_{g}$
\end_inset 

 looks like a time-evolution operator, we are tempted to write
\begin_inset Formula \[
U_{g}^{t}=\exp\; tH_{g}\]

\end_inset 

 for some other operator 
\begin_inset Formula $H_{g}$
\end_inset 

.
 Since 
\begin_inset Formula $U$
\end_inset 

 is in general not unitary, 
\begin_inset Formula $H$
\end_inset 

 is not (anti-)Hermitian.
 As before, describing the eigenvalues and eigenfunctions of 
\begin_inset Formula $H$
\end_inset 

 is a useful excercise.
 Also, any group of symmetries on 
\begin_inset Formula $U$
\end_inset 

 should express themselves as an algebra on 
\begin_inset Formula $H$
\end_inset 

 and these might provide an alternate path for exploring and describing
 the fractal in question.
\layout Standard

In practice, when one is given an iterated map 
\begin_inset Formula $g(x)$
\end_inset 

, one computes the Frobenius-Perron operator as 
\begin_inset Formula \[
\left[U_{g}\rho\right](x)=\sum_{x':x=g(x')}\frac{\rho(x')}{\left|dg(x')/dx'\right|}\]

\end_inset 

 which provides an expression for 
\begin_inset Formula $U_{g}$
\end_inset 

 acting on a general function 
\begin_inset Formula $\rho$
\end_inset 

.
\layout Subsection

Polynomial Representation
\layout Standard

If one is interested in 
\begin_inset Formula $U$
\end_inset 

 acting on polynomial functions, then one immediately writes the Taylor
 (or Maclaurin) series 
\begin_inset Formula \[
\rho(x)=\sum_{n=0}^{\infty}\frac{\rho^{(n)}(0)}{n!}x^{n}=\sum_{n=0}^{\infty}a_{n}x^{n}\]

\end_inset 

 and substitutes this in to get the matrix form of 
\begin_inset Formula $U$
\end_inset 

:
\begin_inset Formula \[
\left[U\rho\right](x)=\sum_{m=0}^{\infty}b_{m}x^{m}=\sum_{m=0}^{\infty}x^{m}\sum_{n=0}^{\infty}U_{mn}a_{n}\]

\end_inset 

 Equating each power of 
\begin_inset Formula $x^{m}$
\end_inset 

 we get 
\begin_inset Formula \[
\left.\frac{1}{m!}\;\frac{d^{m}\left[U\rho\right](x)}{dx^{m}}\right|_{x=0}=\sum_{n=0}^{\infty}U_{mn}\left.\frac{1}{n!}\;\frac{d^{n}\rho(x)}{dx^{n}}\right|_{x=0}\]

\end_inset 

 as the matrix equation for the transformation of polynomials, expressed
 in classical notation.
 
\layout Standard

There are a variety of different notations that one can use when working
 with matrix operators, all of which are, at a certain level, completely
 equivalent.
 However, certain notations are handier than others depending on what representa
tion one is working with, and what point one is trying to emphasize.
 Note in particular that the Dirac bra-ket notation is both very useful,
 and is also sometimes a source for confusion, especially when mixed with
 other notations.
 Thus, in the following, we take some pains to clarify this notation, giving
 a prolonged remedial presentation.
 (XXX this should be moved to an apendix).
\layout Standard

The operator, written in the polynomial representation, in space coordinates,
 is:
\begin_inset Formula \[
\delta\left(x-g(y)\right)=U_{g}(x,y)=\sum_{m=0}^{\infty}\sum_{n=0}^{\infty}\left\langle x|m\right\rangle \left\langle m|U_{g}|n\right\rangle \left\langle n|y\right\rangle \]

\end_inset 

 where 
\begin_inset Formula $U_{mn}=\left\langle m|U|n\right\rangle $
\end_inset 

 and 
\begin_inset Formula $\left\langle x|m\right\rangle =x^{m}$
\end_inset 

 and 
\begin_inset Formula $\left\langle n|y\right\rangle =(-)^{n}\delta^{(n)}(y)/n!$
\end_inset 

, the latter being the 
\begin_inset Formula $n$
\end_inset 

'th derivative of the Dirac delta function.
 In this basis, 
\begin_inset Formula $U$
\end_inset 

 is not diagonal, and the kets 
\begin_inset Formula $\left|n\right\rangle $
\end_inset 

 are not eigenvectors, and the vector element 
\begin_inset Formula $\left\langle x|m\right\rangle $
\end_inset 

 is neither the complex conjugate nor the transpose of 
\begin_inset Formula $\left\langle n|y\right\rangle $
\end_inset 

.
 These are rather monomials and thier inverses, and obey traditional orthogonali
ty and completeness relationships.
 The inner products demonstrate orthogonality: 
\begin_inset Formula \begin{eqnarray*}
\left\langle n|m\right\rangle  & = & \int dx\left\langle n|x\right\rangle \left\langle x|m\right\rangle \\
 & = & \int dx\,(-)^{n}\frac{\delta^{(n)}(x)}{n!}x^{m}\\
 & = & \delta_{nm}\end{eqnarray*}

\end_inset 

 and 
\begin_inset Formula \begin{eqnarray*}
\left\langle x|y\right\rangle  & = & \sum_{n=0}^{\infty}\left\langle x|n\right\rangle \left\langle n|y\right\rangle \\
 & = & \sum_{n=0}^{\infty}(-x)^{n}\frac{\delta^{(n)}(y)}{n!}\\
 & = & \delta(y-x)\end{eqnarray*}

\end_inset 

 are the orthogonality relationships in polynomial space and coordinate
 space, respectively.
 The completeness relationships define the identity operator 
\begin_inset Formula \[
\mathbb{I}=\sum_{n=0}^{\infty}\left|n\right\rangle \left\langle n\right|=\int dx\left|x\right\rangle \left\langle x\right|\]

\end_inset 

 whose matrix elements in coordinate space are 
\begin_inset Formula $\left\langle x\right|\mathbb{I}\left|y\right\rangle =\delta(y-x)$
\end_inset 

 and, in polynomial space, 
\begin_inset Formula $\left\langle m\right|\mathbb{I}\left|n\right\rangle =\delta_{mn}$
\end_inset 

.
 In this notation, a function is represented by it's Taylor series: 
\begin_inset Formula \begin{eqnarray*}
f(x) & = & \left\langle x|f\right\rangle \\
 & = & \sum_{n=0}^{\infty}\left\langle x|n\right\rangle \left\langle n|f\right\rangle \\
 & = & \sum_{n=0}^{\infty}x^{n}\left\langle n|f\right\rangle \\
 & = & \sum_{n=0}^{\infty}x^{n}\int dy\left\langle n|y\right\rangle \left\langle y|f\right\rangle \\
 & = & \sum_{n=0}^{\infty}x^{n}\int dy(-)^{n}\frac{\delta^{(n)}(y)}{n!}f(y)\\
 & = & \sum_{n=0}^{\infty}x^{n}\frac{f^{(n)}(0)}{n!}\end{eqnarray*}

\end_inset 


\layout Standard

Lets complete the review by taking the coordinate-sapce representation of
 the Frobenius-Perron operator back to its matrix representation.
 Integrating the coordinate-space operator representation over 
\begin_inset Formula $y$
\end_inset 

, we regain the previous expressions for the operator in Hilbert space:
 
\begin_inset Formula \begin{multline*}
\left[U_{g}\rho\right](x)=\int dy\; U_{g}(x,y)\rho(y)\end{multline*}

\end_inset 

 
\begin_inset Formula \[
=\int dy\;\delta\left(g(x)-y\right)\rho(y)\]

\end_inset 


\begin_inset Formula \[
=\sum_{m,n=0}^{\infty}\; x^{m}\; U_{mn}\int dy\;(-)^{n}\frac{\delta^{(n)}(y)}{n!}\rho(y)\]

\end_inset 

 
\begin_inset Formula \[
=\sum_{m,n=0}^{\infty}\; x^{m}\; U_{mn}\left.\frac{1}{n!}\;\frac{d^{n}\rho(y)}{dy^{n}}\right|_{y=0}\]

\end_inset 


\begin_inset Formula \[
=\sum_{m,n=0}^{\infty}\; x^{m}\; U_{mn}\;\frac{\rho^{(n)}(0)}{n!}\]

\end_inset 

 Note that when one goes to diagonalize the operator, one will find 
\begin_inset Quotes eld
\end_inset 

right eigenvectors
\begin_inset Quotes erd
\end_inset 

 that will consist solely of a linear combinatation of 
\begin_inset Formula $\left\langle x|m\right\rangle =x^{m}$
\end_inset 

 , that is, will be plynomials.
 The 
\begin_inset Quotes eld
\end_inset 

left eigenstates
\begin_inset Quotes erd
\end_inset 

 will, by definition, be a linear combination solely of 
\begin_inset Formula $\left\langle n|y\right\rangle =(-)^{n}\delta^{(n)}(y)/n!$
\end_inset 

 since, in a polynomial Hilbert space, these are the basis functions that
 are adjoint to polynomials.
\layout Standard

It is critical to understand that the above notation and conventions are
 applicable only to the polynomial representation, and by construction,
 yeilds discrete spectra and polynomial (analytic, 
\begin_inset Formula $C^{\infty}$
\end_inset 

) eigenfunctions.
 This representation is more-or-less incapable of doing otherwise.
 The above expressions, although constructed using an equals sign, in fact
 do a great deal of violence and are in a certain way violently incorrect,
 because they hide or incorrectly equate the function spaces on which the
 operator 
\begin_inset Formula $U_{g}$
\end_inset 

 acts.
 That is, whenever 
\begin_inset Formula $\rho(x)$
\end_inset 

 is not differentiable or is otherwise singular, the expansion in derivatives
 is not justified.
 As we will see shortly, when considered as acting in the space of square-integr
able functions, 
\begin_inset Formula $U_{g}$
\end_inset 

 can and will have fractal eigenfunctions, which will typically be non-different
iable and even possibly continuous-nowhere, and thus not representable by
 polynomials.
 This is, of course, the whole point of this excercise!
\layout Standard

If one is very lucky, one finds that 
\begin_inset Formula $U_{mn}$
\end_inset 

 is upper-triangular, in which case it can be solved immediately for its
 eigenfunctions, and its eigenvalues already lie on the diagonal.
 We will find that we get lucky in this way for the Bernoulli operator,
 and for the 
\begin_inset Quotes eld
\end_inset 

singular sawtooth
\begin_inset Quotes erd
\end_inset 

 operator, but not for the Gauss-Kuzmin-Wirsing operator.
 Of course, it is known that a complete solution of the GKW should lead
 directly to a proof of the Riemann Hypothesis, so getting lucky would be
 truly lucky indeed.
 XXXX edit the above sentances.
\layout Subsection

Fourier Representation
\layout Standard

We repeat the above analysis using standard Fourier Series techniques.
 Although such an analysis may be considered to be old and shop-worn, it
 is critical to note that in this context, the Fourier representation is
 not only inequivalent to the polynomial representation, but that attempting
 to establish an equivalence leads to divergences reminiscent of those seen
 in more complicated Hilbert spaces, such as those encountered in Quantum
 Field Theory and elsewhere.
 In less flowery terms, we provide a simple example where undergraduate
 
\begin_inset Quotes eld
\end_inset 

textbook math
\begin_inset Quotes erd
\end_inset 

 leads one to form incorrect conclusions about Hilbert Spaces and the behaviour
 of operators in them.
 What look like simple statements about orthogonality and completeness of
 a set of basis functions can lead to serious trouble when analysing even
 simple operators, as we shall show.
 The goal here is to get this 
\begin_inset Quotes eld
\end_inset 

dirty laundry
\begin_inset Quotes erd
\end_inset 

 out in the open, as it affects the development of later sections.
 
\layout Standard

Lets quickly review the standard textbook treatment of a Fourier Series.
 In traditional notation, for some (periodic) function 
\begin_inset Formula $f(x)$
\end_inset 

 one writes the Fourier Series as 
\begin_inset Formula \[
f(x)=\sum_{n=-\infty}^{\infty}a_{n}\cos2\pi nx\;+b_{n}\sin2\pi nx\]

\end_inset 

 where the conjugates of 
\begin_inset Formula $f$
\end_inset 

 are given by 
\begin_inset Formula \[
a_{n}=\int_{0}^{1}f(x)\,\cos(2\pi nx)\, dx\]

\end_inset 

 and 
\begin_inset Formula \[
b_{n}=\int_{0}^{1}f(x)\,\sin(2\pi nx)\, dx\]

\end_inset 

 Moving over to bra-ket notation, we can define the Fourier-space basis
 vectors 
\begin_inset Formula $\left|em\right\rangle $
\end_inset 

 in terms of thier components in coordinate space.
 These components are 
\begin_inset Formula $\left\langle x|em\right\rangle =\exp(i2\pi mx)$
\end_inset 

.
 The conjugate vectors 
\begin_inset Formula $\left\langle en\right|$
\end_inset 

 have an equally simple representation: 
\begin_inset Formula $\left\langle en|x\right\rangle =\exp(-i2\pi nx)$
\end_inset 

.
 One has the usual sense of orthogonality over coordinate space in that
 
\begin_inset Formula \[
\left\langle em|en\right\rangle =\int_{0}^{1}dx\,\left\langle em|x\right\rangle \left\langle x|en\right\rangle =\int_{0}^{1}dx\,\exp(2\pi i(n-m)x)=\delta_{nm}\]

\end_inset 

 and the traditional presentation of the Fourier Series is a statement of
 completeness over coordinate space, in that for an arbitrary square-integrable
 coordinate-space function 
\begin_inset Formula $f(x)=\left\langle x|f\right\rangle $
\end_inset 

 one has 
\begin_inset Formula \begin{eqnarray*}
f(x)=\left\langle x|f\right\rangle  & = & \sum_{n=-\infty}^{\infty}\left\langle x|en\right\rangle \left\langle en|f\right\rangle \\
 & = & \sum_{n=-\infty}^{\infty}\exp(i2\pi nx)\int_{0}^{1}dy\,\left\langle en|y\right\rangle \left\langle y|f\right\rangle \\
 & = & \sum_{n=-\infty}^{\infty}\exp(i2\pi nx)\int_{0}^{1}dy\,\exp(-i2\pi ny)f(y)\\
 & = & \int_{0}^{1}dy\,\delta(x-y)\, f(y)\end{eqnarray*}

\end_inset 

 Thus, one is accustomed to the notion of having an identity operator of
 the form 
\begin_inset Formula $1_{F}=\sum_{m=-\infty}^{\infty}\left|em\right\rangle \left\langle em\right|$
\end_inset 

 because it has the matrix elements that one expects in both the Fourier
 space and in coordinate space: that is, 
\begin_inset Formula $\left\langle em\right|1_{F}\left|en\right\rangle =\delta_{nm}$
\end_inset 

 and 
\begin_inset Formula $\left\langle x\right|1_{F}\left|y\right\rangle =\delta(x-y)$
\end_inset 

 .
 
\layout Standard

Thus, in light of this perfectly ordinary standard textbook behaviour, the
 following shall be surprising.
 The matrix elements of this operator, expressed in the polynomial basis,
 are not only non-trivial, but are divergent.
 That is, one can be lulled into beleiving that 
\begin_inset Formula $\left\langle m\right|1_{F}\left|n\right\rangle =\delta_{nm}$
\end_inset 

 for the polynomial basis, and indeed, by performing the operations in a
 certain order, one can certainly show this.
 However, reversing the order of operations shows that what might seem like
 simple operations can in fact be quite treacherous.
 
\layout Standard

We begin by writing the compnents of the vector 
\begin_inset Formula $\left|em\right\rangle $
\end_inset 

 in the polynomial-space representation:
\layout Standard


\begin_inset Formula \begin{eqnarray*}
\left\langle n|em\right\rangle  & = & \int_{0}^{1}dx\left\langle n|x\right\rangle \left\langle x|em\right\rangle \\
 & = & \int_{0}^{1}dx\,\frac{(-)^{n}}{n!}\delta^{(n)}(x)\, e^{i2\pi mx}\\
 & = & \int_{0}^{1}dx\,\frac{\delta(x)}{n!}\,\frac{d^{n}}{dx^{n}}\, e^{i2\pi mx}\\
 & = & \frac{(i2\pi m)^{n}}{n!}\end{eqnarray*}

\end_inset 

 Essentially, this is nothing more than a plain-old Taylor's Series expansion
 of the exponential function.
 The conjugate vectors have a slightly trickier form.
 They are the Fourier components of monomials.
 For 
\begin_inset Formula $m\neq0$
\end_inset 

 
\begin_inset Formula \begin{eqnarray*}
\left\langle em|n\right\rangle  & = & \int_{0}^{1}dy\left\langle em|y\right\rangle \left\langle y|n\right\rangle \\
 & = & \int_{0}^{1}\exp(-2\pi imy)\, y^{n}\, dy\\
 & = & \frac{-1}{2\pi im}+\frac{n}{2\pi im}\int_{0}^{1}\exp(-2\pi imy)\, y^{n-1}\, dy\\
 & = & -\frac{1}{2\pi im}\sum_{k=0}^{n-1}\frac{n!}{(n-k)!}\left(\frac{1}{2\pi im}\right)^{k}\end{eqnarray*}

\end_inset 

 and, for 
\begin_inset Formula $m=0$
\end_inset 

, 
\begin_inset Formula $\left\langle e0|n\right\rangle =1/(n+1)$
\end_inset 

.
 Let us now try to explictly evaluate the matrix elements of the Fourier
 identity operator in the polynomial representation.
 That is, we attempt to write the amtrix elements of 
\begin_inset Formula $1_{F}=\sum_{m=-\infty}^{\infty}\left|em\right\rangle \left\langle em\right|$
\end_inset 

 
\begin_inset Formula \begin{eqnarray*}
\left\langle p\right|1_{F}\left|n\right\rangle  & = & \sum_{m=-\infty}^{\infty}\left\langle p|em\right\rangle \left\langle em|n\right\rangle \\
 & = & \sum_{m=-\infty}^{\infty}\left[\delta_{p0}+\left(1-\delta_{p0}\right)\frac{\left(2\pi im\right)^{p}}{p!}\right]\left[\frac{\delta_{m0}}{n+1}-\frac{\left(1-\delta_{m0}\right)}{2\pi im}\sum_{k=0}^{n-1}\frac{n!}{(n-k)!}\left(\frac{1}{2\pi im}\right)^{k}\right]\end{eqnarray*}

\end_inset 

 We need only to look at the relatively simple matrix element 
\begin_inset Formula $n=1$
\end_inset 

, 
\begin_inset Formula $p\neq0$
\end_inset 

 to see the misery of this expression: 
\begin_inset Formula \[
\left\langle p\neq0\right|1_{F}\left|n=1\right\rangle =\frac{\left(2\pi i\right)^{p}}{p!}\sum_{m=1}^{\infty}\frac{m^{p}}{2\pi im}\]

\end_inset 

 One can try to rescue teh situation by making the Ansatz that the summation
 should have beenreplaced by 
\begin_inset Formula $\zeta(1-p)$
\end_inset 

 which is regular, but already this is dangerous.
 What is perhaps the more surprising is that one might have expected this
 kind of trouble from the polynomial completeness relationship 
\begin_inset Formula $\mathbb{I}_{A}=\sum_{n=0}^{\infty}\left|n\right\rangle \left\langle n\right|$
\end_inset 

 because it ranges only over analytic functions: its essentially a statement
 of the idea that analytic functions are expressible through a series expansion
 in a variable.
 Functions that are not infinitely differntiable more-or-less lie in the
 kernel of 
\begin_inset Formula $\mathbb{I}_{A}$
\end_inset 

.
 However, we'd expect 
\begin_inset Formula $1_{F}$
\end_inset 

 to be more faithful, as it would seem to venture over square-integrable
 functions.
 Thus, such a simple failing is surprising.
 
\layout Standard

The goal here is to simply present a signpost warning, as we make heavy
 use of these techniques in the sections that follow, where we work with
 functions that are differentiable-nowhere or worse.
 
\layout Subsection

The Koopman Operator
\layout Standard

The Koopman operator is in a certain sense conjugate to the Frobenius-Perron
 operator, and defines how observables evolve.
 Given a density 
\begin_inset Formula $\rho(x)$
\end_inset 

 we say that the observation of a function 
\begin_inset Formula $f(x)$
\end_inset 

 by 
\begin_inset Formula $\rho$
\end_inset 

 is 
\begin_inset Formula \[
\left\langle f\,\right\rangle _{\rho}=\int_{0}^{1}f(x)\rho(x)\, dx\]

\end_inset 

 The term 
\begin_inset Quotes eld
\end_inset 

observable
\begin_inset Quotes erd
\end_inset 

 comes from usage in Quantum Mechanics, where 
\begin_inset Formula $f(x)$
\end_inset 

 is associated with the eigenvalues of an operator.
 We do not need to appeal to these operator equations for the following
 development.
 The Koopman operator 
\begin_inset Formula $K$
\end_inset 

 gives the change in 
\begin_inset Formula $f$
\end_inset 

 when 
\begin_inset Formula $U$
\end_inset 

 acts on 
\begin_inset Formula $\rho$
\end_inset 

, thus: 
\begin_inset Formula \[
K_{g}:\left\langle f\,\right\rangle _{\rho}\rightarrow\left\langle K_{g}f\,\right\rangle _{\rho}=\int_{0}^{1}[K_{g}f](x)\rho(x)\, dx=\int_{0}^{1}f(x)[U_{g}\rho](x)\, dx\]

\end_inset 

 In Dirac bra-ket notation, we have 
\begin_inset Formula \begin{eqnarray*}
\int_{0}^{1}f(x)[U_{g}\rho](x)\, dx & = & \int_{0}^{1}\left\langle x|U_{g}|\rho\right\rangle \left\langle x|f\right\rangle \, dx\\
 & = & \int_{0}^{1}dx\int_{0}^{1}dy\left\langle x|U_{g}|y\right\rangle \left\langle y|\rho\right\rangle \left\langle x|f\right\rangle \, dx\end{eqnarray*}

\end_inset 

 and so we have 
\begin_inset Formula \[
\left[K_{g}f\right](y)=\int_{0}^{1}\left\langle x|U_{g}|y\right\rangle \left\langle x|f\right\rangle \, dx=\int_{0}^{1}U_{g}(x,y)f(x)\, dx=\int_{0}^{1}\delta\left(x-g(y)\right)f(x)\, dx\]

\end_inset 

 This gives the action of the Koopman operator in a coordinate-space representat
ion.
 As is the recurring theme, different representations can lead to different
 results.
 In the coordinate-space representation, the Koopman operator appears to
 be the transpose of the Frobenius-Perron operator, in that 
\begin_inset Formula $K(x,y)=U(y,x)$
\end_inset 

.
 However, in a general representation, whether the Koopman operator is the
 transpose or the complex conjugate or something else needs to be determined
 on a case-by-case basis, with an appeal to the particular operator 
\begin_inset Formula $g(x)$
\end_inset 

 and the representations on which it works.
 
\layout Section

The Frobenius-Perron Operator of the Bernoulli Map
\layout Standard

The Bernoulli map is an exactly solvable example of deterministic chaos.
 This map is presented in 
\begin_inset LatexCommand \cite{key-10}

\end_inset 

 and a more thorough exposition of it is provided in 
\begin_inset LatexCommand \cite{key-2}

\end_inset 

.
 However, these authors seem to have missed or ignored certain key aspects
 of the operator, including the fact that the Hurwitz Zeta function is an
 eigenvector, as well as the action of the modular group 
\begin_inset Formula $SL(2,\mathbb{Z})$
\end_inset 

 as a symmetry group playing an important part in the analysis.
 Thus, we recap the results here, using simpler techniques, and then (making
 use of these simpler tools) extend the results in several directions.
 The motivation for the detailed development is, of course, that we will
 want to extend these tools to the GKW operator.
 
\layout Standard

The Bernoulli map is given by 
\begin_inset Formula \[
b(x)=2x-\left\lfloor 2x\right\rfloor \]

\end_inset 

 and can be thought of as poping the leading digit off of the binary expansion
 of 
\begin_inset Formula $x.$
\end_inset 

 This map has a positive Lyapunov exponent and is highly chaotic, as, in
 a certain sense, one can say that the digits of the binary expansion of
 some 'arbitrary' number are 'unpredicatable', and that the orbits of two
 close-by numbers will eventually become 'uncorellated' (after suitably
 defining what we mean by 'arbitrary' and 'unpredictable').
 
\layout Standard

The Frobenius-Perron operator of the Bernoulli map is given by
\begin_inset Formula \[
\left[U_{B}f\right](x)=\frac{1}{2}\left[f\left(\frac{x}{2}\right)+f\left(\frac{x+1}{2}\right)\right]\]

\end_inset 

 
\layout Standard

Blah blah blah.
 How much more here do we want to say? 
\layout Subsection

The Polynomial Representation
\layout Standard

Well, Provide the matrix elements.
\layout Standard


\begin_inset Formula \[
\left[U_{B}\right]_{mk}\equiv U_{mk}\equiv\left\langle m\right|U\left|k\right\rangle =\frac{\delta_{mk}}{2^{m}}+\left(\begin{array}{c}
k\\
m\end{array}\right)\frac{\Theta_{mk}}{2^{k+1}}\]

\end_inset 

 where 
\begin_inset Formula $\left(\begin{array}{c}
m\\
k\end{array}\right)$
\end_inset 

 is the binomial coefficient, and 
\begin_inset Formula \[
\Theta_{mk}=\left\{ \begin{array}{c}
0\;\textrm{ if }\; k\leq m\\
1\;\textrm{ if }\; k>m\end{array}\right.\]

\end_inset 

 is a traceless, pure upper-triangular matrix.
 Thus, for the polynomial eigenstates, we can promptly read the eigenvalues
 off the diagonal; these eigenvalues are 
\begin_inset Formula $\lambda_{n}=2^{-n}$
\end_inset 

.
 Because the matrix is upper-triangular, it is easily solvable for both
 the left and right eigenvectors, which agree perfectly w/ Driebe.
 Visually, the upper-left of this matrix looks like 
\begin_inset Formula \[
\Theta_{mk}=\left[\begin{array}{cccccc}
1 & \frac{1}{4} & \frac{1}{8} & \frac{1}{16} & \frac{1}{32} & ...\\
0 & \frac{1}{2} & \frac{1}{4} & \frac{3}{16} & \frac{1}{8}\\
0 & 0 & \frac{1}{4} & \frac{3}{16} & \frac{3}{16}\\
0 & 0 & 0 & \frac{1}{8} & \frac{1}{8}\\
0 & 0 & 0 & 0 & \frac{1}{16}\\
... &  &  &  &  & ...\end{array}\right]\]

\end_inset 


\layout Standard

The right eigenvectors are denoted by 
\begin_inset Formula $\left|B_{n}\right\rangle $
\end_inset 

 and have the vector components 
\begin_inset Formula \[
\left\langle k|B_{n}\right\rangle =\left(\begin{array}{c}
n\\
k\end{array}\right)\left(1-\Theta_{n,k}\right)B_{n-k}=\left\{ \begin{array}{ccc}
\left(\begin{array}{c}
n\\
k\end{array}\right)B_{n-k} & \;\textrm{ for }\; & k\leq n\\
0 & \;\textrm{ for }\; & k>n\end{array}\right.\]

\end_inset 

 where 
\begin_inset Formula $B_{k}$
\end_inset 

 are the Bernoulli numbers.
 We can verify this by multiplying the eigenvector into the matrix: 
\begin_inset Formula \begin{eqnarray*}
\sum_{k=0}^{\infty}\left\langle m\right|U\left|k\right\rangle \left\langle k|B_{n}\right\rangle  & = & \sum_{k=m}^{n}\left[\frac{\delta_{mk}}{2^{m}}+\left(\begin{array}{c}
k\\
m\end{array}\right)\frac{\Theta_{mk}}{2^{k+1}}\right]\left(\begin{array}{c}
n\\
k\end{array}\right)B_{n-k}\\
 & = & \frac{1}{2^{m}}\left(\begin{array}{c}
n\\
m\end{array}\right)B_{n-m}+...non-trivial-taylor-expn\\
 & = & \lambda_{n}\left\langle m|B_{n}\right\rangle \end{eqnarray*}

\end_inset 

 In coordinate space, the right eigenvectors are the Bernoulli polynomials.
\layout Standard


\begin_inset Formula \[
\sum_{k=0}^{\infty}\left\langle x|k\right\rangle \left\langle k|B_{n}\right\rangle =\sum_{k=0}^{n}\left(\begin{array}{c}
n\\
k\end{array}\right)B_{n-k}x^{k}=B_{n}(x)\]

\end_inset 

 which we can verify explicitly by substituting into the function-operator
 form of the map:
\begin_inset Formula \begin{eqnarray*}
\left[U_{B}B_{n}\right](x) & = & \frac{1}{2}\left[B_{n}\left(\frac{x}{2}\right)+B_{n}\left(\frac{x+1}{2}\right)\right]\\
 & = & \lambda_{n}B_{n}(x)\end{eqnarray*}

\end_inset 

 The last identity follows from the 
\begin_inset Quotes eld
\end_inset 

multiplication formula
\begin_inset Quotes erd
\end_inset 

 for Bernoulli polynomials.
\layout Standard

The left eigenvectors are denoted by 
\begin_inset Formula $\left\langle \tilde{B}_{n}\right|$
\end_inset 

and, for 
\begin_inset Formula $n>0$
\end_inset 

, have the components 
\begin_inset Formula \[
\left\langle \tilde{B}_{n}|k\right\rangle =\left(\begin{array}{c}
k\\
n-1\end{array}\right)\frac{1}{n}\left(\delta_{nk}+\Theta_{nk}\right)\]

\end_inset 

 The zero'th left eigenvector is a special-case; it has components 
\begin_inset Formula $\left\langle \tilde{B}_{0}|k\right\rangle =1/(k+1)$
\end_inset 

.
 The left eigenvectors can also be written out in coordinate space: 
\begin_inset Formula \begin{eqnarray*}
\left\langle \tilde{B}_{n}|x\right\rangle  & = & \sum_{k=0}^{\infty}\left\langle \tilde{B}_{n}|k\right\rangle \left\langle k|x\right\rangle \\
 & = & \sum_{k=0}^{\infty}\left\langle \tilde{B}_{n}|k\right\rangle (-)^{k}\frac{\delta^{(k)}(x)}{k!}\\
 & = & \frac{1}{n}\sum_{k=n}^{\infty}\left(\begin{array}{c}
k\\
n-1\end{array}\right)(-)^{k}\frac{\delta^{(k)}(x)}{k!}\\
 & = & \frac{(-)^{n+1}}{n!}\left[\delta^{(n-1)}(1-x)-\delta^{(n-1)}(x)\right]\end{eqnarray*}

\end_inset 

 for the 
\begin_inset Formula $n>0$
\end_inset 

case.
 The 
\begin_inset Formula $n=0$
\end_inset 

 left eigenvector is best understood by integrating it over some arbitrary
 function 
\begin_inset Formula $f(x)$
\end_inset 

: 
\begin_inset Formula \begin{eqnarray*}
\int_{0}^{1}dx\,\left\langle \tilde{B}_{0}|x\right\rangle f(x) & = & \int_{0}^{1}dx\, f(x)\sum_{k=0}^{\infty}(-)^{k}\frac{\delta^{(k)}(x)}{(k+1)!}\\
 & = & \sum_{k=0}^{\infty}\frac{f^{(k)}(0)}{(k+1)!}\\
 & = & \sum_{k=0}^{\infty}\frac{f^{(k)}(0)}{k!}\int_{0}^{1}x^{k}dx\\
 & = & \int_{0}^{1}f(x)dx\\
 & = & \left\langle \tilde{B}_{0}|f\right\rangle \end{eqnarray*}

\end_inset 

 Its instructive to look at the other left eignvectors acting on some function
 
\begin_inset Formula $f(x)$
\end_inset 

; these can be written as 
\begin_inset Formula \[
\left\langle \tilde{B}_{n}|f\right\rangle =\frac{1}{n!}\left[f^{(n-1)}(1)-f^{(n-1)}(0)\right]\]

\end_inset 

Note that the left eigenvectors are adjoint ot the Bernoulli polynomials.
 Thus, the identity operator 
\begin_inset Formula $\mathbb{I}_{B}=\sum_{n=0}^{\infty}\left|B_{n}\right\rangle \left\langle \tilde{B}_{n}\right|$
\end_inset 

turns out to be the Euler-Maclaurin summation formula in disguise, which
 we can see more easily by writing 
\begin_inset Formula \begin{eqnarray*}
f(x) & = & \left\langle x|f\right\rangle \\
 & = & \sum_{m=0}^{M}B_{m}(x)\left\langle \tilde{B}_{m}|f\right\rangle -\frac{1}{M!}\int_{0}^{1}dy\, B_{M}(x-y)\; f^{(M)}(y)\end{eqnarray*}

\end_inset 

 Its not to hard to explicitly validate completeness: one finds that 
\begin_inset Formula \[
\left\langle j\right|\mathbb{I}_{B}\left|k\right\rangle =\left\langle j\right|\sum_{n=0}^{\infty}\left|B_{n}\right\rangle \left\langle \tilde{B}_{n}\right|\left|k\right\rangle =\delta_{jk}\]

\end_inset 

 One can also check orthogonality over coordinate space, and explicitly
 verify that 
\begin_inset Formula \[
\int_{0}^{1}dx\left\langle B_{n}|x\right\rangle \left\langle x|\tilde{B}_{m}\right\rangle =\frac{1}{m!}\int_{0}^{1}\frac{d^{m}}{dx^{m}}B_{n}(x)\, dx=\delta_{nm}\]

\end_inset 


\layout Standard

Thus, in the polynomial representation, the Frobenius-Perrron operator of
 the Bernoulli map is 
\begin_inset Formula \[
U_{B}=\sum_{n=0}^{\infty}\left|B_{n}\right\rangle \lambda_{n}\left\langle \tilde{B}_{n}\right|\]

\end_inset 

 
\layout Subsection

The Fourier Representation 
\layout Standard

The Koopman operator of the Bernoulli Map has the property of taking a function
 and making two copies of it.
 That is, 
\begin_inset Formula \begin{eqnarray*}
\left[K_{B}f\right](y) & = & \int_{0}^{1}\delta\left(x-b(y)\right)f(x)\, dx\\
 & = & f(b(y))\\
 & = & f(2y)\theta(1-2y)+f(2y-1)\theta(2y-1)\end{eqnarray*}

\end_inset 

 where 
\begin_inset Formula $\theta(x)$
\end_inset 

 is the step function, identically zero for 
\begin_inset Formula $x<0$
\end_inset 

 and identically one for 
\begin_inset Formula $x>0$
\end_inset 

.
 The Koopman operator for the Bernoulli map is not faithfully representatble
 in the polynomial basis; this can be seen in two ways.
 First, it introduces a discontinuity at 
\begin_inset Formula $x=1/2$
\end_inset 

 which the polynomials cannot move beyond; the radius of the circle of converge
 is limited by this singularity.
 Secondly, it takes a function and more-or-less makes it periodic; again,
 the polynomials cannot cope directly with this.
 Thus, we are motivated to explore the Fourier representation, if only to
 express the Koopman operator.
 
\layout Standard

It turns out to be exceedingly simple to find this operator in the Fourier
 basis.
 If we write 
\begin_inset Formula \[
f(x)=\sum_{n}a_{n}\cos2\pi nx\;+b_{n}\sin2\pi nx\]

\end_inset 

 then 
\begin_inset Formula \[
\left[K_{B}f\right](x)=\sum_{n}a_{n}\cos4\pi nx\;+b_{n}\sin4\pi nx\]

\end_inset 

 or, in Dirac notation, 
\begin_inset Formula $\left\langle em|K_{B}|en\right\rangle =\delta_{2m,n}$
\end_inset 

.
 This is a very singular operator in this basis.
 Visually, it has the distinctive appearance of 
\begin_inset Formula \[
K_{B}=\left[\begin{array}{cccccc}
1 & 0 & 0 & 0 & 0 & ...\\
0 & 0 & 0 & 0 & ...\\
0 & 1 & 0 & 0\\
0 & 0 & 0 & 0\\
0 & 0 & 1 & 0 & ...\\
...\end{array}\right]\]

\end_inset 

 where every other row consists of zeros.
 In this same basis, 
\begin_inset Formula $U_{B}$
\end_inset 

is equally remarkable: it is literally the transpose: that is 
\begin_inset Formula $K_{B}=U_{B}^{T}$
\end_inset 

 in this basis, and so 
\begin_inset Formula \[
U_{B}=\left[\begin{array}{cccccc}
1 & 0 & 0 & 0 & 0 & ...\\
0 & 0 & 1 & 0 & 0\\
0 & 0 & 0 & 0 & 1\\
0 & 0 & 0 & 0 & 0\\
0 & 0 & 0 & 0 & ...\\
...\end{array}\right]\]

\end_inset 

 We can see that in this representation, we have 
\begin_inset Formula $U_{B}K_{B}=1$
\end_inset 

 but 
\begin_inset Formula $K_{B}U_{B}\neq1$
\end_inset 

, just as in the coordinate-space representation.
 It is very instructive to verify that the Bernoulli polynomials are still
 eigenfunctions in this representation.
 For 
\begin_inset Formula $n\neq0$
\end_inset 

, we have 
\begin_inset Formula \[
\int_{0}^{1}B_{1}(x)\,\sin(2\pi nx)\, dx=\frac{-1}{\pi n}\]

\end_inset 

 and it is straightforward to visually verify that 
\begin_inset Formula $U_{B}B_{1}=\frac{1}{2}B_{1}$
\end_inset 

.
 By working with the generator for the Bernoulli polynomials, 
\begin_inset Formula \[
\frac{te^{xt}}{e^{t}-1}=\sum_{n=0}^{\infty}B_{n}(x)\,\frac{t^{n}}{n!}\]

\end_inset 

 one can immediately find, for 
\begin_inset Formula $m\neq0$
\end_inset 

, the Fourier components 
\begin_inset Formula \[
\int_{0}^{1}B_{n}(x)\,\cos(2\pi mx)\, dx=\left\{ \begin{array}{cc}
0 & \;\textrm{ for n odd }\\
\left(-\right)^{1+n/2}n!/\left(2\pi m\right)^{n} & \;\textrm{ for n even }\end{array}\right.\]

\end_inset 

 and 
\begin_inset Formula \[
\int_{0}^{1}B_{n}(x)\,\sin(2\pi mx)\, dx=\left\{ \begin{array}{cc}
0 & \;\textrm{ for n even }\\
\left(-\right)^{(n+1)/2}n!/\left(2\pi m\right)^{n} & \;\textrm{ for n odd }\end{array}\right.\]

\end_inset 

 Applying the Fourier-representation 
\begin_inset Formula $U_{B}$
\end_inset 

 to these to these vector components makes it immediately clear how the
 eigenvalue of 
\begin_inset Formula $1/2^{n}$
\end_inset 

 is associated with the eigenvector 
\begin_inset Formula $B_{n}$
\end_inset 

.
 
\layout Subsection

The Hurwitz Zeta Eigenfunctions
\layout Standard

The Fourier representation also makes it clear that any vector with vector
 components 
\begin_inset Formula $a_{n}=1/n^{s}$
\end_inset 

 will be an eigenvector of 
\begin_inset Formula $U_{B}$
\end_inset 

 associated with the eigenvalue 
\begin_inset Formula $\lambda=1/2^{s}$
\end_inset 

.
 In coordinate space, we can write these eigenfunctions as 
\begin_inset Formula \[
\beta(x;s)=2\Gamma(s+1)\sum_{n=1}^{\infty}\frac{\exp(2\pi inx)}{\left(2\pi n\right)^{s}}\]

\end_inset 

 which transform as 
\begin_inset Formula $U_{B}\beta(x;s)=2^{-s}\beta(x;s)$
\end_inset 

.
 Given the nature of summation, we see that the series is strictly convergent
 for any complex-valued 
\begin_inset Formula $s$
\end_inset 

 with 
\begin_inset Formula $\Re s>1$
\end_inset 

.
 This series recreates the Bernoulli polynomials for integer values of 
\begin_inset Formula $n$
\end_inset 

, so for example, 
\begin_inset Formula $\Re\beta(x;2)=B_{2}(x)$
\end_inset 

 and 
\begin_inset Formula $\Im\beta(x;3)=B_{3}(x)$
\end_inset 

 and generally 
\begin_inset Formula $\Re\left[\left(-i\right)^{n}\beta(x;n)\right]=-B_{n}(x)$
\end_inset 

.
 
\layout Standard

It turns out that these eigenfunctions are essentially a form of the Hurwitz
 Zeta function 
\begin_inset Formula \[
\zeta(s,x)=\sum_{n=0}^{\infty}\frac{1}{\left(n+x\right)^{s}}\]

\end_inset 

 and that, in fact, the Hurwitz Zeta itself is an eigenfunction, with eigenvalue
 
\begin_inset Formula $2^{s-1}$
\end_inset 

.
 We can confirm this by following a very old-fashioned recipie for obtaining
 the functional relation for a zeta-like sum.
 We start by expressing the gamma function as 
\begin_inset Formula \[
\int_{0}^{\infty}dy\, e^{-2\pi ny}y^{s-1}=\frac{\Gamma(s)}{(2\pi n)^{s}}\]

\end_inset 

 Substituting into the expression for 
\begin_inset Formula $\beta$
\end_inset 

 and performing the sum, we find we can write 
\begin_inset Formula \[
\beta(x;s)=2s\int_{0}^{\infty}dy\,\frac{y^{s-1}}{\exp\left(-2\pi i(x+iy)\right)-1}\]

\end_inset 

 Then, following a traditional trick [ref Edwards] we can re-write this
 as a contour integral 
\begin_inset Formula \[
\beta(x;s)=\frac{-is}{\sin\pi s}\oint\frac{(-y)^{s}}{\exp\left(-2\pi i(x+iy)\right)-1}\;\frac{dy}{y}\]

\end_inset 

 where the contour is taken to extend from 
\begin_inset Formula $+\infty+i\epsilon$
\end_inset 

, running just above the positive real axis, to the origin, circling the
 origin in a clockwise fashion, and returning to 
\begin_inset Formula $+\infty-i\epsilon$
\end_inset 

 just under the real axis.
 The contour essentially encloses the cut of the logarithm in the expression
 
\begin_inset Formula $(-y)^{s}=\exp s\,\log(-y)$
\end_inset 

.
 The old fashioned recipie calls for closing the contour at infinity (in
 a counter-clockwise direction) and then taking the dubious step of asserting
 Cauchy's Theorem to equate the integral around the cut to the sum of the
 poles, where we note that we have a pole whenever 
\begin_inset Formula $x+iy=n$
\end_inset 

 for some integer 
\begin_inset Formula $n$
\end_inset 

.
 By doing this we get the formal summation 
\begin_inset Formula \[
\frac{i\sin\pi s}{s}\beta(x;s)=\exp\left(\frac{i\pi s}{2}\right)\sum_{n=-\infty}^{\infty}(n-x)^{s-1}\]

\end_inset 

 We call this a formal sum, since the preceeding steps required taking 
\begin_inset Formula $\Re s>1$
\end_inset 

 whereas now we need to take 
\begin_inset Formula $\Re s<0$
\end_inset 

.
 This is a bit of jiggery-pokery that is common for this type of presentation;
 and a very different set of tools is required to do better.
 So we proceed.
 We re-write this sum as 
\begin_inset Formula \[
\frac{i\sin\pi s}{s}\beta(x;s)=\exp\left(\frac{i\pi s}{2}\right)\left[\sum_{n=0}^{\infty}(n+(1-x))^{s-1}+e^{-i\pi(s-1)}\sum_{n=0}^{\infty}(n+x)^{s-1}\right]\]

\end_inset 

 where we were minful to rotatee counter-clockwise for 
\begin_inset Formula $n<0$
\end_inset 

 when replacing 
\begin_inset Formula $(-)^{n}$
\end_inset 

 by 
\begin_inset Formula $e^{-i\pi n}$
\end_inset 

 instead of the sloppy and incorrect 
\begin_inset Formula $e^{i\pi n}$
\end_inset 

.
 Recognizing the sums as the Hurwitz Zeta, this then gives us the desired
 result: 
\begin_inset Formula \[
\beta(x;s)=\frac{is}{\sin\pi s}\left[e^{-i\pi s/2}\zeta(1-s,x)-e^{i\pi s/2}\zeta(1-s,1-x)\right]\]

\end_inset 

 It is straightforward to invert this and solve for 
\begin_inset Formula $\zeta$
\end_inset 

; one gets 
\begin_inset Formula \[
\zeta(1-s,x)=\frac{1}{2s}\left[e^{-i\pi s/2}\beta(x;s)+e^{i\pi s/2}\beta(1-x;s)\right]\]

\end_inset 

 thus proving the assertion that the Hurwitz Zeta is an eigenfunction of
 the Bernoulli Operator, with eigenvalue 
\begin_inset Formula $2^{z-1}$
\end_inset 

.
 To verify the correctness of the above steps, we can expand the exponentials
 in terms of thier real and imaginary parts, to find that 
\layout Standard


\begin_inset Formula \[
\zeta(z,x)=\frac{2\Gamma(1-z)}{\left(2\pi\right)^{1-z}}\left[\sin\left(\frac{\pi z}{2}\right)\sum_{n=1}^{\infty}\frac{\cos(2\pi nx)}{n^{1-z}}+\cos\left(\frac{\pi z}{2}\right)\sum_{n=1}^{\infty}\frac{\sin(2\pi nx)}{n^{1-z}}\right]\]

\end_inset 

 which agrees with standard textbook presentations of the Hurwitz Zeta.
 
\layout Subsection

Visualizing the Hurwitz Zeta Eigenfunctions
\layout Standard

Perhaps one surprising aspect of this result is that the Hurwitz Zeta eigenfunct
ions appear to be smooth, since one is conditioned to expect that the only
 continuous-spectrum eigenfunctions of a Frobenius-Perron style operator
 are fractal.
 Its worthwhile to take a few minutes to get aquainted with the shape of
 the zeta.
 This section shows a number of graphs, and discusses the analytic structure
 of the eigenvalues.
 We'll see that the eigenfunctions are 
\begin_inset Formula $C^{\infty}$
\end_inset 

 in 
\begin_inset Formula $x$
\end_inset 

 for almost all 
\begin_inset Formula $x$
\end_inset 

: everywhere except at the endpoints 
\begin_inset Formula $x=0,1$
\end_inset 

.
 Thus, these are not 
\begin_inset Quotes eld
\end_inset 

physical
\begin_inset Quotes erd
\end_inset 

 eigenstates, if 
\begin_inset Formula $C^{\infty}$
\end_inset 

 in 
\begin_inset Formula $x$
\end_inset 

 is placed as a demand for being 
\begin_inset Quotes eld
\end_inset 

physical
\begin_inset Quotes erd
\end_inset 

.
 We also find that there are eigenfunctions that have eigenvalues greater
 than one; however, these are not square-integrable: they are divergent
 at 
\begin_inset Formula $x=0,1$
\end_inset 

.
 However, in all other respects, the eigenfunctions are analytically quite
 well-behaved, even if a bit 
\begin_inset Quotes eld
\end_inset 

lumpy
\begin_inset Quotes erd
\end_inset 

.
 
\layout Standard

Although we have a continuous spectrum, the eigenvalues are degenerate,
 with a multiplicity of countable infinity.
 We can see this by writing 
\begin_inset Formula $s=\sigma+i\tau$
\end_inset 

 in terms of its real and imaginary components.
 Then the eigenvalue is 
\begin_inset Formula $\lambda=2^{-s}=2^{-\sigma}\exp(-i\tau\ln2)$
\end_inset 

 and it belongs to a family of eigenvectors with 
\begin_inset Formula $\tau'=\tau+2\pi n/\ln2$
\end_inset 

 .
 The next five figures show these.
\layout Standard


\begin_inset Float figure
wide false
collapsed true

\layout Caption

Beta Real Part
\layout Standard


\begin_inset Graphics
	filename zeta-2.2345-04.png

\end_inset 


\layout Standard

This figure illustrates a family of eigenvectors 
\begin_inset Formula $\beta(x;s)$
\end_inset 

 having the same eigenvalue.
 To be precise, the illustration shows 
\begin_inset Formula \[
\Re\left[\beta(x;s)+\beta(-x;s)\right]/2\left|\Gamma(1+s)\right|\]

\end_inset 

 for values of 
\begin_inset Formula $s=\sigma+2\pi in/\ln2$
\end_inset 

 for 
\begin_inset Formula $\sigma=2.345$
\end_inset 

 and n=0,1,2,3,4.
 Note that 
\begin_inset Formula $\left|\Gamma(1+s)\right|$
\end_inset 

gets very small as n gets large, and so the normalization brings them to
 visually comparable values.
 Other real values of 
\begin_inset Formula $\sigma$
\end_inset 

 can be understood by recalling that 
\begin_inset Formula $\beta$
\end_inset 

 essentially interpolatees between Bernoulli polynomials at integer values
 of 
\begin_inset Formula $\sigma$
\end_inset 

.
 In short, they'll all look more or less like this.
 
\end_inset 


\layout Standard


\begin_inset Float figure
wide false
collapsed true

\layout Caption

Beta Magnitude
\layout Standard


\begin_inset Graphics
	filename zeta-abs-2.2345-04.png

\end_inset 


\layout Standard

This figure illustrates a family of eigenvectors 
\begin_inset Formula $\beta(x;s)$
\end_inset 

 having the same eigenvalue.
 To be precise, the illustration shows 
\begin_inset Formula \[
\left|\beta(x;s)+\beta(-x;s)\right|/2\left|\Gamma(1+s)\right|\]

\end_inset 

 for values of 
\begin_inset Formula $s=\sigma+2\pi in/\ln2$
\end_inset 

 for 
\begin_inset Formula $\sigma=2.345$
\end_inset 

 and n=0,1,2,3,4.
 Note that 
\begin_inset Formula $\left|\Gamma(1+s)\right|$
\end_inset 

gets very small as n gets large, and so the normalization brings them to
 visually comparable values.
 
\end_inset 


\layout Standard


\begin_inset Float figure
wide false
collapsed true

\layout Caption

Exp figure
\layout Standard


\begin_inset Graphics
	filename zeta-exp-2.2345-04.png

\end_inset 


\layout Standard

This figure illustrates a family of eigenvectors 
\begin_inset Formula $\beta(x;s)$
\end_inset 

 having the same eigenvalue.
 To be precise, the illustration shows 
\begin_inset Formula \[
\Re\beta(x;s)/2\left|\Gamma(1+s)\right|\]

\end_inset 

 for values of 
\begin_inset Formula $s=\sigma+2\pi in/\ln2$
\end_inset 

 for 
\begin_inset Formula $\sigma=2.345$
\end_inset 

 and n=0,1,2,3,4.
 
\end_inset 


\layout Standard


\begin_inset Float figure
wide false
collapsed true

\layout Caption

another magnit
\layout Standard


\begin_inset Graphics
	filename zeta-emag-2.2345-04.png

\end_inset 


\layout Standard

This figure illustrates a family of eigenvectors 
\begin_inset Formula $\beta(x;s)$
\end_inset 

 having the same eigenvalue.
 To be precise, the illustration shows 
\begin_inset Formula \[
\left|\beta(x;s)\right|/2\left|\Gamma(1+s)\right|\]

\end_inset 

 for values of 
\begin_inset Formula $s=\sigma+2\pi in/\ln2$
\end_inset 

 for 
\begin_inset Formula $\sigma=2.345$
\end_inset 

 and n=0,1,2,3,4.
 Note that curiously, these functions seem to be smoother for larger x and
 seem to have vanishing ripples as x approaches zero.
 Curiously, the ripples seem to have a period of oscillation of approximately
 
\begin_inset Formula $nx$
\end_inset 

, which can best be seen in the n=1 curve, which seems to hold a complete
 cycle between 1, 1/2, 1/4, 1/8, ...
\end_inset 


\layout Standard


\begin_inset Float figure
wide false
collapsed true

\layout Caption

the arg
\layout Standard


\begin_inset Graphics
	filename zeta-arg-2.2345-04.png

\end_inset 


\layout Standard

This figure illustrates a family of eigenvectors 
\begin_inset Formula $\beta(x;s)$
\end_inset 

 having the same eigenvalue.
 To be precise, the illustration shows 
\begin_inset Formula \[
\arg\beta(x;s)/2\left|\Gamma(1+s)\right|\]

\end_inset 

 for values of 
\begin_inset Formula $s=\sigma+2\pi in/\ln2$
\end_inset 

 for 
\begin_inset Formula $\sigma=2.345$
\end_inset 

 and n=0,1,2,3,4.
 
\end_inset 

 
\layout Standard

Note that there are eigenfunctions with eigenvalues greater than one, essentiall
y because the Hurwitz Zeta can be analytically continued to everywhere except
 for a pole at 
\begin_inset Formula $z=1$
\end_inset 

.
 Examining these eigenfunctions, one quickly discovers that these are not
 square-integrable: they have singularities located at 
\begin_inset Formula $x=0,1$
\end_inset 

.
 That is, for for 
\begin_inset Formula $\Re z>0$
\end_inset 

, that the Hurwitz Zeta 
\begin_inset Formula $\zeta(z,x)$
\end_inset 

 has a clear singularity 
\begin_inset Formula $x^{-z}$
\end_inset 

 at 
\begin_inset Formula $x=0$
\end_inset 

.
 We remove this explicitly, and write 
\begin_inset Formula \begin{eqnarray*}
\frac{\sin\pi s}{is}\beta(x;s) & = & \frac{e^{-i\pi s/2}}{x^{1-s}}-\frac{e^{i\pi s/2}}{(1-x)^{1-s}}+\\
 &  & e^{-i\pi s/2}\left(\zeta(1-s,x)-x^{s-1}\right)-e^{i\pi s/2}\left(\zeta(1-s,1-x)-(1-x)^{s-1}\right)\end{eqnarray*}

\end_inset 

 The first part of the equation above encapsulates the singularities at
 
\begin_inset Formula $x=0,1$
\end_inset 

 when working with eigenvalues 
\begin_inset Formula $\left|\lambda\right|=\left|2^{-s}\right|>1$
\end_inset 

, that is, with 
\begin_inset Formula $\Re s<0$
\end_inset 

.
 The remaining term is well-behaved and is shown in one of the accompanying
 figures.
 
\layout Standard


\begin_inset Float figure
wide false
collapsed true

\layout Caption

non-singular part
\end_inset 

 
\layout Standard

Note that when 
\begin_inset Formula $\left|\lambda\right|=\left|2^{-s}\right|<1/2$
\end_inset 

, that is, when 
\begin_inset Formula $\Re s>1$
\end_inset 

, there is no singularity, and 
\begin_inset Formula $\beta(x;s)$
\end_inset 

 is finite on the entier interval 
\begin_inset Formula $x\in[0,1]$
\end_inset 

 including the endpoints.
 For 
\begin_inset Formula $1/2<\Re s\leq1$
\end_inset 

 there is a bit of funny-business at the endpoints, that is, there is a
 weak divergence there, but the function overall remains square-integrable.
 Things break loose after that, with the exception of 
\begin_inset Formula $s=0$
\end_inset 

, where we have 
\begin_inset Formula $\beta(x;0)=-1$
\end_inset 

, a constant independent of 
\begin_inset Formula $x$
\end_inset 

.
 This essentially follows from the nature of differentiation on the Bernoulli
 polynomials, which we'll see below.
 Note, however, that for 
\begin_inset Formula $s$
\end_inset 

 near zero, the function 
\begin_inset Formula $\beta(x;s)$
\end_inset 

 has severe ringing artifacts in 
\begin_inset Formula $x$
\end_inset 

, suffering from a variation of Gibbs Phenomenon.
 
\layout Standard


\begin_inset Float figure
wide false
collapsed false

\layout Caption

Ringing
\end_inset 


\layout Standard

We conclude by noting that 
\begin_inset Formula $\beta$
\end_inset 

 is 
\begin_inset Formula $C^{\infty}$
\end_inset 

 for 
\begin_inset Formula $x\in(0,1)$
\end_inset 

 bot not at the endpoints 
\begin_inset Formula $x=0,1$
\end_inset 

.
 This can be easily seen by writing the derivative 
\begin_inset Formula \[
\frac{d}{dx}\beta(x;s)=2\pi i\beta(x;s-1)\]

\end_inset 

 and so even if we start with 
\begin_inset Formula $\Re s>1$
\end_inset 

, each derivative carries us one step closer into the danger zone.
 
\layout Subsection

The Kernel
\layout Standard

What is the kernel of 
\begin_inset Formula $U_{B}$
\end_inset 

? It is the set of functions that have odd symmetry.
 blahh xxxx wrongo-boyo ...
 This implies that 'half' of all square-integrable functions are in the
 kernel.
 This is a huge space.
 The quotient space of the implied isomorphism thus has the Bernoulli polynomial
s as the representative elements.
 This is I think the correct way to relate coordinate space to the Hilbert
 space, is by means of the quotient space generated by the kernel of the
 time-evolution operator.
 This provides the isomorphisms, and any other square-integrable function
 is thus expandable as a linear combination of the polynomial eigenfunctions
 plus the kernel.
 Talk about 
\begin_inset Formula $H$
\end_inset 

 and its spectrum.
 Symmetry symmetry talk about the symmetry group of the kernel.
 
\layout Subsection

The Symmetry Group
\layout Standard

Note that 
\begin_inset Formula $\left[U_{B}f\right](x)=\frac{1}{2}\left(f(g_{D}(x))+f(r_{D}g_{D}r_{D}(x)\right)$
\end_inset 

 and so on.
\layout Subsection

The Takagi Representation 
\layout Standard

Note that the the iterated tent map behaves sort-of like a shift state,
 in that 
\begin_inset Formula \[
\left[U_{B}\tau^{k}\right](x)=\tau^{k-1}(x)\]

\end_inset 

 although it does not terminate properly for a shift state: 
\begin_inset Formula \[
\left[U_{B}\tau\right](x)=\frac{1}{2}\]

\end_inset 

 (a true shift state would vanish on the final iteration).
 Thus we see that the Takagi curve transforms as 
\begin_inset Formula \[
\left[U_{B}t_{w}\right](x)=\frac{1}{2}+wt_{w}(x)\]

\end_inset 

 under the Bernoullli operator.
 We can use this to build an eigenfunction 
\begin_inset Formula \[
b_{w}(x)=\frac{-1}{2(1-w)}+t_{w}(x)\]

\end_inset 

 so that 
\begin_inset Formula $U_{B}b_{w}=wb_{w}$
\end_inset 

.
 
\layout Standard

We can quickly obtain the other eigenvectors by starting with the Takagi
 curves that transform under the higher-dimensional representations of 
\begin_inset Formula $SL(2,\mathbb{Z})$
\end_inset 

.
 We do this by noting that we can write the Bernoulli transfer operator
 as 
\begin_inset Formula \[
\left[U_{B}f\right](x)=\frac{1}{2}\left(f(g_{D}(x))+f(r_{D}g_{D}r_{D}(x)\right)\]

\end_inset 

 so that if 
\begin_inset Formula $t_{n,w}(x)$
\end_inset 

 is a Takagi curve that transforms under the 
\begin_inset Formula $n$
\end_inset 

-dimensional representation, then 
\begin_inset Formula $U_{B}$
\end_inset 

 obviously is represented by 
\begin_inset Formula $(g_{n}+r_{n}g_{n}r_{n})/2$
\end_inset 

 where 
\begin_inset Formula $r_{n},g_{n}\in GL(n,\mathbb{R})$
\end_inset 

 are the generators of the 
\begin_inset Formula $n$
\end_inset 

-dimensional represenation of 
\begin_inset Formula $SL(2,\mathbb{Z})$
\end_inset 

.
 As before, we have, up to conjugacy, only two representations, the even
 and odd-parity representations.
\layout Subsection

The Continuous Fractal Spectrum
\layout Standard

The continuous-spectrum eigenfunctions of the Bernoulli map are of course
 a generalizastion of the Takagi-Landsberg curve to complex values.
 These eigenfunctions are 
\begin_inset Formula \[
\phi_{z,l}(x)=\sum_{n=0}^{\infty}z^{n}\exp\left(2\pi i\;2^{n}\left(2l+1\right)x\right)\]

\end_inset 

 which have eigenvalue 
\begin_inset Formula $z$
\end_inset 

: that is 
\begin_inset Formula $[U_{B}\phi_{z,l}](x)=z\phi_{z,l}(x)$
\end_inset 

.
 These are quite beautiful fractals (xxx provide a picture here).
 Symmetry is the name of the game here.
 
\layout Standard

These are protype forms for and the famous and beautiful Levy Dragons (reference
 the Paul Levy 1938 paper here) (actually Levy was trying to generalize
 the Koch curves).
 
\layout Standard

Note that when we go to look at the tesselatation of the hyperbolic plane
 by the hyperbolic triangle under the symmetry of the modular group, I think
 we get the tesselation of the plane with Levy's Dragons, which I think
 is the point that Paul Levy was trying to make.
 So this fits all very nicely: we have a direct 1-1 correspondance between
 tesselations on the hyperplane with tessalations of real space by fractal
 curves.
 It is sufficient to talk about one to talk about the other.
\layout Standard

This also means that Bournoulli map also makes for a good toy example of
 quantum chaos.
 In quantum chaos, the eigenfunctions must form a complete set in the sense
 that for any given point in space, there must exist at least one eigenfunction
 that is non-vanishing on that point.
 In other words, the eigenfunctions of a quantum-chaotic system must tesselate
 the space in which they live.
 The toy example of this kind of tesselation is the Levy Dragon.
 
\layout Section

The Gauss-Kuzmin-Wirsing Operator
\layout Standard

The iterated map is 
\begin_inset Formula \[
h(x)=\frac{1}{x}-\left\lfloor \frac{1}{x}\right\rfloor \]

\end_inset 

 The FP operator for this map is the GKW.
 Blah Blah.
 Give the usual expression of matrix elements.
 Give the connection to Riemann Zeta.
 Give the collection of interesting summations.
 Give the Riemann Hypothesis as a vector equation.
 
\layout Standard


\begin_inset Formula \[
\left[U_{h}f\right](x)=\sum_{n=1}^{\infty}\frac{1}{(n+x)^{2}}f\left(\frac{1}{n+x}\right)\]

\end_inset 

 There is one known eigenvector, 
\begin_inset Formula $f(x)=1/(1+x)$
\end_inset 

 which corresponds to the unit eigenvalue.
 The others do not seem to be (by combinatorial search) any simple combination
 or summation of simple functions, including the digamma, and etc.
 Provide the details.
 We do have the identities 
\begin_inset Formula \[
\left[U_{h}x^{n}\right](x)=\]

\end_inset 


\layout Section

The Singular Sawtooth of the First Kind
\layout Standard

The frac function 
\begin_inset Formula $h(x)=\frac{1}{x}-\left\lfloor \frac{1}{x}\right\rfloor $
\end_inset 

 is used in the construction of continued fractions.
 In this section, we will study a model for this function, where we replace
 the curve by a set of straight lines arranged between values of 
\begin_inset Formula $1/n$
\end_inset 

 for integer 
\begin_inset Formula $n$
\end_inset 

.
 This forms a singular sawtooth, with a singularity at 
\begin_inset Formula $x=0.$
\end_inset 

 
\layout Standard


\begin_inset Formula \[
w(x)=\left\{ \begin{array}{ccc}
2-2x & \;\textrm{ for \;} & \frac{1}{2}<x\leq1\\
3-6x & \;\textrm{ for \;} & \frac{1}{3}<x\leq\frac{1}{2}\\
4-12x & \;\textrm{ for \;} & \frac{1}{4}<x\leq\frac{1}{3}\\
n+1-n(n+1)x & \;\textrm{ for \;} & \frac{1}{n+1}<x\leq\frac{1}{n}\end{array}\right.\]

\end_inset 

 This function is pictured in figure 
\begin_inset LatexCommand \ref{cap:The-Singular-Sawtooth}

\end_inset 

.
 
\layout Standard


\begin_inset Float figure
wide false
collapsed false

\layout Caption


\begin_inset LatexCommand \label{cap:The-Singular-Sawtooth}

\end_inset 

The Singular Sawtooth of the First Kind
\layout Standard


\begin_inset Graphics
	filename saw-first.png

\end_inset 


\layout Standard

This sawtooth function joins values of 
\begin_inset Formula $1/n$
\end_inset 

 with straight lines.
\end_inset 

 The Frobenius-Perron operator for this function is exactly solvable, and
 provides a toy model of the Gauss-Kuzmin-Wirsing operator.
 The Frobenius-Perron operator of this sawtooth, acting on a general function
 
\begin_inset Formula $f(x)$
\end_inset 

, is given by
\begin_inset Formula \[
\left[U_{w}f\right](x)=\sum_{x':w(x')=x}\frac{f(x')}{\left|dw(x')/dx'\right|}=\sum_{n=1}^{\infty}\frac{1}{n(n+1)}f\left(\frac{n+1-x}{n(n+1)}\right)\]

\end_inset 

We develop a representation of this operator in the polynomial-basis Hilbert
 space below.
\layout Subsection

The Polynomial Eigenfunctions
\layout Standard

We will want to consider the action of this operator on polynomials of 
\begin_inset Formula $y=1-x$
\end_inset 

, so that we can express 
\begin_inset Formula $f(x)$
\end_inset 

 as a Taylor's expansion about 
\begin_inset Formula $y=0$
\end_inset 

.
 Lets make this change-of-variable now, and write 
\begin_inset Formula \[
f(y)=\sum_{k=0}^{\infty}\frac{f^{(k)}(0)}{k!}y^{k}\equiv\sum_{k=0}^{\infty}a_{k}y^{k}\]

\end_inset 

 so that 
\begin_inset Formula \[
\left[U_{w}f\right](y)=\sum_{k=0}^{\infty}b_{k}y^{k}=\sum_{n=1}^{\infty}\frac{1}{n(n+1)}\sum_{k=0}^{\infty}a_{k}\left(\frac{n+y}{n(n+1)}\right)^{k}\]

\end_inset 

 Rarranging the sums, and equating terms with the same power of 
\begin_inset Formula $y$
\end_inset 

, we define the matrix elements 
\begin_inset Formula $W_{mk}$
\end_inset 

 so that 
\begin_inset Formula \[
b_{m}=\sum_{k=0}^{\infty}W_{mk}a_{k}\]

\end_inset 

 and find that 
\begin_inset Formula \[
W_{mk}=\left\{ \begin{array}{ccc}
\left(\begin{array}{c}
k\\
m\end{array}\right)\sum_{n=1}^{\infty}n^{-m-1}(n+1)^{-k-1} & \;\textrm{ for \;} & k\geq m\\
0 & \;\textrm{ for \;} & k<m\end{array}\right.\]

\end_inset 

 where we use 
\begin_inset Formula $\left(\begin{array}{c}
k\\
m\end{array}\right)$
\end_inset 

 to denote the binomial coefficient.
 This matrix is upper-triangular, and thus has its eigenvalues along the
 diagonal.
 These are 
\begin_inset Formula \[
\lambda_{k}=\sum_{n=1}^{\infty}\frac{1}{n^{k+1}(n+1)^{k+1}}\]

\end_inset 

 so that 
\begin_inset Formula $\lambda_{0}=1$
\end_inset 

 and 
\begin_inset Formula $\lambda_{1}=2\zeta(2)-3$
\end_inset 

 where 
\begin_inset Formula $\zeta(x)$
\end_inset 

 is the Riemann zeta.
 Numerically, we can see that the first few eigenvalues are 
\begin_inset Formula $\lambda_{1}=0.289868...$
\end_inset 

 and 
\begin_inset Formula $\lambda_{2}=0.130396...$
\end_inset 

 and 
\begin_inset Formula $\lambda_{3}=0.0633278...$
\end_inset 

 and 
\begin_inset Formula $\lambda_{4}=0.031383...$
\end_inset 

 and 
\begin_inset Formula $\lambda_{5}=0.0156468...$
\end_inset 

 We can trivialy see that the ratio of eigenvalues settles down to 
\begin_inset Formula $\lambda_{k}/\lambda_{k+1}=2$
\end_inset 

 for large 
\begin_inset Formula $k$
\end_inset 

, since the first term of the sum will dominate for large 
\begin_inset Formula $k$
\end_inset 

.
 
\layout Standard

We can solve the operator through recursion on the matrix elements of a
 related operator, by observing that 
\begin_inset Formula \[
Z_{mk}\equiv\sum_{n=1}^{\infty}\frac{1}{n^{m}(n+1)^{k}}\left[\frac{1}{n}-\frac{1}{n+1}\right]=Z_{m,k-1}-Z_{m-1,k}\]

\end_inset 

 These recurrance relations are bounded on the edges by 
\begin_inset Formula $Z_{00}=1$
\end_inset 

, 
\begin_inset Formula $Z_{01}=2-\zeta(2)$
\end_inset 

 and thus 
\begin_inset Formula \begin{eqnarray*}
Z_{0k} &  & =Z_{0,k-1}-\left(\zeta(k+1)-1\right)=1-\sum_{j=1}^{k}\left[\zeta(j+1)-1\right]\end{eqnarray*}

\end_inset 

 and 
\begin_inset Formula $Z_{10}=\zeta(2)-1$
\end_inset 

 so that 
\begin_inset Formula \[
Z_{m0}=\zeta(m+1)-Z_{m-1,0}=(-)^{m}\left[1+\sum_{j=1}^{m}(-)^{j}\zeta(j+1)\right]\]

\end_inset 

 and we have 
\begin_inset Formula $Z_{mk}=W_{mk}$
\end_inset 

 for 
\begin_inset Formula $m\leq k$
\end_inset 

 .
 The first few eigenfunctions are 
\begin_inset Formula \[
e_{0}(y)=1\]

\end_inset 

 
\begin_inset Formula \[
e_{1}(y)=1-2y\]

\end_inset 

 
\begin_inset Formula \begin{eqnarray*}
e_{2}(y) & = & \frac{15-13\zeta(2)-9\zeta(3)+2\zeta(2)[\zeta(2)+3\zeta(3)]}{3(13\zeta(2)-8\zeta(3))(3-2\zeta(2))}+\\
 &  & +y\;\frac{6\zeta(2)+2\zeta(3)-12}{13-8\zeta(2)}+y^{2}\end{eqnarray*}

\end_inset 

 We can quickly see that although the eigenfunctions are polynomials and
 are exactly solvable, they quickly spiral out of control.
 
\layout Standard

XXX To Do: Double-check 
\begin_inset Formula $e_{2}$
\end_inset 

 Provide the closed-form finite-sum matrix elements.
 Discuss the similarity transform that takes 
\begin_inset Formula $w(x)$
\end_inset 

 to 
\begin_inset Formula $h(x)$
\end_inset 

 and discuss why this fails to preserve the eignevalues.
 What are the shift-states of this operator? What are the continuous-eigenvalue
 (square-integrable) eigenfunctions? Graph these eigenfunctions, see what
 kind of fratals they look like.
 
\layout Section

Singular Sawtooth of the Second Kind
\layout Standard

The singular sawtooth of the second kind is given by the dyadic-space conjugate
 of the continued-fraction shift function 
\begin_inset Formula $h(x)=\frac{1}{x}-\left\lfloor \frac{1}{x}\right\rfloor $
\end_inset 

, that is, 
\begin_inset Formula \[
c(x)=?\left(\frac{1}{?^{-1}(x)}-\left\lfloor \frac{1}{?^{-1}(x)}\right\rfloor \right)=(?\circ h\circ?^{-1})(x)\]

\end_inset 

 where 
\begin_inset Formula $?(x)$
\end_inset 

 is the Minkowski Question Mark, presented in earlier sections.
 This map consists of straight-line segments between values of 
\begin_inset Formula $1/2^{k}$
\end_inset 

, as pictured in figure 
\begin_inset LatexCommand \ref{cap:Singular-Sawtooth,-Second}

\end_inset 

.
 
\layout Standard


\begin_inset Float figure
wide false
collapsed false

\layout Caption


\begin_inset LatexCommand \label{cap:Singular-Sawtooth,-Second}

\end_inset 

Singular Sawtooth, Second Kind
\layout Standard


\begin_inset Graphics
	filename saw-second.png

\end_inset 


\layout Standard

Picture of the second kind of sawtooth.
 
\end_inset 

and can be written as 
\begin_inset Formula \[
c(x)=2-2^{n}x\;\textrm{ for \; }\frac{1}{2^{n}}<x\leq\frac{1}{2^{n-1}}\]

\end_inset 

 The Frobenius-Perron operator of this function provides a second model
 of the Gauss-Kuzmin-Wirsing operator.
 It can be solved exactly; unfortunately, while one might think that there
 is a similarity transform to take it back to GKW, it turns out this similarity
 transform is dastardly singular, being just the Jacobian of the Minkowski
 question mark 
\begin_inset Formula $(?'\circ?^{-1})(x)$
\end_inset 

, which we'll examine shortly.
 The FP operator is 
\begin_inset Formula \[
\left[U_{C}f\right](x)=\sum_{n=1}^{\infty}\frac{1}{2^{n}}f\left(\frac{2-x}{2^{n}}\right)\]

\end_inset 

 The following sections develop this operator in different function spaces.
 
\layout Subsection

The Polynomial Basis Eigenfunctions
\layout Standard

As before, we change variables to 
\begin_inset Formula $y=1-x$
\end_inset 

, expand both sides in terms of 
\begin_inset Formula $y$
\end_inset 

, and match terms to find the matrix elements 
\begin_inset Formula \[
C_{mk}=\left(\begin{array}{c}
k\\
m\end{array}\right)\frac{1}{2^{k+1}-1}\]

\end_inset 

 which is upper triangular (we take the binomial coeeficients to be vanishing
 when 
\begin_inset Formula $k<m$
\end_inset 

).
 The eigenvalues lie along the diagonal.
 The first few are 
\begin_inset Formula $\lambda_{0}=1$
\end_inset 

, 
\begin_inset Formula $\lambda_{1}=1/3$
\end_inset 

, 
\begin_inset Formula $\lambda_{2}=1/7$
\end_inset 

, 
\emph on 
etc
\emph default 
.
 with the ratio of successive eigenvalues tending to 2.
 The first few eigenvectors are 
\begin_inset Formula \[
e_{0}=1\]

\end_inset 

 
\begin_inset Formula \[
e_{1}=1-2y=2x-1\]

\end_inset 

 
\begin_inset Formula \[
e_{2}=1-\frac{18}{5}y+\frac{12}{5}y^{2}=\frac{-1}{5}\left(1+6x-12x^{2}\right)\]

\end_inset 

 
\begin_inset Formula \[
e_{3}=1-\frac{66}{13}y+\frac{84}{13}y^{2}-\frac{32}{13}y^{3}=\frac{-1}{13}\left(1+6x+12x^{2}-32x^{3}\right)\]

\end_inset 


\layout Standard

XXX present 
\begin_inset Formula $e_{4}$
\end_inset 

 as well.
\layout Subsection

The Failure of the Similarity Transform for the Polynomial Basis
\layout Standard

Under normal circumstances, whenever one has a pair of maps 
\begin_inset Formula $\alpha(x)$
\end_inset 

 and 
\begin_inset Formula $\beta(x)$
\end_inset 

 that are conjugate to each other through an invertible function 
\begin_inset Formula $\phi(x)$
\end_inset 

 such that 
\begin_inset Formula $\alpha(x)=(\phi\circ\beta\circ\phi^{-1})(x)$
\end_inset 

, then there exists a similarity transform 
\begin_inset Formula $S_{\phi}$
\end_inset 

 such that the Frobenius-Perron operators are also conjugate; that is, 
\begin_inset Formula $U_{\alpha}=S_{\phi}U_{\beta}S_{\phi}^{-1}$
\end_inset 

 where 
\begin_inset Formula $S_{\phi}^{-1}=S_{\phi^{-1}}$
\end_inset 

.
 Formally, one finds that 
\begin_inset Formula $S_{\phi}=1/(\phi'\circ\phi^{-1})$
\end_inset 

 where the prime denotes differentiation: 
\begin_inset Formula $\phi'(x)=d\phi(x)/dx$
\end_inset 

 .
 Since the continued-fraction shift function is conjugate to the sawtooth,
 one might hope that GKW would be conjugate to 
\begin_inset Formula $U_{C}$
\end_inset 

, that is, 
\begin_inset Formula $U_{h}=S_{?}U_{C}S_{?}^{-1}$
\end_inset 

.
 Unfortunately, the Minkowski Question Mark is highly singular and is not
 traditionally differentiable, and so we cannot build such a similarity
 transform using the polynomial function basis.
 Another way to deduce this is to note that the similarity transform 
\begin_inset Formula $S_{\phi}$
\end_inset 

, working as a traditional, ordinary operator, normally preserves the eigenvalue
s; that is, the eigenvalues of 
\begin_inset Formula $U_{\alpha}$
\end_inset 

 equal those of 
\begin_inset Formula $U_{\beta}$
\end_inset 

.
 In the current case, we see trouble in that the eigenvalues of 
\begin_inset Formula $U_{C}$
\end_inset 

 are not those of GKW.
 They are not even 'close', in that the ratio of tends to 
\begin_inset Formula $\lambda_{k}/\lambda_{k+1}=2$
\end_inset 

 whereas for the GKW the ratio is 2.65...
 I am not aware of what this value is supposed to be.
 Its plausible that it may be Khinchin's constant 2.685.
 But given the intricate connection between the Riemann Zeta, the Modular
 Group, and period-doubling fractals, its equally plausible is that it may
 be Feigenbaum's constant, the ratio of period doubling 
\begin_inset Formula $\delta=4.6692...$
\end_inset 

 which is 2+2.6692...
\layout Standard

However, there are suggestive elements.
 For example, the function argument 
\begin_inset Formula $(2-x)/2^{n}$
\end_inset 

 is just the dyadic polynomial 
\begin_inset Formula $(g_{D}^{n-1}r_{D}g_{D})(x)$
\end_inset 

.
 Tantalizingly, the correspondig Mobius transform is 
\begin_inset Formula $(g_{C}^{n-1}r_{C}g_{C})(x)=1/(n+x)$
\end_inset 

 which is the function argument to the GKW operator.
 This suggests the tantalizing re-write of the terms of GKW as 
\begin_inset Formula \[
f\left(\frac{1}{n+x}\right)=f\circ?^{-1}\left(\frac{2-?(x)}{2^{n}}\right)\]

\end_inset 

 Also, one can do strange things such as xxx but why do we want to do that?
\layout Standard

The point is to not give up hope on the operator relationships, even though
 the polynomial basis breaks the relationship.
 Thus, we are motivated to explore other bases, and not just the polynomial
 basis.
 Fortunately, we can find some of these.
 
\layout Subsection

Fractal Eigenfunctions of the Second Sawtooth
\layout Standard

The Takagi curve can be used to build an alternate set of eigenfunctions
 for the seco
\layout Standard

nd sawtooth, posessing continuous-spectrum eigenvalues.
 These eigenfunctions are not differentiable, and thus cannot be obtained
 through polynomials, and thus are not visible when working with the operator
 in a polynomial-basis Hilbert Space.
 They can be used to build an alternate function space, in which the Second
 Sawtooth remains exactly solvable.
 
\layout Standard

We recognize from the studying of the dyadic representation of the Modular
 Group 
\begin_inset Formula $SL(2,\mathbb{Z})$
\end_inset 

 that the second sawtooth is expressed in terms of the the group element
 
\begin_inset Formula \[
\left[g_{D}^{k-1}r_{D}g_{D}\right](x)=\frac{1}{2^{k-1}}-\frac{x}{2^{k}}\]

\end_inset 

 adn thus functions posessing the modular group symmetry are candidates
 for solving the operator 
\begin_inset Formula $U_{C}$
\end_inset 

.
 The candidates we have in mind are of course the family of Takagi Curves.
 
\layout Standard

We begin by defining the Takagi Curve as 
\begin_inset Formula \[
t_{w}(x)=\sum_{k=0}^{\infty}w^{k}\tau\left(2^{k}x-\left\lfloor 2^{k}x\right\rfloor \right)\]

\end_inset 

 where 
\begin_inset Formula $\tau(x)$
\end_inset 

 is the triangle wave: 
\begin_inset Formula \[
\tau(x)=\left\{ \begin{array}{ccc}
2x & \;\textrm{ when }\; & 0\leq x\leq1/2\\
2(1-x) & \;\textrm{ when }\; & 1/2\leq x\leq1\end{array}\right.\]

\end_inset 

 This form of the Takagi curve transforms under the three-dimensional representa
tion of the Modular Group.
 Specifically, we write 
\begin_inset Formula \[
g_{3}^{n}=\left(\begin{array}{ccc}
1 & 0 & 0\\
0 & 1/2^{n} & 0\\
0 & q_{n}(w) & w\end{array}\right)\]

\end_inset 

 where 
\begin_inset Formula $q_{n}(w)$
\end_inset 

 is the polynomial 
\begin_inset Formula \[
q_{n}(w)=\frac{1}{2^{n-1}}\sum_{k-0}^{n-1}(2w)^{k}=\frac{1}{2^{n-1}}\left(\frac{1-(2w)^{n}}{1-2w}\right)\]

\end_inset 

 We write out the full matrix form for 
\begin_inset Formula $g_{3}^{k-1}r_{3}g_{3}$
\end_inset 

 and apply the group action isomorphism 
\begin_inset Formula $t_{w}g_{D}^{k-1}r_{D}g_{D}=g_{3}^{k-1}r_{3}g_{3}t_{w}$
\end_inset 

 to obtain 
\begin_inset Formula \[
t_{w}\left(\frac{1}{2^{k-1}}-\frac{x}{2^{k}}\right)=q_{k-1}(w)+x\left(w^{k-1}-q_{k-1}(w)/2\right)+w^{k}t_{w}(x)\]

\end_inset 

 Inserting the above back into the definition for the sawtooth operator,
 and performing the sum, we get
\begin_inset Formula \[
\left[U_{C}t_{w}\right](x)=\frac{4}{3(2-w)}+\frac{x}{3(2-w)}+\frac{wt_{w}(x)}{2-w}\]

\end_inset 

 From this, we can immediately read off the eigenvalue as 
\begin_inset Formula $w/(2-w)$
\end_inset 

.
 To get the eigenfunction, we need to complete the diagonalization by using
 
\begin_inset Formula $\left[U_{C}1\right](x)=1$
\end_inset 

 and 
\begin_inset Formula $\left[U_{C}x\right](x)=(2-x)/3$
\end_inset 

 to get the eigenfunction 
\begin_inset Formula \[
E_{2}(x)=\frac{2-w}{2(w+1)(w-1)}+\frac{x}{2(w+1)}+t_{w}(x)\]

\end_inset 

 It should be clear from this presentation that the higher and lower dimensional
 Takagi curves, of both even and odd parity, give eigenvectors and eigenvalues
 as well.
 We present a few more here:
\layout Standard

XXX to do, present 
\begin_inset Formula $E_{1}$
\end_inset 

and the odd-parity 
\begin_inset Formula $E_{2}$
\end_inset 

and both parities for 
\begin_inset Formula $E_{3}$
\end_inset 

 as well.
\layout Section

Other Trees of Rationals
\layout Standard

Recall that we were able to construct other trees that are isomorphic to
 the Stern-Brocot tree by passing the values in the Stern-Brocot Tree through
 a ratio of polynomials, thus mapping rationals to rationals.
 Monotonically-increasing functions will always perserve monotonicity of
 the question mark.
 Other mappings, such as the cubic 
\begin_inset Formula $x^{3}-x$
\end_inset 

, are in general not globally monotonic, but they are always locally monotonic.
 In other words, 
\begin_inset Formula $?((2x-1)^{3}-x+1)$
\end_inset 

 is montonic between the same regions that 
\begin_inset Formula $(2x-1)^{3}-x+1$
\end_inset 

 is, and thus it does not yeild a fundamentally new function.
 Thus, these ploynomial-based mappings of rationals into rationals do not
 generate another self-similar map, they are distorted versions of the Minkowski
 question mark.
\layout Standard

Here's a mapping that is continuous and is also fractally non-monotonic
 (and is thus self-similar): its 
\begin_inset Formula $x-?(x)$
\end_inset 

 which looks sine-like and we want to exhibit the cosine-like so that we
 can build up fractally-periodic basis functions.
 
\layout Section

Conclusions
\layout Standard

Apologies for the format of this paper
\layout Bibliography
\bibitem [asdf]{key-1}

Here is a very similarly titled paper with a very different subject matter:
 
\begin_inset LatexCommand \htmlurl[Continued Fractions and Chaos]{http://www.cecm.sfu.ca/organics/papers/corless/confrac/html/confrac.html}

\end_inset 

 by Robert M.
 Corless
\layout Bibliography
\bibitem [Dri99]{key-2}

Dean Driebe, 
\emph on 
Fully Chaotic Maps and Broken Time Symmetry, 1999,
\emph default 
 Kluwer Academic Publishers
\layout Bibliography
\bibitem [Man88]{key-3}

Benoit Mandelbrot, in 
\emph on 
The Science of Fractal Images, ed.
 Heinz-Otto Peitgen, Dietmar Saupe,
\emph default 
 (Springer-Verlag, 1988) p.
 246
\layout Bibliography
\bibitem [deR57]{key-4}

Georges de Rham, 
\emph on 
On Some Curves Defined by Functional Equations
\emph default 
 (1957), reprinted in
\emph on 
 Classics on Fractals, ed.
 Gerald A.
 Edgar
\emph default 
, (Addison-Wesley, 1993) pp.
 285-298
\layout Bibliography
\bibitem [Gas92]{key-10}

P.
 Gaspard, 
\emph on 
r-adic one-dimensional maps and the Euler summation formula
\emph default 
, 1992, Journal of Physics A: Mathematical and General, vol.
 25, L483-485.
 
\the_end
