#LyX 1.5.3 created this file. For more info see http://www.lyx.org/
\lyxformat 276
\begin_document
\begin_header
\textclass article
\language english
\inputencoding auto
\font_roman times
\font_sans helvet
\font_typewriter courier
\font_default_family default
\font_sc false
\font_osf false
\font_sf_scale 100
\font_tt_scale 100
\graphics default
\paperfontsize default
\spacing single
\papersize default
\use_geometry false
\use_amsmath 2
\use_esint 0
\cite_engine basic
\use_bibtopic false
\paperorientation portrait
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\defskip medskip
\quotes_language english
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\author "" 
\end_header

\begin_body

\begin_layout Title
Entropy of Continued Fractions (Gauss-Kuzmin Entropy)
\end_layout

\begin_layout Author
Linas Vepstas <linasvepstas@gmail.com>
\end_layout

\begin_layout Date
June 2008
\end_layout

\begin_layout Abstract
This short paper provides a numerical exploration of the entropy of the
 Gauss-Kuzmin distribution.
 
\end_layout

\begin_layout Section
Introduction
\end_layout

\begin_layout Standard
Let 
\begin_inset Formula $x$
\end_inset

 be a real number, 
\begin_inset Formula $0\le x\le1$
\end_inset

.
 Let 
\begin_inset Formula \[
x=[a_{1},a_{2},a_{3},\cdots]=\frac{1}{a_{1}+\frac{1}{a_{2}+\frac{1}{a_{3}+\cdots}}}\]

\end_inset

be the continued fraction expansion of 
\begin_inset Formula $x.$
\end_inset

 Given the uniform distribution of the reals on the unit interval, the Gauss-Kuz
min distribution gives the probability 
\begin_inset Formula $\mbox{Pr}(a_{n}=k)$
\end_inset

 of an integer 
\begin_inset Formula $k$
\end_inset

 appearing in any given place 
\begin_inset Formula $a_{n}$
\end_inset

 of the expansion.
 This probability is known classically, and is given by 
\begin_inset Formula \[
\mbox{Pr}(a_{n}=k)=p_{k}=-\log_{2}\left[1-\frac{1}{\left(k+1\right)^{2}}\right]\]

\end_inset


\end_layout

\begin_layout Standard
The continued fraction expansion can be viewed as a discrete random variable,
 which may be sampled; the 
\begin_inset Formula $n$
\end_inset

'th sampling giving the value 
\begin_inset Formula $a_{n}$
\end_inset

.
 Given a discrete random variable with 
\begin_inset Formula $N$
\end_inset

 possible discrete states, the (information-theoretic) entropy
\begin_inset LatexCommand cite
key "Ash1965"

\end_inset

 is defined as
\begin_inset Formula \[
H=-\sum_{k=1}^{N}p_{k}\log_{2}p_{k}\]

\end_inset

where 
\begin_inset Formula $p_{k}$
\end_inset

 is the probability of the 
\begin_inset Formula $k$
\end_inset

'th state occuring in a measurement of the random variable.
 The entropy is measured in bits; and so 
\begin_inset Formula $\log_{2}p=\log p/\log2$
\end_inset

 is the base-2 logarithm.
 For continued fractions, one has an infinite number of possible states,
 and so 
\begin_inset Formula $N=\infty$
\end_inset

 and so 
\begin_inset Formula \[
H=-\sum_{k=1}^{\infty}p_{k}\log_{2}p_{k}\]

\end_inset

Here, the probability 
\begin_inset Formula $p_{k}$
\end_inset

 is given by the Gauss-Kuzmin distribution.
 This entropy shall be termed the 
\begin_inset Quotes eld
\end_inset


\emph on
Gauss-Kuzmin entropy
\emph default

\begin_inset Quotes erd
\end_inset

, as it is uniquely fixed by the Gauss-Kuzmin distribution.
 It appears to have been first defined and calculated by N.
 M.
 Blachman in 1984
\begin_inset LatexCommand cite
key "Blach84"

\end_inset

.
 The numerical value of 
\begin_inset Formula $H$
\end_inset

 may be obtained by computation; it is 
\begin_inset Formula \[
H=3.4325275139\cdots\]

\end_inset

 or alternately, in terms of the natural logarithm,
\end_layout

\begin_layout Standard
\begin_inset Formula \[
H\log2=2.37924676850\cdots\]

\end_inset

The above values were computed with the GNU MP multiple precision library
\begin_inset LatexCommand cite
key "GMP"

\end_inset

, and should be accurate to approximately the given number of digits.
 They were obtained by means of brute-force summation, together with quadratic
 extrapolation, up to values of 
\begin_inset Formula $k=2.5\times10^{9}$
\end_inset

.
 The quadratic extrapolation may be performed as follows: let 
\begin_inset Formula \[
t=1-\sum_{k=1}^{N}p_{k}\]

\end_inset

and 
\begin_inset Formula \[
H(t)=-\sum_{k=1}^{N}p_{k}\log p_{k}\]

\end_inset

It can be readily seen that 
\begin_inset Formula $\lim_{N\to\infty}t=0$
\end_inset

.
 An explicit form for 
\begin_inset Formula $t$
\end_inset

 as a function of 
\begin_inset Formula $N$
\end_inset

 is given in the next section.
 It is also straightforward to observe that 
\begin_inset Formula $H(t)$
\end_inset

 is very nearly a linear function of 
\begin_inset Formula $t$
\end_inset

.
 Thus, one can readily estimate the value of 
\begin_inset Formula $H=\lim_{t\to0}H(t)$
\end_inset

 by means of a quadratic extrapolation in 
\begin_inset Formula $t$
\end_inset

 to the limit 
\begin_inset Formula $t=0$
\end_inset

.
 Such extrapolation offers several additional decimal digits of precision
 over the raw value of the sum, terminated at a finite 
\begin_inset Formula $N$
\end_inset

.
 
\end_layout

\begin_layout Section
Analytic results
\end_layout

\begin_layout Standard
The partial sum 
\begin_inset Formula \[
C(N)=-\sum_{k=1}^{N}p_{k}\]

\end_inset

 is straightforward to sum explicitly.
 Note that 
\begin_inset Formula \[
1-\frac{1}{\left(k+1\right)^{2}}=\frac{k\left(k+2\right)}{\left(k+1\right)^{2}}\]

\end_inset

 and so 
\begin_inset Formula \begin{align*}
C(N)= & -\sum_{k=1}^{N}\log_{2}\left[\frac{k\left(k+2\right)}{\left(k+1\right)^{2}}\right]\\
= & -\log_{2}\left[\prod_{k=1}^{N}\frac{k\left(k+2\right)}{\left(k+1\right)^{2}}\right]\\
= & 1-\log_{2}\left[\frac{N+2}{N+1}\right]\end{align*}

\end_inset


\end_layout

\begin_layout Section
Typical Sequences
\end_layout

\begin_layout Standard
Given any particular value of 
\begin_inset Formula $x=[a_{1},a_{2},a_{3},\cdots]$
\end_inset

, one may ask just how representative the sequence is of a 
\begin_inset Quotes eld
\end_inset

typical
\begin_inset Quotes erd
\end_inset

 sequence, where a 
\begin_inset Quotes eld
\end_inset

typical
\begin_inset Quotes erd
\end_inset

 sequences is one which has a distribution of 
\begin_inset Formula $a_{n}$
\end_inset

 close to that of the Gauss-Kuzmin distribution.
 It is of some interest to see whether the rational numbers are 
\begin_inset Quotes eld
\end_inset

typical
\begin_inset Quotes erd
\end_inset

 continued factions, or not.
 The question is important, as many numerical explorations of continued
 fractions must, by necessity, work with either finite-length, or periodic
 continued fraction expansions.
 Also of some curiosity is whether well-known transcendental constants,
 such as 
\begin_inset Formula $\pi$
\end_inset

 of the Euler-Mascheroni constant 
\begin_inset Formula $\gamma$
\end_inset

 are 
\begin_inset Quotes eld
\end_inset

typical
\begin_inset Quotes erd
\end_inset

 or not.
\end_layout

\begin_layout Standard
The standard techniques of discussing typical sequences
\begin_inset LatexCommand cite
key "Ash1965"

\end_inset

 are not directly applicable, as the Gauss-Kuzmin distribution has infinite
 mean and mean-square variance.
 Let 
\begin_inset Formula $p/q$
\end_inset

 be a rational, with a continued-fraction representation of length 
\begin_inset Formula $M$
\end_inset

.
 Let 
\begin_inset Formula $m_{k}$
\end_inset

 be the number of times that the integer 
\begin_inset Formula $k$
\end_inset

 occurs in the continued fraction expansion of 
\begin_inset Formula $p/q$
\end_inset

.
 Normalizing, one has a frequency of occurance: 
\begin_inset Formula \[
f_{k}=\frac{m_{k}}{M}\]

\end_inset

and clearly, 
\begin_inset Formula $\sum_{k}f_{k}=1$
\end_inset

.
 One may define a relative entropy as 
\begin_inset Formula \begin{equation}
\Delta H\left(\frac{p}{q}\right)=-\sum_{k=1}^{\infty}\left(f_{k}-p_{k}\right)\log_{2}p_{k}\label{eq:relative-ent}\end{equation}

\end_inset

 This relative entropy is shown in figure 
\begin_inset LatexCommand ref
reference "fig:relent"

\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide true
sideways false
status open

\begin_layout Standard
\begin_inset LatexCommand label
name "fig:relent"

\end_inset


\begin_inset Caption

\begin_layout Standard
Relative Entropy
\end_layout

\end_inset

 
\begin_inset Graphics
	filename relative-entropy.ps

\end_inset


\end_layout

\begin_layout Standard
This graph shows the relative entropy, given by eqn.
 
\begin_inset LatexCommand ref
reference "eq:relative-ent"

\end_inset

, for all of the rationals 
\begin_inset Formula $p/q$
\end_inset

 for 
\begin_inset Formula $q\le128$
\end_inset

.
 
\begin_inset Note Note
status open

\begin_layout Standard
This graph was made with data from src/fractal/misc/entropy.C and plotted
 with entropy.gplot
\end_layout

\end_inset


\end_layout

\begin_layout Standard

\end_layout

\end_inset


\end_layout

\begin_layout Standard
Another standard interpretation of entropy is that, given a length 
\begin_inset Formula $\ell$
\end_inset

, there are 
\begin_inset Formula $2^{\ell H}$
\end_inset

 
\begin_inset Quotes eld
\end_inset

typical
\begin_inset Quotes erd
\end_inset

 sequences of length 
\begin_inset Formula $\ell$
\end_inset

; other sequences are possible, but unlikely.
 For small rationals, this can be reversed.
 Consider, intead, the set of all (irreducible) rationals 
\begin_inset Formula $p/q$
\end_inset

 up to a maximum denominator 
\begin_inset Formula $q\le Q$
\end_inset

.
 There are 
\begin_inset Formula $N(Q)$
\end_inset

 such rationals, which have an average length 
\begin_inset Formula $\ell(Q)$
\end_inset

.
 One then defines a 
\emph on
de facto
\emph default
 entropy as 
\begin_inset Formula \begin{equation}
H\left(Q\right)=\frac{\log_{2}N\left(Q\right)}{\ell\left(Q\right)}\label{eq:defacto}\end{equation}

\end_inset

 For small rationals, the defacto entropy is considerably smaller than the
 Gass-Kuzmin entropy.
 This is illustrated in figure 
\begin_inset LatexCommand ref
reference "fig:defacto"

\end_inset

.
 
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Standard

\end_layout

\begin_layout Standard
\begin_inset LatexCommand label
name "fig:defacto"

\end_inset


\begin_inset Caption

\begin_layout Standard
Defacto entropy for small rationals
\end_layout

\end_inset

 
\begin_inset Graphics
	filename defacto.ps

\end_inset


\end_layout

\begin_layout Standard
This figure shows the defacto entropy, given by eqn 
\begin_inset LatexCommand ref
reference "eq:defacto"

\end_inset

.
\begin_inset Note Note
status open

\begin_layout Standard
Created by src/fractal/misc/entropy/defacto.C plotted with defacto.gplot
\end_layout

\end_inset


\end_layout

\begin_layout Standard

\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset LatexCommand bibtex
options "plain"
bibfiles "/home/linas/src/fractal/paper/fractal"

\end_inset


\end_layout

\end_body
\end_document
